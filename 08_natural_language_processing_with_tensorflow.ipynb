{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP fundamentals in TensorFlow\n",
    "\n",
    "NLP has the goal of deriving information out of natural language (could be sequences of text or speech).\n",
    "\n",
    "Another common term for NLP problem is sequence to sequence problems (seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 10 12:22:25 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.59       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   50C    P8    18W /  N/A |    536MiB /  6144MiB |     42%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3132    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      8152    C+G   ...lication\\WebCompanion.exe    N/A      |\n",
      "|    0   N/A  N/A      9916    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     12332    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12424    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16404    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     24668    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     25988    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     27132    C+G   ...4__htrsf667h5kn2\\AWCC.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-2349283b-d8c3-574d-bb05-0097332584c3)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"helper_functions.py\"):\n",
    "    !python -m wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a text dataset\n",
    "\n",
    "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster).\n",
    "\n",
    "See the original source: https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"nlp_getting_started.zip\"):\n",
    "    !python -m wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
    "unzip_data(\"C:/Selbststudium/Udemy/Udemy_TensorFlow_Certificate/nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a text dataset\n",
    "\n",
    "To visualize our text samples, we first have to read them in , one way to do so would be to use Python: https://realpython.com/read-write-files-python/ \n",
    "\n",
    "But i prefer to get visual straight away.\n",
    "\n",
    "So another way to do this is to use pandes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Forest fire near La Ronge Sask. Canada', 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"][1], train_df[\"target\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the test dataframe look like?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text: Plans by former First Lady and wife of ex-President Goodluck Jonathan Dame Patience Jonathan to hijack the All... http://t.co/HaShGQAFic\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text: Migrants Rescued After Boat Capsizes Off Libya http://t.co/pmGgavtokP\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text: Meet the man who survived both Hiroshima and Nagasaki http://t.co/PNSsIa5e46 http://t.co/LSVsYSpdxX\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text: #WeLoveLA #NHLDucks Avalanche Defense: How They Match vs St. Louis Blues http://t.co/9v1RVCOMH2 #SportsRoadhouse\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text: coleslaw #wrecked http://t.co/sijNBmCZIJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # Create random indexes not higher than the total number\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split training data into training and validation sets \n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cnverting text into numbers\n",
    "\n",
    "When dealing with a text problem, one of the first thing you'll have to do before you can build a model is to convert your text to numbers. \n",
    "\n",
    "There are a few ways to do this, namely:\n",
    "* Tokenization - direct mapping of token (a token could be a word or a character)\n",
    "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet'], 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0].split(), len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokes (words) in the training tweets\n",
    "max_length = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization parameters\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    standardize=\"lower_and_strip_punctuation\", # Default\n",
    "    split=\"whitespace\", # Default\n",
    "    ngrams=None, # Default\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    "    pad_to_max_tokens=True) # Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I made a friend more interesting than all of y'all combined https://t.co/isBtzUJFBm\n",
      "    Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   8,  299,    3, 1020,   51, 1281,   76,   44,    6, 1341, 2515,\n",
       "           1,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\n\\\n",
    "    Vectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an EmbeddingLayer\n",
    "\n",
    "To make our embedding, we're going to use TensorFlow's EmbeddingLayer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "The parameters we care most about for our embedding layer: \n",
    "* `input_dim` = the size of our vocabulary\n",
    "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each tolen gets represented by a vector 100 long\n",
    "* `input_length` = length of the sequences being passed to the embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x28f3e06b9d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "#KCA #VoteJKT48ID 12News: UPDATE: A family of 3 has been displaced after fired damaged housed near 90th and Osborn. Fire extinguished no iÛ_    \n",
      "Embedded version: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.04977724,  0.02507932, -0.00719507, ..., -0.03601396,\n",
       "          0.03175818, -0.03941443],\n",
       "        [-0.04432033,  0.02450072, -0.02139157, ..., -0.00452955,\n",
       "         -0.02465843,  0.04637128],\n",
       "        [-0.01199299,  0.02760195,  0.04409454, ..., -0.01528273,\n",
       "          0.04369998,  0.00600426],\n",
       "        ...,\n",
       "        [-0.01989381, -0.00746895,  0.01519025, ..., -0.01858713,\n",
       "          0.03209586, -0.04201304],\n",
       "        [ 0.01687857,  0.04230985,  0.01540412, ...,  0.00295796,\n",
       "          0.01308397, -0.00442243],\n",
       "        [-0.00556092, -0.03691836, -0.00257389, ..., -0.02613376,\n",
       "         -0.00646905,  0.02240257]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "    \\nEmbedded version: \")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 4.9777243e-02,  2.5079321e-02, -7.1950667e-03, -1.2261905e-02,\n",
       "        -4.0188681e-02,  2.8195310e-02,  2.8609131e-02,  2.7586173e-02,\n",
       "        -1.6464401e-02,  3.4368411e-03, -3.9052926e-02, -4.7568500e-02,\n",
       "         1.2606230e-02, -4.9501408e-02, -1.4889944e-02, -6.9529936e-04,\n",
       "         3.9857674e-02,  2.9290430e-03,  2.5315285e-03, -4.0469982e-02,\n",
       "         2.3827221e-02,  1.2340140e-02, -2.3072435e-02,  3.7684109e-02,\n",
       "         1.7969381e-02, -3.2950103e-02, -1.9873654e-02,  3.7652854e-02,\n",
       "         3.5863925e-02,  3.9562497e-02, -1.8415451e-03,  5.4061413e-03,\n",
       "         4.0263083e-02,  4.2565260e-02, -9.6150525e-03,  4.5403134e-02,\n",
       "        -9.9942908e-03,  3.1701256e-02,  3.5582669e-03,  2.2150148e-02,\n",
       "         2.6151385e-02, -2.2909714e-02,  1.0143507e-02,  1.8426504e-02,\n",
       "        -3.6476851e-03,  1.7457437e-02, -3.7434995e-02, -2.9602909e-02,\n",
       "        -2.1389890e-02, -5.7799444e-03, -4.3734442e-02, -4.4298600e-02,\n",
       "        -4.8745967e-02,  4.5896817e-02,  3.9485220e-02,  4.9237832e-03,\n",
       "         1.8299222e-03, -3.8498342e-02, -3.9363302e-02, -4.5908120e-02,\n",
       "         1.2824047e-02, -4.9961518e-02, -4.2735197e-02,  3.0239191e-02,\n",
       "         2.2888195e-02, -7.8896657e-03, -3.8998403e-02, -2.0125080e-02,\n",
       "         7.2942600e-03, -2.3681343e-02, -2.7251948e-02, -3.4368195e-02,\n",
       "         4.9342360e-02, -4.1692875e-02,  1.1666037e-02, -2.0977212e-02,\n",
       "         2.0046558e-02,  4.4886414e-02,  4.5101915e-02, -2.0096589e-02,\n",
       "         3.5558525e-02, -1.4414359e-02, -2.8670454e-02, -4.8603762e-02,\n",
       "         5.1484592e-03, -2.8918220e-02,  4.5966357e-05, -4.7443319e-02,\n",
       "         7.6305494e-03,  3.9232109e-02,  3.6604498e-02, -7.5208321e-03,\n",
       "         3.0313618e-03,  1.0089062e-02,  3.1824000e-03, -1.6609251e-02,\n",
       "        -3.9144088e-02, -3.3435583e-02,  4.1219506e-02,  8.4346421e-03,\n",
       "        -3.9672386e-02, -2.8903389e-02,  4.7376622e-02,  2.4683896e-02,\n",
       "        -3.5032570e-02, -1.0375060e-02,  4.5463648e-02, -3.7968528e-02,\n",
       "         1.9015782e-03,  1.1051834e-02,  3.4791443e-02,  2.1390978e-02,\n",
       "         2.4544861e-02, -2.7588403e-02,  2.5806878e-02, -3.7427269e-02,\n",
       "        -4.1128635e-02, -4.9752858e-02,  3.8330462e-02, -2.8287578e-02,\n",
       "        -3.8706042e-02,  5.0601475e-03, -2.1442462e-02,  3.2434050e-02,\n",
       "         1.1660218e-02, -3.6013961e-02,  3.1758178e-02, -3.9414428e-02],\n",
       "       dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " '#KCA #VoteJKT48ID 12News: UPDATE: A family of 3 has been displaced after fired damaged housed near 90th and Osborn. Fire extinguished no i\\x89Û_')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "Now we've got a way to turn our text sequences into numbers, it's time  to start building a series of modelling experiments.\n",
    "\n",
    "We'll start with a baseline and move on from there.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline), from sklearn ML map: \n",
    "* Model 1: Feed-forward neural network (dense model)\n",
    "* Model 2: LSTM (RNN)\n",
    "* Model 3: GRU (RNN) \n",
    "* Model 4: Bidirectional-LSTM model (RNN)\n",
    "* Model 5: 1D Convolutional Network (CNN)\n",
    "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
    "* Model 7: Same as model 6 with 10% of training data\n",
    "\n",
    "How are we going to approach all of these?\n",
    "\n",
    "Use the standard steps in modelling with tensorflow:\n",
    "* Create a model\n",
    "* Build the model\n",
    "* Fit the model\n",
    "* Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline\n",
    "\n",
    "As with all machine learning modelling experiments it's important to create a baseline model so you've got a benchmark for future experiments to build uopn.\n",
    "\n",
    "To create our baseline, we'll use Sklearn's Mulinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
    "\n",
    "> 🔑 **Note:** It's common to use non DL-algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([ # Pipeline is similar to tensorflow's sequential\n",
    "    (\"tfidf\", TfidfVectorizer()), # name of the step is \"tfidf\"; convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()), # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate all of our model's predictions with different metrics every time, however this will be cumbersome and could easily be fixed with a function.\n",
    "\n",
    "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "For a deep overview of many different methods, see the Sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate accuracy, precision, reall and f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binare classification model.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _, = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy, \n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall, \n",
    "        \"f1-score\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (Need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save tensorboard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220710-122238\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 10ms/step - loss: 0.6116 - accuracy: 0.6945 - val_loss: 0.5384 - val_accuracy: 0.7428\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.4417 - accuracy: 0.8164 - val_loss: 0.4717 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3468 - accuracy: 0.8608 - val_loss: 0.4632 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2840 - accuracy: 0.8914 - val_loss: 0.4648 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2375 - accuracy: 0.9129 - val_loss: 0.4858 - val_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 79.26509186351706,\n",
       "  'precision': 0.8111390004213173,\n",
       "  'recall': 0.7926509186351706,\n",
       "  'f1-score': 0.7862189758049549},)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4858403503894806, 0.7900262475013733]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.02368134e-01],\n",
       "       [7.47478485e-01],\n",
       "       [9.97771680e-01],\n",
       "       [1.09837860e-01],\n",
       "       [1.19640715e-01],\n",
       "       [9.29973125e-01],\n",
       "       [8.89709949e-01],\n",
       "       [9.92094934e-01],\n",
       "       [9.63363707e-01],\n",
       "       [2.90245444e-01],\n",
       "       [1.06996849e-01],\n",
       "       [6.79377198e-01],\n",
       "       [4.58070226e-02],\n",
       "       [2.29362205e-01],\n",
       "       [5.86651498e-03],\n",
       "       [1.08360559e-01],\n",
       "       [2.27997359e-02],\n",
       "       [8.14560056e-02],\n",
       "       [2.01601163e-01],\n",
       "       [4.50489968e-01],\n",
       "       [8.97438586e-01],\n",
       "       [3.71858627e-02],\n",
       "       [3.79374534e-01],\n",
       "       [7.09106922e-02],\n",
       "       [9.56156731e-01],\n",
       "       [9.98832047e-01],\n",
       "       [3.14853452e-02],\n",
       "       [5.75141497e-02],\n",
       "       [2.07765307e-02],\n",
       "       [1.57222584e-01],\n",
       "       [5.06276488e-01],\n",
       "       [2.22774699e-01],\n",
       "       [4.39422578e-01],\n",
       "       [1.75170362e-01],\n",
       "       [4.66602921e-01],\n",
       "       [5.49983718e-02],\n",
       "       [9.94507015e-01],\n",
       "       [1.31776586e-01],\n",
       "       [2.86819581e-02],\n",
       "       [9.98799324e-01],\n",
       "       [1.87497929e-01],\n",
       "       [1.59357823e-02],\n",
       "       [3.32042634e-01],\n",
       "       [4.76655103e-02],\n",
       "       [6.41487062e-01],\n",
       "       [9.83124971e-01],\n",
       "       [2.57463366e-01],\n",
       "       [9.15954590e-01],\n",
       "       [1.98299125e-01],\n",
       "       [5.76173007e-01],\n",
       "       [4.32130247e-02],\n",
       "       [5.15063286e-01],\n",
       "       [4.11750257e-01],\n",
       "       [3.30396593e-02],\n",
       "       [1.13064721e-01],\n",
       "       [2.86830030e-02],\n",
       "       [2.17533395e-01],\n",
       "       [9.48876381e-01],\n",
       "       [7.21850321e-02],\n",
       "       [2.09364411e-03],\n",
       "       [1.41993821e-01],\n",
       "       [9.63323414e-01],\n",
       "       [8.93769741e-01],\n",
       "       [1.40054002e-01],\n",
       "       [9.19777513e-01],\n",
       "       [9.74746704e-01],\n",
       "       [6.72495067e-01],\n",
       "       [4.06964391e-01],\n",
       "       [1.10519283e-01],\n",
       "       [1.42687023e-01],\n",
       "       [6.35614321e-02],\n",
       "       [2.60124449e-02],\n",
       "       [9.40570295e-01],\n",
       "       [1.36999235e-01],\n",
       "       [1.09735005e-01],\n",
       "       [3.56310487e-01],\n",
       "       [3.93492848e-01],\n",
       "       [8.26143980e-01],\n",
       "       [2.41028517e-01],\n",
       "       [5.37325621e-01],\n",
       "       [4.21140820e-01],\n",
       "       [2.12538525e-01],\n",
       "       [9.95748580e-01],\n",
       "       [8.60467926e-02],\n",
       "       [1.42990053e-01],\n",
       "       [7.72485361e-02],\n",
       "       [2.08998527e-02],\n",
       "       [9.38280225e-02],\n",
       "       [6.07267022e-01],\n",
       "       [8.61141801e-01],\n",
       "       [9.91053998e-01],\n",
       "       [8.81624501e-03],\n",
       "       [5.97459316e-01],\n",
       "       [2.32346617e-02],\n",
       "       [9.80611742e-01],\n",
       "       [7.41114020e-01],\n",
       "       [8.59402478e-01],\n",
       "       [9.60969150e-01],\n",
       "       [8.57728064e-01],\n",
       "       [9.46630299e-01],\n",
       "       [9.99430716e-01],\n",
       "       [2.11024567e-01],\n",
       "       [1.15160821e-02],\n",
       "       [9.02290463e-01],\n",
       "       [8.63630593e-01],\n",
       "       [7.23039508e-02],\n",
       "       [8.29148591e-01],\n",
       "       [9.73769009e-01],\n",
       "       [5.39253876e-02],\n",
       "       [3.72983783e-01],\n",
       "       [6.94684923e-01],\n",
       "       [3.04167364e-02],\n",
       "       [2.50370622e-01],\n",
       "       [1.39694780e-01],\n",
       "       [1.19343437e-01],\n",
       "       [3.72276694e-01],\n",
       "       [4.13117349e-01],\n",
       "       [6.69910252e-01],\n",
       "       [6.94611251e-01],\n",
       "       [7.04838634e-02],\n",
       "       [9.99699354e-01],\n",
       "       [7.24516883e-02],\n",
       "       [1.24597214e-01],\n",
       "       [7.75064826e-01],\n",
       "       [4.17700022e-01],\n",
       "       [2.91780055e-01],\n",
       "       [8.38739932e-01],\n",
       "       [1.06318565e-02],\n",
       "       [7.05487281e-02],\n",
       "       [7.94462025e-01],\n",
       "       [9.74723101e-02],\n",
       "       [9.99699354e-01],\n",
       "       [9.99809563e-01],\n",
       "       [9.98832047e-01],\n",
       "       [9.79153275e-01],\n",
       "       [7.53833801e-02],\n",
       "       [9.71792579e-01],\n",
       "       [1.67108357e-01],\n",
       "       [2.66093940e-01],\n",
       "       [8.84334221e-02],\n",
       "       [9.96005356e-01],\n",
       "       [2.86841989e-01],\n",
       "       [2.29362205e-01],\n",
       "       [9.50930953e-01],\n",
       "       [2.36121073e-01],\n",
       "       [5.40815890e-01],\n",
       "       [4.12902348e-02],\n",
       "       [6.76316814e-03],\n",
       "       [2.14380816e-01],\n",
       "       [9.78914738e-01],\n",
       "       [2.39198461e-01],\n",
       "       [7.02327862e-02],\n",
       "       [3.82221162e-01],\n",
       "       [1.49604931e-01],\n",
       "       [2.10103050e-01],\n",
       "       [9.92291749e-01],\n",
       "       [7.07589030e-01],\n",
       "       [4.21411544e-01],\n",
       "       [9.87221181e-01],\n",
       "       [1.57829169e-02],\n",
       "       [9.72043395e-01],\n",
       "       [5.43785580e-02],\n",
       "       [2.26715699e-01],\n",
       "       [9.93483961e-01],\n",
       "       [2.19271690e-01],\n",
       "       [6.75515383e-02],\n",
       "       [9.98484790e-01],\n",
       "       [3.29173326e-01],\n",
       "       [9.81865227e-01],\n",
       "       [1.88404128e-01],\n",
       "       [9.93217528e-01],\n",
       "       [8.62003982e-01],\n",
       "       [7.98993289e-01],\n",
       "       [2.65718848e-02],\n",
       "       [9.97586727e-01],\n",
       "       [6.45146817e-02],\n",
       "       [3.68116260e-01],\n",
       "       [3.93200040e-01],\n",
       "       [6.91986978e-01],\n",
       "       [9.92872953e-01],\n",
       "       [1.26335472e-02],\n",
       "       [7.94321299e-01],\n",
       "       [7.17146754e-01],\n",
       "       [9.66309488e-01],\n",
       "       [9.71053958e-01],\n",
       "       [3.69663179e-01],\n",
       "       [9.51078832e-02],\n",
       "       [9.99612510e-01],\n",
       "       [1.24631040e-02],\n",
       "       [3.16117592e-02],\n",
       "       [1.09021820e-01],\n",
       "       [8.91579151e-01],\n",
       "       [7.38109648e-02],\n",
       "       [2.35016778e-01],\n",
       "       [1.34165604e-02],\n",
       "       [7.31752440e-02],\n",
       "       [3.94720323e-02],\n",
       "       [2.09853366e-01],\n",
       "       [7.23392725e-01],\n",
       "       [5.62608093e-02],\n",
       "       [2.91792423e-01],\n",
       "       [8.64395320e-01],\n",
       "       [9.67859745e-01],\n",
       "       [3.52273941e-01],\n",
       "       [9.25926268e-02],\n",
       "       [9.99760807e-01],\n",
       "       [5.81992984e-01],\n",
       "       [9.25784230e-01],\n",
       "       [6.54119670e-01],\n",
       "       [8.19689631e-01],\n",
       "       [2.95143694e-01],\n",
       "       [9.81111228e-01],\n",
       "       [1.49376523e-02],\n",
       "       [1.99251130e-01],\n",
       "       [5.80355013e-03],\n",
       "       [4.83694905e-03],\n",
       "       [9.54943419e-01],\n",
       "       [7.71636248e-01],\n",
       "       [8.86656165e-01],\n",
       "       [1.60192803e-01],\n",
       "       [7.04105437e-01],\n",
       "       [7.45365992e-02],\n",
       "       [2.17653122e-02],\n",
       "       [1.40456825e-01],\n",
       "       [9.79734898e-01],\n",
       "       [1.86598778e-01],\n",
       "       [4.83371943e-01],\n",
       "       [9.94566202e-01],\n",
       "       [5.72270811e-01],\n",
       "       [5.74174047e-01],\n",
       "       [8.44106674e-02],\n",
       "       [1.67621210e-01],\n",
       "       [8.13184798e-01],\n",
       "       [2.85337120e-01],\n",
       "       [4.98585075e-01],\n",
       "       [1.54259324e-01],\n",
       "       [5.10597885e-01],\n",
       "       [3.08022529e-01],\n",
       "       [1.28632694e-01],\n",
       "       [7.49014542e-02],\n",
       "       [3.92797828e-01],\n",
       "       [2.26341665e-01],\n",
       "       [9.99787390e-01],\n",
       "       [9.85364020e-01],\n",
       "       [5.87767288e-02],\n",
       "       [1.76157076e-02],\n",
       "       [8.52508187e-01],\n",
       "       [9.74825472e-02],\n",
       "       [1.02345102e-01],\n",
       "       [4.01734203e-01],\n",
       "       [3.73386852e-02],\n",
       "       [5.53579688e-01],\n",
       "       [6.60960679e-04],\n",
       "       [4.43421185e-01],\n",
       "       [9.07445550e-01],\n",
       "       [2.19599485e-01],\n",
       "       [9.64650869e-01],\n",
       "       [9.98700500e-01],\n",
       "       [2.57609546e-01],\n",
       "       [1.36075452e-01],\n",
       "       [3.03411067e-01],\n",
       "       [3.42066064e-02],\n",
       "       [4.80456278e-03],\n",
       "       [9.80173707e-01],\n",
       "       [9.60263431e-01],\n",
       "       [6.25409365e-01],\n",
       "       [9.50033188e-01],\n",
       "       [5.72618917e-02],\n",
       "       [1.51147664e-01],\n",
       "       [9.00535192e-03],\n",
       "       [1.60823300e-01],\n",
       "       [3.69013995e-02],\n",
       "       [9.52668250e-01],\n",
       "       [8.11148286e-02],\n",
       "       [7.25608086e-03],\n",
       "       [9.77633059e-01],\n",
       "       [1.13886334e-02],\n",
       "       [8.51156563e-02],\n",
       "       [9.80854630e-01],\n",
       "       [3.44230570e-02],\n",
       "       [1.00781955e-01],\n",
       "       [5.27706463e-03],\n",
       "       [9.66528833e-01],\n",
       "       [6.06363118e-01],\n",
       "       [7.41107583e-01],\n",
       "       [6.58677280e-01],\n",
       "       [5.11939406e-01],\n",
       "       [6.10464253e-02],\n",
       "       [9.25075293e-01],\n",
       "       [3.28638032e-02],\n",
       "       [6.98233724e-01],\n",
       "       [3.55358422e-01],\n",
       "       [3.33052427e-01],\n",
       "       [3.74464422e-01],\n",
       "       [1.72185227e-01],\n",
       "       [7.08821118e-01],\n",
       "       [2.26863295e-01],\n",
       "       [6.69056594e-01],\n",
       "       [1.26171365e-01],\n",
       "       [7.50535250e-01],\n",
       "       [3.25130634e-02],\n",
       "       [7.48952776e-02],\n",
       "       [2.02123508e-01],\n",
       "       [9.82051909e-01],\n",
       "       [1.57355964e-01],\n",
       "       [8.99265409e-02],\n",
       "       [3.47837210e-01],\n",
       "       [2.06404895e-01],\n",
       "       [1.23058230e-01],\n",
       "       [2.56517325e-02],\n",
       "       [2.61064805e-02],\n",
       "       [9.79792356e-01],\n",
       "       [3.18462610e-01],\n",
       "       [1.99067265e-01],\n",
       "       [9.99812186e-01],\n",
       "       [4.48433682e-02],\n",
       "       [5.38185418e-01],\n",
       "       [2.09642619e-01],\n",
       "       [3.93093675e-02],\n",
       "       [1.56742543e-01],\n",
       "       [1.50633991e-01],\n",
       "       [1.03771545e-01],\n",
       "       [8.87134850e-01],\n",
       "       [1.96142241e-01],\n",
       "       [9.85987723e-01],\n",
       "       [6.43052906e-02],\n",
       "       [1.99713707e-02],\n",
       "       [9.94255960e-01],\n",
       "       [1.89922061e-02],\n",
       "       [9.96202648e-01],\n",
       "       [1.43344790e-01],\n",
       "       [3.96967679e-02],\n",
       "       [9.61839497e-01],\n",
       "       [4.32762466e-02],\n",
       "       [3.60046662e-02],\n",
       "       [9.76460397e-01],\n",
       "       [5.26067009e-03],\n",
       "       [1.64517432e-01],\n",
       "       [7.38716662e-01],\n",
       "       [9.03775275e-01],\n",
       "       [3.92025150e-03],\n",
       "       [1.28058657e-01],\n",
       "       [9.83481228e-01],\n",
       "       [9.51875448e-01],\n",
       "       [6.93504393e-01],\n",
       "       [3.70858252e-01],\n",
       "       [5.39720595e-01],\n",
       "       [4.42536175e-01],\n",
       "       [5.39148375e-02],\n",
       "       [7.88488388e-02],\n",
       "       [9.59024206e-02],\n",
       "       [6.78038895e-01],\n",
       "       [3.10070626e-02],\n",
       "       [3.69610518e-01],\n",
       "       [3.79023343e-01],\n",
       "       [1.09361568e-02],\n",
       "       [9.61801648e-01],\n",
       "       [9.98832047e-01],\n",
       "       [9.91977811e-01],\n",
       "       [4.28720415e-02],\n",
       "       [2.91487992e-01],\n",
       "       [1.19217344e-01],\n",
       "       [3.54581982e-01],\n",
       "       [7.59838223e-01],\n",
       "       [1.50747493e-01],\n",
       "       [2.18489300e-02],\n",
       "       [6.74573705e-02],\n",
       "       [3.57111730e-02],\n",
       "       [4.88645285e-01],\n",
       "       [8.37881304e-03],\n",
       "       [1.88270897e-01],\n",
       "       [3.37530486e-02],\n",
       "       [3.32672864e-01],\n",
       "       [3.44054371e-01],\n",
       "       [3.47001255e-01],\n",
       "       [1.77414283e-01],\n",
       "       [4.81864810e-02],\n",
       "       [3.08378935e-01],\n",
       "       [6.79326430e-02],\n",
       "       [9.96394575e-01],\n",
       "       [8.98914993e-01],\n",
       "       [4.16317761e-01],\n",
       "       [6.35819316e-01],\n",
       "       [2.18350589e-02],\n",
       "       [4.55084980e-01],\n",
       "       [9.91486669e-01],\n",
       "       [7.29719996e-01],\n",
       "       [1.77230224e-01],\n",
       "       [9.77486908e-01],\n",
       "       [1.57151014e-01],\n",
       "       [9.38259840e-01],\n",
       "       [2.86944836e-01],\n",
       "       [2.83901710e-02],\n",
       "       [4.77674395e-01],\n",
       "       [4.30314064e-01],\n",
       "       [9.95364547e-01],\n",
       "       [1.19237497e-01],\n",
       "       [4.85181846e-02],\n",
       "       [7.71583468e-02],\n",
       "       [1.50747493e-01],\n",
       "       [9.98557985e-01],\n",
       "       [2.46128235e-02],\n",
       "       [6.45036280e-01],\n",
       "       [9.66408134e-01],\n",
       "       [7.66115785e-02],\n",
       "       [9.99699354e-01],\n",
       "       [2.93711890e-02],\n",
       "       [3.51149261e-01],\n",
       "       [4.48068269e-02],\n",
       "       [7.59125054e-01],\n",
       "       [8.82600605e-01],\n",
       "       [6.71792477e-02],\n",
       "       [1.36250048e-03],\n",
       "       [2.09280401e-01],\n",
       "       [9.86012518e-01],\n",
       "       [8.14014077e-01],\n",
       "       [1.31084114e-01],\n",
       "       [3.70894223e-01],\n",
       "       [6.37867510e-01],\n",
       "       [2.63636131e-02],\n",
       "       [9.92947221e-01],\n",
       "       [4.34828043e-01],\n",
       "       [9.98284876e-01],\n",
       "       [8.98653150e-01],\n",
       "       [8.28649402e-02],\n",
       "       [3.78864199e-01],\n",
       "       [9.69823450e-02],\n",
       "       [9.22634542e-01],\n",
       "       [7.13694274e-01],\n",
       "       [3.37170690e-01],\n",
       "       [3.73363718e-02],\n",
       "       [2.70602763e-01],\n",
       "       [2.99484301e-02],\n",
       "       [6.01844564e-02],\n",
       "       [1.12429865e-01],\n",
       "       [3.72178763e-01],\n",
       "       [4.60001916e-01],\n",
       "       [1.46700218e-01],\n",
       "       [9.98968244e-01],\n",
       "       [9.82516170e-01],\n",
       "       [2.28138074e-01],\n",
       "       [7.47478485e-01],\n",
       "       [2.30052233e-01],\n",
       "       [3.16291116e-02],\n",
       "       [2.87478596e-01],\n",
       "       [6.27953529e-01],\n",
       "       [1.21567182e-01],\n",
       "       [1.89741626e-01],\n",
       "       [1.54337445e-02],\n",
       "       [4.32743937e-01],\n",
       "       [2.13529030e-03],\n",
       "       [9.42237198e-01],\n",
       "       [9.74100053e-01],\n",
       "       [9.92136121e-01],\n",
       "       [9.66406643e-01],\n",
       "       [7.42754996e-01],\n",
       "       [1.36403412e-01],\n",
       "       [4.84794788e-02],\n",
       "       [6.58627748e-01],\n",
       "       [8.87945354e-01],\n",
       "       [9.98115420e-01],\n",
       "       [3.44821718e-03],\n",
       "       [1.18855603e-01],\n",
       "       [1.31790057e-01],\n",
       "       [9.98672128e-01],\n",
       "       [9.99362886e-01],\n",
       "       [2.38112062e-01],\n",
       "       [1.16938233e-01],\n",
       "       [9.96194839e-01],\n",
       "       [4.48499434e-02],\n",
       "       [3.44155550e-01],\n",
       "       [9.81730819e-01],\n",
       "       [1.11021377e-01],\n",
       "       [3.87243889e-02],\n",
       "       [9.19283271e-01],\n",
       "       [2.35087931e-01],\n",
       "       [3.63961667e-01],\n",
       "       [9.59664941e-01],\n",
       "       [1.60250496e-02],\n",
       "       [4.39813733e-02],\n",
       "       [1.06540089e-02],\n",
       "       [1.79615673e-02],\n",
       "       [1.07601471e-01],\n",
       "       [9.74062622e-01],\n",
       "       [2.01062150e-02],\n",
       "       [3.83690476e-01],\n",
       "       [4.46456164e-01],\n",
       "       [6.50108308e-02],\n",
       "       [2.51486331e-01],\n",
       "       [7.77605399e-02],\n",
       "       [3.23424160e-01],\n",
       "       [9.96765733e-01],\n",
       "       [5.65033734e-01],\n",
       "       [1.11861520e-01],\n",
       "       [1.21300630e-01],\n",
       "       [1.29829124e-01],\n",
       "       [5.93490005e-02],\n",
       "       [6.66119874e-01],\n",
       "       [1.51202213e-02],\n",
       "       [8.76357675e-01],\n",
       "       [7.80533433e-01],\n",
       "       [5.84585011e-01],\n",
       "       [6.25123322e-01],\n",
       "       [7.30663359e-01],\n",
       "       [8.61308947e-02],\n",
       "       [3.00471604e-01],\n",
       "       [3.49065870e-01],\n",
       "       [9.07703459e-01],\n",
       "       [2.07417682e-01],\n",
       "       [2.14259401e-01],\n",
       "       [3.41733813e-01],\n",
       "       [1.35855554e-02],\n",
       "       [9.36447531e-02],\n",
       "       [3.05259377e-01],\n",
       "       [7.63365686e-01],\n",
       "       [1.11774422e-01],\n",
       "       [9.88839567e-01],\n",
       "       [9.01865125e-01],\n",
       "       [7.41114020e-01],\n",
       "       [9.77408648e-01],\n",
       "       [1.15331128e-01],\n",
       "       [6.85176104e-02],\n",
       "       [8.70819628e-01],\n",
       "       [1.77274734e-01],\n",
       "       [2.35322602e-02],\n",
       "       [8.36032853e-02],\n",
       "       [1.47642091e-01],\n",
       "       [1.04049442e-03],\n",
       "       [8.33781064e-01],\n",
       "       [7.70506382e-01],\n",
       "       [8.04159224e-01],\n",
       "       [9.36191678e-01],\n",
       "       [8.00002739e-02],\n",
       "       [1.39661252e-01],\n",
       "       [6.46241128e-01],\n",
       "       [1.32664638e-02],\n",
       "       [2.52469212e-01],\n",
       "       [1.18250988e-01],\n",
       "       [6.32377565e-01],\n",
       "       [5.10140836e-01],\n",
       "       [4.16284092e-02],\n",
       "       [5.00659533e-02],\n",
       "       [4.79572326e-01],\n",
       "       [1.21904254e-01],\n",
       "       [1.13983832e-01],\n",
       "       [1.11402072e-01],\n",
       "       [1.78172559e-01],\n",
       "       [9.98804808e-01],\n",
       "       [9.75483596e-01],\n",
       "       [3.01140994e-01],\n",
       "       [7.82440126e-01],\n",
       "       [9.91029263e-01],\n",
       "       [1.19933649e-03],\n",
       "       [9.56623971e-01],\n",
       "       [2.06910297e-01],\n",
       "       [4.12790000e-01],\n",
       "       [2.24402353e-01],\n",
       "       [8.68175998e-02],\n",
       "       [1.17203251e-01],\n",
       "       [3.02597638e-02],\n",
       "       [6.13887608e-02],\n",
       "       [7.37980902e-02],\n",
       "       [6.88219368e-01],\n",
       "       [2.40662739e-01],\n",
       "       [9.91925180e-01],\n",
       "       [4.65535708e-02],\n",
       "       [6.21783614e-01],\n",
       "       [5.10320902e-01],\n",
       "       [1.42868822e-02],\n",
       "       [4.35353667e-02],\n",
       "       [9.60956812e-01],\n",
       "       [6.45759165e-01],\n",
       "       [9.54837441e-01],\n",
       "       [1.97583511e-01],\n",
       "       [7.60648921e-02],\n",
       "       [3.63337725e-01],\n",
       "       [2.52181023e-01],\n",
       "       [2.97362566e-01],\n",
       "       [9.91029263e-01],\n",
       "       [1.05196955e-02],\n",
       "       [3.55529152e-02],\n",
       "       [1.79945946e-01],\n",
       "       [9.96491373e-01],\n",
       "       [1.75529867e-01],\n",
       "       [4.27292399e-02],\n",
       "       [7.43632913e-01],\n",
       "       [4.89385091e-02],\n",
       "       [2.54465695e-02],\n",
       "       [1.47619978e-01],\n",
       "       [2.00536147e-01],\n",
       "       [1.25806853e-01],\n",
       "       [3.47558796e-01],\n",
       "       [3.27413648e-01],\n",
       "       [1.64989337e-01],\n",
       "       [7.39339516e-02],\n",
       "       [3.29550624e-01],\n",
       "       [1.62231028e-02],\n",
       "       [9.48475897e-01],\n",
       "       [7.89488673e-01],\n",
       "       [4.74191010e-01],\n",
       "       [2.95630004e-02],\n",
       "       [2.43975855e-02],\n",
       "       [9.79581952e-01],\n",
       "       [5.89779377e-01],\n",
       "       [9.99560535e-01],\n",
       "       [2.40542114e-01],\n",
       "       [8.65455270e-01],\n",
       "       [1.07750162e-01],\n",
       "       [5.41548252e-01],\n",
       "       [6.48874521e-01],\n",
       "       [1.96261071e-02],\n",
       "       [9.69515502e-01],\n",
       "       [9.18001384e-02],\n",
       "       [4.96749818e-01],\n",
       "       [9.98268485e-01],\n",
       "       [1.41690925e-01],\n",
       "       [2.49959528e-02],\n",
       "       [2.73040205e-01],\n",
       "       [1.18169170e-02],\n",
       "       [4.35602665e-01],\n",
       "       [9.99760807e-01],\n",
       "       [2.04206467e-01],\n",
       "       [9.37744796e-01],\n",
       "       [2.26234242e-01],\n",
       "       [7.55456626e-01],\n",
       "       [2.04490587e-01],\n",
       "       [2.60708570e-01],\n",
       "       [1.53374979e-02],\n",
       "       [6.32206261e-01],\n",
       "       [1.27956076e-02],\n",
       "       [1.85207382e-01],\n",
       "       [9.38673317e-01],\n",
       "       [9.37039673e-01],\n",
       "       [9.93763745e-01],\n",
       "       [7.08899975e-01],\n",
       "       [4.23820764e-02],\n",
       "       [2.72319645e-01],\n",
       "       [1.18507529e-02],\n",
       "       [4.38546568e-01],\n",
       "       [3.20300937e-01],\n",
       "       [8.81255448e-01],\n",
       "       [2.89903246e-02],\n",
       "       [7.71995783e-01],\n",
       "       [8.03066850e-01],\n",
       "       [2.13873461e-01],\n",
       "       [2.01355413e-01],\n",
       "       [2.14259401e-01],\n",
       "       [1.82035774e-01],\n",
       "       [3.77959132e-01],\n",
       "       [6.07821941e-01],\n",
       "       [9.98237610e-01],\n",
       "       [6.23056404e-02],\n",
       "       [6.02434948e-03],\n",
       "       [1.63786709e-02],\n",
       "       [2.20210239e-01],\n",
       "       [2.02704191e-01],\n",
       "       [2.15616245e-02],\n",
       "       [7.94970393e-01],\n",
       "       [8.45309570e-02],\n",
       "       [1.72636822e-01],\n",
       "       [1.83013335e-01],\n",
       "       [2.16950774e-01],\n",
       "       [9.08573925e-01],\n",
       "       [1.26371175e-01],\n",
       "       [4.43370402e-01],\n",
       "       [2.82726288e-01],\n",
       "       [9.76039004e-03],\n",
       "       [7.87804499e-02],\n",
       "       [9.99719918e-01],\n",
       "       [8.05045605e-01],\n",
       "       [3.37407319e-03],\n",
       "       [3.05658937e-01],\n",
       "       [1.58841833e-01],\n",
       "       [5.77875115e-02],\n",
       "       [8.65101337e-01],\n",
       "       [4.72380698e-01],\n",
       "       [5.66359043e-01],\n",
       "       [3.85143816e-01],\n",
       "       [1.84337676e-01],\n",
       "       [5.93306303e-01],\n",
       "       [1.30788118e-01],\n",
       "       [3.98542807e-02],\n",
       "       [8.77737641e-01],\n",
       "       [1.41442746e-01],\n",
       "       [3.35699975e-01],\n",
       "       [9.73060191e-01],\n",
       "       [2.51125425e-01],\n",
       "       [3.70149195e-01],\n",
       "       [1.04049442e-03],\n",
       "       [3.06288958e-01],\n",
       "       [8.20915103e-01],\n",
       "       [9.99699354e-01],\n",
       "       [6.26633108e-01],\n",
       "       [4.12560180e-02],\n",
       "       [9.89730954e-01],\n",
       "       [4.08549607e-01],\n",
       "       [8.69092345e-01],\n",
       "       [4.08549607e-01],\n",
       "       [9.91512716e-01],\n",
       "       [9.29732900e-03],\n",
       "       [3.94810200e-01],\n",
       "       [8.91894102e-02],\n",
       "       [9.68830824e-01],\n",
       "       [1.74711153e-01],\n",
       "       [4.09929931e-01],\n",
       "       [4.88923788e-02],\n",
       "       [3.05164635e-01],\n",
       "       [1.02053657e-01],\n",
       "       [1.94128025e-02],\n",
       "       [2.07851246e-01],\n",
       "       [5.27910404e-02],\n",
       "       [8.70801434e-02],\n",
       "       [8.13497245e-01],\n",
       "       [2.23539397e-02],\n",
       "       [1.16044194e-01],\n",
       "       [2.68969126e-02],\n",
       "       [1.17756007e-02],\n",
       "       [1.34689331e-01],\n",
       "       [5.94119132e-01],\n",
       "       [5.49082942e-02],\n",
       "       [5.27169466e-01],\n",
       "       [1.10861585e-01],\n",
       "       [2.04875782e-01],\n",
       "       [8.69093895e-01],\n",
       "       [1.48694918e-01],\n",
       "       [3.12254839e-02],\n",
       "       [4.96484563e-02],\n",
       "       [5.48474677e-03],\n",
       "       [9.86709118e-01],\n",
       "       [1.17756007e-02],\n",
       "       [2.94474602e-01],\n",
       "       [9.94120419e-01],\n",
       "       [9.92605090e-01],\n",
       "       [9.97261286e-01],\n",
       "       [9.99890685e-01],\n",
       "       [9.99442518e-01],\n",
       "       [1.63852125e-01],\n",
       "       [7.27827325e-02],\n",
       "       [2.33007416e-01],\n",
       "       [4.81435150e-01],\n",
       "       [9.95997906e-01],\n",
       "       [5.62436640e-01],\n",
       "       [2.20853299e-01],\n",
       "       [4.82174516e-01],\n",
       "       [6.90809846e-01],\n",
       "       [2.53899060e-02],\n",
       "       [5.01993252e-03],\n",
       "       [8.04591477e-02],\n",
       "       [3.46821636e-01],\n",
       "       [6.53999858e-03],\n",
       "       [7.20892176e-02],\n",
       "       [3.40280771e-01],\n",
       "       [9.87865150e-01],\n",
       "       [2.22274493e-02],\n",
       "       [9.15550411e-01],\n",
       "       [6.97245836e-01],\n",
       "       [8.41273367e-02],\n",
       "       [2.90419638e-01],\n",
       "       [9.44211408e-02],\n",
       "       [7.68646598e-01],\n",
       "       [4.03922766e-01],\n",
       "       [8.56062956e-03]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30236813], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a single prediction\n",
    "model_1_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30236813],\n",
       "       [0.7474785 ],\n",
       "       [0.9977717 ],\n",
       "       [0.10983786],\n",
       "       [0.11964072],\n",
       "       [0.9299731 ],\n",
       "       [0.88970995],\n",
       "       [0.99209493],\n",
       "       [0.9633637 ],\n",
       "       [0.29024544]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 10\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model prediction probabilities to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.00262467191601,\n",
       " 'precision': 0.7975156487081627,\n",
       " 'recall': 0.7900262467191601,\n",
       " 'f1-score': 0.7863113264688066}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model_1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing learned embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0450073   0.00656272  0.03699991 ... -0.00481941 -0.05943283\n",
      "  -0.03213095]\n",
      " [-0.01241818 -0.01980377  0.03326921 ... -0.00221783  0.0106469\n",
      "  -0.02488378]\n",
      " [-0.01944665  0.04438812  0.05942794 ...  0.01355892 -0.05955082\n",
      "   0.06507559]\n",
      " ...\n",
      " [ 0.02852719 -0.01534789  0.0049188  ...  0.00807668  0.03450284\n",
      "  -0.04139275]\n",
      " [-0.05767578  0.0724211   0.01994244 ...  0.0107463  -0.08523721\n",
      "   0.06789196]\n",
      " [-0.03806192  0.10335895  0.04989688 ...  0.06572568 -0.10596616\n",
      "   0.05568728]]\n",
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# (these are the numerical representations of each token in our training data, which have been learned for 5 epochs)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "print(embed_weights)\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
    "\n",
    "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
    "\n",
    "And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the files above we can visualize them using http://projector.tensorflow.org/ and clicking the \"load\" button on  the left hand side.\n",
    "\n",
    "> 📖 **Ressource:** If you'd like to know more about embeddings, I'd encourage you to check out:\n",
    "* Jay Alammar's visualized word2vec post: https://jalammar.github.io/illustrated-word2vec/\n",
    "* TensorFlow's Word Embeddings guide: https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "RNN's are useful for sequence data.\n",
    "\n",
    "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
    "\n",
    "> 📖 **Ressources:** If you want an overview of the internals of a recurrent neural network, see the following:\n",
    " - MIT's sequence modell lecture: https://youtu.be/qjrad0V0uJE\n",
    " - Chris Olag's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    " - Andrej Kaparthy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM\n",
    "LSTM  = long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "Our structure of an RNN typically looks like this:\n",
    "```Input(text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1, ), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 15, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,366,657\n",
      "Trainable params: 1,366,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the nmodel\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220710-130419\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 16s 14ms/step - loss: 0.2300 - accuracy: 0.9177 - val_loss: 0.5430 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1520 - accuracy: 0.9450 - val_loss: 0.6387 - val_accuracy: 0.7927\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1279 - accuracy: 0.9524 - val_loss: 0.6485 - val_accuracy: 0.7808\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1070 - accuracy: 0.9602 - val_loss: 0.8415 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0845 - accuracy: 0.9653 - val_loss: 1.2340 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "histor_model_2 = model_2.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6423762e-04],\n",
       "       [4.7330874e-01],\n",
       "       [9.9996972e-01],\n",
       "       [1.0294931e-02],\n",
       "       [2.8183906e-05],\n",
       "       [9.9971503e-01],\n",
       "       [9.6708542e-01],\n",
       "       [9.9998343e-01],\n",
       "       [9.9996209e-01],\n",
       "       [7.5623459e-01]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 2 pred probs to labels\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7786304709648849,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1-score': 0.7711035650901983}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63418e73e250c304d26eaf03185e2f59ff2277f62dd1cc8bba54019c2c46cc60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
