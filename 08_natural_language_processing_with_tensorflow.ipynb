{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP fundamentals in TensorFlow\n",
    "\n",
    "NLP has the goal of deriving information out of natural language (could be sequences of text or speech).\n",
    "\n",
    "Another common term for NLP problem is sequence to sequence problems (seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 12 07:01:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.59       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   49C    P8    18W /  N/A |    955MiB /  6144MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1960    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      4656    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      5808    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      6784    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     10140    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     10156    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13248    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     14192    C+G   ...obeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     15156    C+G   ...signal-desktop\\Signal.exe    N/A      |\n",
      "|    0   N/A  N/A     15756    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     17012    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     18064    C+G   ...4__htrsf667h5kn2\\AWCC.exe    N/A      |\n",
      "|    0   N/A  N/A     19628    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     20088    C+G   ... iCUE 4 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A     20380    C+G   ...lication\\WebCompanion.exe    N/A      |\n",
      "|    0   N/A  N/A     21248    C+G   ...ropbox\\Client\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     21312    C+G   ...264.49\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     24480    C+G   ...batNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     24628    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-2349283b-d8c3-574d-bb05-0097332584c3)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"helper_functions.py\"):\n",
    "    !python -m wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a text dataset\n",
    "\n",
    "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster).\n",
    "\n",
    "See the original source: https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"nlp_getting_started.zip\"):\n",
    "    !python -m wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
    "unzip_data(\"C:/Selbststudium/Udemy/Udemy_TensorFlow_Certificate/nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a text dataset\n",
    "\n",
    "To visualize our text samples, we first have to read them in , one way to do so would be to use Python: https://realpython.com/read-write-files-python/ \n",
    "\n",
    "But i prefer to get visual straight away.\n",
    "\n",
    "So another way to do this is to use pandes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Forest fire near La Ronge Sask. Canada', 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"][1], train_df[\"target\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does the test dataframe look like?\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples?\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text: @MistressPip I'm amazed you have not been inundated mistress.\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text: [GPV Wind] As of 06JST 6AUG: WNW 06JST 6AUG / E 12JST 6AUG / S 18JST 6AUG. http://t.co/l6jBjAj8dm\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text: APC Chieftain Tasks Dickson On N15b Floods Donation To Bayelsa http://t.co/LqGOe7psXp\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text: Saving the City in Old Town: The Proposed Demolition of 159 West Burton http://t.co/FJddx43Ewj @MessnerMatthew for @newcity\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text: POTUS appoints Brig. Gen. Richard G. Kaiser as member of the Mississippi River Commission. Learn more about the MRC: http://t.co/vdUKcV7YJy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # Create random indexes not higher than the total number\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split training data into training and validation sets \n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 762, 6851, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cnverting text into numbers\n",
    "\n",
    "When dealing with a text problem, one of the first thing you'll have to do before you can build a model is to convert your text to numbers. \n",
    "\n",
    "There are a few ways to do this, namely:\n",
    "* Tokenization - direct mapping of token (a token could be a word or a character)\n",
    "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet'], 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0].split(), len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokes (words) in the training tweets\n",
    "max_length = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization parameters\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    standardize=\"lower_and_strip_punctuation\", # Default\n",
    "    split=\"whitespace\", # Default\n",
    "    ngrams=None, # Default\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    "    pad_to_max_tokens=True) # Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Top link: Reddit's new content policy goes into effect many horrible subreddits banned or quarantined http://t.co/o8XvTLP4mF\n",
      "    Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 212, 1074,  878,   50,  226,  595,  512,   66,  780,  123,  395,\n",
       "         918,  793,   53,  433]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\n\\\n",
    "    Vectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an EmbeddingLayer\n",
    "\n",
    "To make our embedding, we're going to use TensorFlow's EmbeddingLayer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "\n",
    "The parameters we care most about for our embedding layer: \n",
    "* `input_dim` = the size of our vocabulary\n",
    "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each tolen gets represented by a vector 100 long\n",
    "* `input_length` = length of the sequences being passed to the embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1943ed0e6a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Paul Craig Roberts ÛÒ Vladimir Putin Issues Major Warning But Is It Too Late To Escape A http://t.co/NVfKzv5FEx #brics #roberts #russia    \n",
      "Embedded version: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.04891973,  0.04736659, -0.03571372, ...,  0.02649527,\n",
       "         -0.02896649,  0.02546373],\n",
       "        [ 0.01254879, -0.00744461, -0.02050283, ...,  0.01598382,\n",
       "          0.01984534,  0.02964808],\n",
       "        [ 0.0107003 , -0.04386288, -0.0295881 , ...,  0.0267735 ,\n",
       "         -0.02421486,  0.04811308],\n",
       "        ...,\n",
       "        [ 0.00535109, -0.01134799,  0.02069268, ..., -0.03748838,\n",
       "          0.00892508,  0.03023869],\n",
       "        [-0.00036003, -0.02903252, -0.03873315, ...,  0.04375435,\n",
       "         -0.0243019 ,  0.03859427],\n",
       "        [-0.04920788,  0.01116934, -0.03242011, ..., -0.03320735,\n",
       "         -0.00565697,  0.00040314]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "    \\nEmbedded version: \")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 4.8919726e-02,  4.7366593e-02, -3.5713721e-02, -3.8636971e-02,\n",
       "         1.0832977e-02,  4.4510849e-03,  4.7425199e-02,  2.0172130e-02,\n",
       "        -1.2726046e-02, -4.4271328e-02, -3.0293489e-02,  1.1286199e-02,\n",
       "        -6.2276833e-03, -1.3142936e-03,  4.8652019e-02, -3.2233894e-02,\n",
       "         4.6658549e-02,  1.4312986e-02, -3.6838733e-02,  1.7869603e-02,\n",
       "        -2.1557689e-02, -6.5167546e-03,  3.4328703e-02,  2.1289479e-02,\n",
       "         9.6921809e-03, -2.9338038e-02, -1.0357998e-02, -4.3938436e-02,\n",
       "        -1.5208472e-02,  1.9760240e-02, -4.0905632e-02, -8.8608153e-03,\n",
       "        -4.2070746e-03, -3.8174856e-02,  3.0935142e-02,  9.4338544e-03,\n",
       "         4.3139346e-03,  1.5246283e-02,  4.3030288e-02, -1.6224276e-02,\n",
       "         3.6810044e-02, -2.5422847e-02,  4.8510376e-02, -7.5422227e-05,\n",
       "        -1.1930991e-02, -1.1389565e-02,  2.7467553e-02, -2.4855435e-02,\n",
       "        -3.4005262e-02,  2.3005534e-02,  2.3369107e-02,  1.5406821e-02,\n",
       "         1.4387790e-02, -3.1217821e-03,  1.7204773e-02, -2.9740632e-02,\n",
       "         2.8064441e-02, -1.1241663e-02, -2.4740040e-02,  4.0197019e-02,\n",
       "         2.5245275e-02,  3.3543002e-02,  3.1701472e-02,  1.9209649e-02,\n",
       "         2.8987359e-02,  1.7396990e-02, -4.2450465e-02, -4.5783341e-02,\n",
       "         3.9694075e-02, -1.7485715e-02, -4.9214032e-02, -3.7807308e-02,\n",
       "         3.3864509e-02,  4.3665353e-02,  1.0945547e-02, -3.2006431e-02,\n",
       "         3.2926392e-02,  3.2644656e-02,  4.4188190e-02, -3.2712460e-02,\n",
       "        -2.7436007e-02, -2.0005321e-02,  2.0691369e-02, -8.0526359e-03,\n",
       "        -8.1212632e-03, -4.1964423e-02, -1.5560269e-02,  1.2516048e-02,\n",
       "        -1.3996564e-02, -1.3874222e-02,  3.1699691e-02,  7.0806034e-03,\n",
       "        -1.7211661e-03, -3.2502316e-02, -4.0990949e-02,  3.2492150e-02,\n",
       "        -2.9116809e-02,  2.0077590e-02, -2.2131933e-02, -3.8124621e-02,\n",
       "         9.2735179e-03, -4.1914023e-02,  2.0549845e-02, -6.1106682e-04,\n",
       "        -5.4582469e-03,  1.2399245e-02, -2.6288439e-02,  1.9422043e-02,\n",
       "        -1.6463913e-02, -1.2811113e-02,  4.0707778e-02, -2.0332182e-02,\n",
       "         4.1916121e-02,  4.3944787e-02, -3.2990351e-03, -3.8894616e-02,\n",
       "        -2.2620559e-02, -1.9168699e-02, -1.5108958e-03, -4.4507362e-02,\n",
       "         3.7013497e-02, -4.8489321e-02, -2.9267704e-02,  4.1598082e-03,\n",
       "        -1.5899409e-02,  2.6495267e-02, -2.8966486e-02,  2.5463734e-02],\n",
       "       dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'Paul Craig Roberts \\x89ÛÒ Vladimir Putin Issues Major Warning But Is It Too Late To Escape A http://t.co/NVfKzv5FEx #brics #roberts #russia')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "Now we've got a way to turn our text sequences into numbers, it's time  to start building a series of modelling experiments.\n",
    "\n",
    "We'll start with a baseline and move on from there.\n",
    "\n",
    "* Model 0: Naive Bayes (baseline), from sklearn ML map: \n",
    "* Model 1: Feed-forward neural network (dense model)\n",
    "* Model 2: LSTM (RNN)\n",
    "* Model 3: GRU (RNN) \n",
    "* Model 4: Bidirectional-LSTM model (RNN)\n",
    "* Model 5: 1D Convolutional Network (CNN)\n",
    "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
    "* Model 7: Same as model 6 with 10% of training data\n",
    "\n",
    "How are we going to approach all of these?\n",
    "\n",
    "Use the standard steps in modelling with tensorflow:\n",
    "* Create a model\n",
    "* Build the model\n",
    "* Fit the model\n",
    "* Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline\n",
    "\n",
    "As with all machine learning modelling experiments it's important to create a baseline model so you've got a benchmark for future experiments to build uopn.\n",
    "\n",
    "To create our baseline, we'll use Sklearn's Mulinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
    "\n",
    "> 🔑 **Note:** It's common to use non DL-algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([ # Pipeline is similar to tensorflow's sequential\n",
    "    (\"tfidf\", TfidfVectorizer()), # name of the step is \"tfidf\"; convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()), # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "We could evaluate all of our model's predictions with different metrics every time, however this will be cumbersome and could easily be fixed with a function.\n",
    "\n",
    "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score\n",
    "\n",
    "For a deep overview of many different methods, see the Sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate accuracy, precision, reall and f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binare classification model.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1-score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _, = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy, \n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall, \n",
    "        \"f1-score\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensorboard callback (Need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save tensorboard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220712-070132\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 6ms/step - loss: 0.6102 - accuracy: 0.6929 - val_loss: 0.5344 - val_accuracy: 0.7598\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8156 - val_loss: 0.4709 - val_accuracy: 0.7874\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3471 - accuracy: 0.8626 - val_loss: 0.4603 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2841 - accuracy: 0.8911 - val_loss: 0.4648 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2369 - accuracy: 0.9121 - val_loss: 0.4800 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 79.26509186351706,\n",
       "  'precision': 0.8111390004213173,\n",
       "  'recall': 0.7926509186351706,\n",
       "  'f1-score': 0.7862189758049549},)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4800204038619995, 0.7887139320373535]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.26800764e-01],\n",
       "       [7.53424823e-01],\n",
       "       [9.97852206e-01],\n",
       "       [8.49002600e-02],\n",
       "       [1.01164453e-01],\n",
       "       [9.30915058e-01],\n",
       "       [9.22577500e-01],\n",
       "       [9.93345499e-01],\n",
       "       [9.67820883e-01],\n",
       "       [2.11431876e-01],\n",
       "       [1.13343917e-01],\n",
       "       [6.57970846e-01],\n",
       "       [4.44574840e-02],\n",
       "       [2.09898397e-01],\n",
       "       [5.04573481e-03],\n",
       "       [1.13284126e-01],\n",
       "       [2.60618776e-02],\n",
       "       [8.25275853e-02],\n",
       "       [1.87564194e-01],\n",
       "       [4.99211848e-01],\n",
       "       [9.04086888e-01],\n",
       "       [4.20053005e-02],\n",
       "       [3.97532195e-01],\n",
       "       [7.81666562e-02],\n",
       "       [9.61529434e-01],\n",
       "       [9.98942435e-01],\n",
       "       [2.86790766e-02],\n",
       "       [6.27055243e-02],\n",
       "       [2.45401524e-02],\n",
       "       [2.15850443e-01],\n",
       "       [4.89037335e-01],\n",
       "       [2.30490252e-01],\n",
       "       [4.77458566e-01],\n",
       "       [1.71117097e-01],\n",
       "       [4.66904610e-01],\n",
       "       [5.78024574e-02],\n",
       "       [9.93622720e-01],\n",
       "       [1.25244826e-01],\n",
       "       [3.46464291e-02],\n",
       "       [9.98710155e-01],\n",
       "       [1.69856936e-01],\n",
       "       [2.21880469e-02],\n",
       "       [3.76212388e-01],\n",
       "       [4.75381911e-02],\n",
       "       [6.67085767e-01],\n",
       "       [9.75802839e-01],\n",
       "       [2.45976061e-01],\n",
       "       [9.14355159e-01],\n",
       "       [1.96689516e-01],\n",
       "       [6.21989727e-01],\n",
       "       [6.63758814e-02],\n",
       "       [5.03921390e-01],\n",
       "       [4.11044836e-01],\n",
       "       [2.93533634e-02],\n",
       "       [1.14540264e-01],\n",
       "       [2.83052213e-02],\n",
       "       [2.04294056e-01],\n",
       "       [9.64177310e-01],\n",
       "       [8.96956250e-02],\n",
       "       [2.88540311e-03],\n",
       "       [1.08429879e-01],\n",
       "       [9.56712604e-01],\n",
       "       [9.08433080e-01],\n",
       "       [1.27409980e-01],\n",
       "       [9.28005278e-01],\n",
       "       [9.75662768e-01],\n",
       "       [7.15501964e-01],\n",
       "       [3.69471043e-01],\n",
       "       [1.28531054e-01],\n",
       "       [1.15226030e-01],\n",
       "       [8.85333046e-02],\n",
       "       [3.11246794e-02],\n",
       "       [9.44953263e-01],\n",
       "       [1.17214181e-01],\n",
       "       [9.15522724e-02],\n",
       "       [3.69845569e-01],\n",
       "       [3.34818125e-01],\n",
       "       [8.17677557e-01],\n",
       "       [2.07015187e-01],\n",
       "       [5.88400543e-01],\n",
       "       [3.90720934e-01],\n",
       "       [2.27761149e-01],\n",
       "       [9.95991170e-01],\n",
       "       [1.01519115e-01],\n",
       "       [1.42067090e-01],\n",
       "       [9.21002626e-02],\n",
       "       [1.68117769e-02],\n",
       "       [9.50958431e-02],\n",
       "       [5.92171073e-01],\n",
       "       [8.86711001e-01],\n",
       "       [9.90884006e-01],\n",
       "       [8.79878271e-03],\n",
       "       [6.03420675e-01],\n",
       "       [2.61743609e-02],\n",
       "       [9.83644962e-01],\n",
       "       [7.42161214e-01],\n",
       "       [8.45081449e-01],\n",
       "       [9.71279085e-01],\n",
       "       [8.59539986e-01],\n",
       "       [9.65412259e-01],\n",
       "       [9.99253452e-01],\n",
       "       [1.65878847e-01],\n",
       "       [1.12506486e-02],\n",
       "       [9.22858357e-01],\n",
       "       [8.60290706e-01],\n",
       "       [6.82943389e-02],\n",
       "       [8.70707691e-01],\n",
       "       [9.75135505e-01],\n",
       "       [5.45786768e-02],\n",
       "       [3.78950864e-01],\n",
       "       [7.06016898e-01],\n",
       "       [4.04491574e-02],\n",
       "       [2.24498898e-01],\n",
       "       [1.52042881e-01],\n",
       "       [1.58082411e-01],\n",
       "       [4.49397564e-01],\n",
       "       [4.67651635e-01],\n",
       "       [7.15707242e-01],\n",
       "       [6.99408948e-01],\n",
       "       [8.75007510e-02],\n",
       "       [9.99707043e-01],\n",
       "       [8.95030871e-02],\n",
       "       [1.38170734e-01],\n",
       "       [8.06094885e-01],\n",
       "       [3.75628591e-01],\n",
       "       [2.14036837e-01],\n",
       "       [8.36285055e-01],\n",
       "       [1.19950874e-02],\n",
       "       [5.74824139e-02],\n",
       "       [7.07337677e-01],\n",
       "       [7.98299983e-02],\n",
       "       [9.99707043e-01],\n",
       "       [9.99816120e-01],\n",
       "       [9.98942435e-01],\n",
       "       [9.75993216e-01],\n",
       "       [9.07582268e-02],\n",
       "       [9.67126191e-01],\n",
       "       [1.73460528e-01],\n",
       "       [2.93072581e-01],\n",
       "       [7.87735879e-02],\n",
       "       [9.96504068e-01],\n",
       "       [2.60016263e-01],\n",
       "       [2.09898397e-01],\n",
       "       [9.56346989e-01],\n",
       "       [1.96831003e-01],\n",
       "       [6.14208758e-01],\n",
       "       [4.58279662e-02],\n",
       "       [1.04316548e-02],\n",
       "       [2.30389580e-01],\n",
       "       [9.79083359e-01],\n",
       "       [2.49001220e-01],\n",
       "       [6.37254342e-02],\n",
       "       [3.74757439e-01],\n",
       "       [1.67554438e-01],\n",
       "       [2.54611135e-01],\n",
       "       [9.92090344e-01],\n",
       "       [7.59537935e-01],\n",
       "       [4.34780061e-01],\n",
       "       [9.87549543e-01],\n",
       "       [1.56847406e-02],\n",
       "       [9.77191746e-01],\n",
       "       [5.92498295e-02],\n",
       "       [2.46560335e-01],\n",
       "       [9.92224455e-01],\n",
       "       [2.01189861e-01],\n",
       "       [6.55280873e-02],\n",
       "       [9.98530149e-01],\n",
       "       [2.35973611e-01],\n",
       "       [9.80181754e-01],\n",
       "       [1.99491635e-01],\n",
       "       [9.93643641e-01],\n",
       "       [8.39758515e-01],\n",
       "       [8.22831392e-01],\n",
       "       [2.99653970e-02],\n",
       "       [9.98011947e-01],\n",
       "       [5.75108640e-02],\n",
       "       [3.71874750e-01],\n",
       "       [4.75901753e-01],\n",
       "       [7.56888449e-01],\n",
       "       [9.94238019e-01],\n",
       "       [1.49696749e-02],\n",
       "       [8.43303680e-01],\n",
       "       [7.32583344e-01],\n",
       "       [9.64224756e-01],\n",
       "       [9.73850250e-01],\n",
       "       [4.36555773e-01],\n",
       "       [8.00962672e-02],\n",
       "       [9.99517798e-01],\n",
       "       [1.36982361e-02],\n",
       "       [3.28268483e-02],\n",
       "       [9.73408893e-02],\n",
       "       [9.14299667e-01],\n",
       "       [8.24982971e-02],\n",
       "       [2.11133972e-01],\n",
       "       [1.59444362e-02],\n",
       "       [9.14358497e-02],\n",
       "       [4.25236113e-02],\n",
       "       [2.08540037e-01],\n",
       "       [7.34287620e-01],\n",
       "       [7.67553225e-02],\n",
       "       [2.06724107e-01],\n",
       "       [8.57760608e-01],\n",
       "       [9.73443210e-01],\n",
       "       [3.41832608e-01],\n",
       "       [1.08693399e-01],\n",
       "       [9.99809563e-01],\n",
       "       [5.45038640e-01],\n",
       "       [9.46599782e-01],\n",
       "       [6.48625016e-01],\n",
       "       [8.22229862e-01],\n",
       "       [3.11332136e-01],\n",
       "       [9.79705036e-01],\n",
       "       [1.82995722e-02],\n",
       "       [1.97713703e-01],\n",
       "       [6.60919119e-03],\n",
       "       [4.15246608e-03],\n",
       "       [9.57270145e-01],\n",
       "       [7.99166441e-01],\n",
       "       [8.98407400e-01],\n",
       "       [1.46900848e-01],\n",
       "       [7.57013142e-01],\n",
       "       [8.84432271e-02],\n",
       "       [2.54479069e-02],\n",
       "       [1.47980645e-01],\n",
       "       [9.78033602e-01],\n",
       "       [2.11996749e-01],\n",
       "       [5.26250601e-01],\n",
       "       [9.95550156e-01],\n",
       "       [5.42074025e-01],\n",
       "       [5.94294965e-01],\n",
       "       [8.45532566e-02],\n",
       "       [2.08927423e-01],\n",
       "       [7.92614520e-01],\n",
       "       [2.01039329e-01],\n",
       "       [4.50813413e-01],\n",
       "       [1.22005045e-01],\n",
       "       [5.71735442e-01],\n",
       "       [3.80625904e-01],\n",
       "       [1.47939071e-01],\n",
       "       [7.01943785e-02],\n",
       "       [3.86892021e-01],\n",
       "       [2.47605681e-01],\n",
       "       [9.99815285e-01],\n",
       "       [9.84889567e-01],\n",
       "       [6.64506927e-02],\n",
       "       [2.08693221e-02],\n",
       "       [8.66821706e-01],\n",
       "       [9.36959013e-02],\n",
       "       [6.75303563e-02],\n",
       "       [4.18060154e-01],\n",
       "       [3.47642861e-02],\n",
       "       [5.81124663e-01],\n",
       "       [7.59235234e-04],\n",
       "       [4.39060122e-01],\n",
       "       [9.17106271e-01],\n",
       "       [1.85339540e-01],\n",
       "       [9.74745691e-01],\n",
       "       [9.98911500e-01],\n",
       "       [3.16431165e-01],\n",
       "       [1.55221149e-01],\n",
       "       [3.73029560e-01],\n",
       "       [3.67382355e-02],\n",
       "       [5.04565053e-03],\n",
       "       [9.83233869e-01],\n",
       "       [9.68549371e-01],\n",
       "       [6.75180852e-01],\n",
       "       [9.48412061e-01],\n",
       "       [6.57399967e-02],\n",
       "       [1.61039144e-01],\n",
       "       [8.12992826e-03],\n",
       "       [1.37594074e-01],\n",
       "       [4.24480364e-02],\n",
       "       [9.57817435e-01],\n",
       "       [7.90504366e-02],\n",
       "       [8.74384213e-03],\n",
       "       [9.70066905e-01],\n",
       "       [1.25177903e-02],\n",
       "       [1.07029483e-01],\n",
       "       [9.82895017e-01],\n",
       "       [5.20113707e-02],\n",
       "       [8.06338862e-02],\n",
       "       [8.08820315e-03],\n",
       "       [9.66695309e-01],\n",
       "       [6.06150448e-01],\n",
       "       [7.19668210e-01],\n",
       "       [6.44602895e-01],\n",
       "       [5.58754206e-01],\n",
       "       [6.81980029e-02],\n",
       "       [9.34753537e-01],\n",
       "       [4.38381992e-02],\n",
       "       [7.61698782e-01],\n",
       "       [4.24031138e-01],\n",
       "       [3.52684408e-01],\n",
       "       [4.08617169e-01],\n",
       "       [1.71771109e-01],\n",
       "       [7.05067992e-01],\n",
       "       [2.56606340e-01],\n",
       "       [6.85148478e-01],\n",
       "       [1.44141942e-01],\n",
       "       [7.90907323e-01],\n",
       "       [3.59146148e-02],\n",
       "       [7.30446503e-02],\n",
       "       [2.25246340e-01],\n",
       "       [9.82484996e-01],\n",
       "       [1.53023928e-01],\n",
       "       [7.74348229e-02],\n",
       "       [3.00035506e-01],\n",
       "       [1.62408188e-01],\n",
       "       [1.17944047e-01],\n",
       "       [2.32475549e-02],\n",
       "       [2.94182468e-02],\n",
       "       [9.79454100e-01],\n",
       "       [2.85620242e-01],\n",
       "       [3.12835902e-01],\n",
       "       [9.99805748e-01],\n",
       "       [4.89045642e-02],\n",
       "       [6.06564105e-01],\n",
       "       [2.08401173e-01],\n",
       "       [4.89372313e-02],\n",
       "       [1.23544700e-01],\n",
       "       [2.00851381e-01],\n",
       "       [9.60554406e-02],\n",
       "       [9.11576211e-01],\n",
       "       [2.76119232e-01],\n",
       "       [9.84837353e-01],\n",
       "       [1.01937361e-01],\n",
       "       [1.62394959e-02],\n",
       "       [9.94684756e-01],\n",
       "       [2.11177971e-02],\n",
       "       [9.95964527e-01],\n",
       "       [1.62986755e-01],\n",
       "       [2.86239553e-02],\n",
       "       [9.53184724e-01],\n",
       "       [4.64215837e-02],\n",
       "       [3.05264015e-02],\n",
       "       [9.77069557e-01],\n",
       "       [5.24880597e-03],\n",
       "       [1.92523494e-01],\n",
       "       [7.74565518e-01],\n",
       "       [9.20732021e-01],\n",
       "       [5.69793256e-03],\n",
       "       [1.84836954e-01],\n",
       "       [9.80407417e-01],\n",
       "       [9.66858447e-01],\n",
       "       [7.27892160e-01],\n",
       "       [3.76758516e-01],\n",
       "       [5.83948135e-01],\n",
       "       [4.08020824e-01],\n",
       "       [4.20076251e-02],\n",
       "       [7.72255510e-02],\n",
       "       [6.87959641e-02],\n",
       "       [6.78199112e-01],\n",
       "       [3.66618112e-02],\n",
       "       [3.71199429e-01],\n",
       "       [3.74596328e-01],\n",
       "       [1.23083657e-02],\n",
       "       [9.55869675e-01],\n",
       "       [9.98942435e-01],\n",
       "       [9.93126750e-01],\n",
       "       [3.06553263e-02],\n",
       "       [2.38874346e-01],\n",
       "       [1.36751786e-01],\n",
       "       [3.89479578e-01],\n",
       "       [8.02155852e-01],\n",
       "       [1.59446627e-01],\n",
       "       [1.50385033e-02],\n",
       "       [5.50479367e-02],\n",
       "       [3.60807329e-02],\n",
       "       [5.08503139e-01],\n",
       "       [1.10529307e-02],\n",
       "       [1.75749958e-01],\n",
       "       [3.62177603e-02],\n",
       "       [3.32016110e-01],\n",
       "       [3.57899696e-01],\n",
       "       [2.88692206e-01],\n",
       "       [1.41348213e-01],\n",
       "       [5.26498966e-02],\n",
       "       [3.93258125e-01],\n",
       "       [9.75805670e-02],\n",
       "       [9.97369170e-01],\n",
       "       [9.06148672e-01],\n",
       "       [3.49945217e-01],\n",
       "       [5.77417493e-01],\n",
       "       [1.83850024e-02],\n",
       "       [4.41151291e-01],\n",
       "       [9.90083098e-01],\n",
       "       [7.51607597e-01],\n",
       "       [1.79348350e-01],\n",
       "       [9.77603018e-01],\n",
       "       [1.69800594e-01],\n",
       "       [9.47302938e-01],\n",
       "       [2.98839182e-01],\n",
       "       [2.62778923e-02],\n",
       "       [5.28761744e-01],\n",
       "       [3.99227500e-01],\n",
       "       [9.96162653e-01],\n",
       "       [1.09129645e-01],\n",
       "       [4.37208451e-02],\n",
       "       [7.34746531e-02],\n",
       "       [1.59446627e-01],\n",
       "       [9.98994172e-01],\n",
       "       [2.55047809e-02],\n",
       "       [5.63495815e-01],\n",
       "       [9.72262502e-01],\n",
       "       [7.81305730e-02],\n",
       "       [9.99707043e-01],\n",
       "       [3.42465341e-02],\n",
       "       [2.94127762e-01],\n",
       "       [4.64430228e-02],\n",
       "       [7.50903249e-01],\n",
       "       [9.14531112e-01],\n",
       "       [7.21906945e-02],\n",
       "       [2.01485795e-03],\n",
       "       [2.33818576e-01],\n",
       "       [9.88798559e-01],\n",
       "       [8.45367074e-01],\n",
       "       [1.05508484e-01],\n",
       "       [4.12120223e-01],\n",
       "       [6.94962025e-01],\n",
       "       [1.88843552e-02],\n",
       "       [9.93608832e-01],\n",
       "       [4.58381712e-01],\n",
       "       [9.98840034e-01],\n",
       "       [9.22364473e-01],\n",
       "       [1.09414801e-01],\n",
       "       [3.49851459e-01],\n",
       "       [1.00585356e-01],\n",
       "       [9.19762373e-01],\n",
       "       [7.57978320e-01],\n",
       "       [3.17420661e-01],\n",
       "       [2.59207617e-02],\n",
       "       [2.63239622e-01],\n",
       "       [4.32557687e-02],\n",
       "       [7.40848333e-02],\n",
       "       [1.32257044e-01],\n",
       "       [3.96745086e-01],\n",
       "       [4.48563337e-01],\n",
       "       [1.33866891e-01],\n",
       "       [9.99154449e-01],\n",
       "       [9.83678102e-01],\n",
       "       [2.57876366e-01],\n",
       "       [7.53424823e-01],\n",
       "       [2.15090930e-01],\n",
       "       [3.92051451e-02],\n",
       "       [2.51202881e-01],\n",
       "       [6.88148260e-01],\n",
       "       [9.26680267e-02],\n",
       "       [1.72691196e-01],\n",
       "       [1.83795635e-02],\n",
       "       [4.34584260e-01],\n",
       "       [1.93587434e-03],\n",
       "       [9.50889111e-01],\n",
       "       [9.77024674e-01],\n",
       "       [9.92779553e-01],\n",
       "       [9.64960575e-01],\n",
       "       [7.52171278e-01],\n",
       "       [1.49138674e-01],\n",
       "       [5.52667826e-02],\n",
       "       [6.29696429e-01],\n",
       "       [8.92416418e-01],\n",
       "       [9.98353481e-01],\n",
       "       [3.28434538e-03],\n",
       "       [1.19856656e-01],\n",
       "       [1.41687185e-01],\n",
       "       [9.98550832e-01],\n",
       "       [9.99430835e-01],\n",
       "       [2.95273989e-01],\n",
       "       [1.21660650e-01],\n",
       "       [9.96442974e-01],\n",
       "       [4.55508977e-02],\n",
       "       [3.20615232e-01],\n",
       "       [9.82880414e-01],\n",
       "       [1.01776518e-01],\n",
       "       [3.40226032e-02],\n",
       "       [9.13189709e-01],\n",
       "       [3.36502135e-01],\n",
       "       [3.60338420e-01],\n",
       "       [9.66778696e-01],\n",
       "       [1.65280923e-02],\n",
       "       [5.50124906e-02],\n",
       "       [1.04115810e-02],\n",
       "       [1.49274608e-02],\n",
       "       [1.10399388e-01],\n",
       "       [9.64065194e-01],\n",
       "       [1.89441089e-02],\n",
       "       [3.87543976e-01],\n",
       "       [3.99729639e-01],\n",
       "       [5.94552793e-02],\n",
       "       [2.48062953e-01],\n",
       "       [8.48217010e-02],\n",
       "       [3.24262619e-01],\n",
       "       [9.97678578e-01],\n",
       "       [5.97208500e-01],\n",
       "       [1.31159499e-01],\n",
       "       [1.26986340e-01],\n",
       "       [1.51170984e-01],\n",
       "       [5.21963686e-02],\n",
       "       [6.31865859e-01],\n",
       "       [2.39712317e-02],\n",
       "       [8.77372086e-01],\n",
       "       [7.46328056e-01],\n",
       "       [5.45969784e-01],\n",
       "       [6.16470575e-01],\n",
       "       [7.63050377e-01],\n",
       "       [7.67079964e-02],\n",
       "       [2.18082100e-01],\n",
       "       [3.93220305e-01],\n",
       "       [8.95774841e-01],\n",
       "       [2.34136105e-01],\n",
       "       [1.63078114e-01],\n",
       "       [4.04771239e-01],\n",
       "       [1.73669308e-02],\n",
       "       [7.91992843e-02],\n",
       "       [3.36059272e-01],\n",
       "       [7.45997727e-01],\n",
       "       [8.36203843e-02],\n",
       "       [9.90980804e-01],\n",
       "       [8.86162817e-01],\n",
       "       [7.42161214e-01],\n",
       "       [9.80991662e-01],\n",
       "       [1.21026330e-01],\n",
       "       [4.63395640e-02],\n",
       "       [8.69176090e-01],\n",
       "       [1.67133957e-01],\n",
       "       [1.85231566e-02],\n",
       "       [7.31109455e-02],\n",
       "       [1.20889232e-01],\n",
       "       [1.04446802e-03],\n",
       "       [8.42351913e-01],\n",
       "       [7.49748111e-01],\n",
       "       [7.83070564e-01],\n",
       "       [9.26111042e-01],\n",
       "       [8.99618566e-02],\n",
       "       [9.65341553e-02],\n",
       "       [6.88731432e-01],\n",
       "       [1.55778555e-02],\n",
       "       [2.29828030e-01],\n",
       "       [1.20012380e-01],\n",
       "       [6.16030335e-01],\n",
       "       [5.46761096e-01],\n",
       "       [5.31364717e-02],\n",
       "       [6.75989538e-02],\n",
       "       [4.22887802e-01],\n",
       "       [1.10085376e-01],\n",
       "       [9.66235623e-02],\n",
       "       [1.43887743e-01],\n",
       "       [2.49731347e-01],\n",
       "       [9.98714089e-01],\n",
       "       [9.82511580e-01],\n",
       "       [3.03386003e-01],\n",
       "       [8.43362331e-01],\n",
       "       [9.91559565e-01],\n",
       "       [8.34981969e-04],\n",
       "       [9.59497213e-01],\n",
       "       [2.70702869e-01],\n",
       "       [4.17905867e-01],\n",
       "       [1.83707267e-01],\n",
       "       [7.99255893e-02],\n",
       "       [1.02335721e-01],\n",
       "       [2.20668539e-02],\n",
       "       [8.52825642e-02],\n",
       "       [8.29212740e-02],\n",
       "       [7.01559246e-01],\n",
       "       [2.32762635e-01],\n",
       "       [9.92246509e-01],\n",
       "       [3.43355909e-02],\n",
       "       [6.55677259e-01],\n",
       "       [5.20051539e-01],\n",
       "       [1.89584009e-02],\n",
       "       [5.93699552e-02],\n",
       "       [9.60598171e-01],\n",
       "       [6.44261956e-01],\n",
       "       [9.58545804e-01],\n",
       "       [1.29046232e-01],\n",
       "       [1.01443850e-01],\n",
       "       [4.34172750e-01],\n",
       "       [2.63469249e-01],\n",
       "       [2.44225085e-01],\n",
       "       [9.91559565e-01],\n",
       "       [1.00108674e-02],\n",
       "       [4.51745093e-02],\n",
       "       [1.28407493e-01],\n",
       "       [9.96666610e-01],\n",
       "       [1.66924551e-01],\n",
       "       [4.39982973e-02],\n",
       "       [8.01201522e-01],\n",
       "       [5.54097965e-02],\n",
       "       [2.85556559e-02],\n",
       "       [1.23932905e-01],\n",
       "       [1.58455104e-01],\n",
       "       [1.13320082e-01],\n",
       "       [3.28759938e-01],\n",
       "       [3.15541685e-01],\n",
       "       [2.15599895e-01],\n",
       "       [6.47159889e-02],\n",
       "       [3.01131934e-01],\n",
       "       [1.63941272e-02],\n",
       "       [9.38623190e-01],\n",
       "       [8.31379235e-01],\n",
       "       [4.47989941e-01],\n",
       "       [2.89629363e-02],\n",
       "       [2.01531295e-02],\n",
       "       [9.86107111e-01],\n",
       "       [6.08023107e-01],\n",
       "       [9.99554932e-01],\n",
       "       [2.51524419e-01],\n",
       "       [8.64912927e-01],\n",
       "       [7.65544772e-02],\n",
       "       [6.08006597e-01],\n",
       "       [6.25342011e-01],\n",
       "       [1.71850100e-02],\n",
       "       [9.79050457e-01],\n",
       "       [7.36648291e-02],\n",
       "       [5.59139967e-01],\n",
       "       [9.98354971e-01],\n",
       "       [1.43185645e-01],\n",
       "       [3.45761999e-02],\n",
       "       [2.37933740e-01],\n",
       "       [9.15963296e-03],\n",
       "       [4.17146862e-01],\n",
       "       [9.99809563e-01],\n",
       "       [2.36639932e-01],\n",
       "       [9.41326857e-01],\n",
       "       [2.03234166e-01],\n",
       "       [7.69510806e-01],\n",
       "       [2.10807100e-01],\n",
       "       [2.22295761e-01],\n",
       "       [1.52870044e-02],\n",
       "       [6.85174644e-01],\n",
       "       [1.45773860e-02],\n",
       "       [1.60516486e-01],\n",
       "       [9.51610148e-01],\n",
       "       [9.36550319e-01],\n",
       "       [9.94757950e-01],\n",
       "       [7.33122468e-01],\n",
       "       [4.09960262e-02],\n",
       "       [2.66207546e-01],\n",
       "       [1.53646348e-02],\n",
       "       [4.15450960e-01],\n",
       "       [3.53242874e-01],\n",
       "       [8.68579328e-01],\n",
       "       [4.07234021e-02],\n",
       "       [7.21556008e-01],\n",
       "       [7.79080272e-01],\n",
       "       [2.19810992e-01],\n",
       "       [1.66015893e-01],\n",
       "       [1.63078114e-01],\n",
       "       [1.57933712e-01],\n",
       "       [3.21412414e-01],\n",
       "       [6.62565649e-01],\n",
       "       [9.98886764e-01],\n",
       "       [4.66101132e-02],\n",
       "       [8.39787908e-03],\n",
       "       [1.71587113e-02],\n",
       "       [1.74544275e-01],\n",
       "       [1.77930504e-01],\n",
       "       [2.16893293e-02],\n",
       "       [8.21374536e-01],\n",
       "       [1.02661133e-01],\n",
       "       [2.04178885e-01],\n",
       "       [2.17449322e-01],\n",
       "       [1.80018693e-01],\n",
       "       [9.26268935e-01],\n",
       "       [1.37253016e-01],\n",
       "       [4.46760446e-01],\n",
       "       [2.50122458e-01],\n",
       "       [1.33279255e-02],\n",
       "       [9.51271951e-02],\n",
       "       [9.99669433e-01],\n",
       "       [7.77401328e-01],\n",
       "       [3.83983087e-03],\n",
       "       [3.59080553e-01],\n",
       "       [1.43328458e-01],\n",
       "       [6.36134148e-02],\n",
       "       [8.49432349e-01],\n",
       "       [5.17655015e-01],\n",
       "       [5.27778089e-01],\n",
       "       [3.55338961e-01],\n",
       "       [2.13785201e-01],\n",
       "       [6.54533863e-01],\n",
       "       [1.04117833e-01],\n",
       "       [5.86165823e-02],\n",
       "       [8.86837184e-01],\n",
       "       [1.22717887e-01],\n",
       "       [2.92013854e-01],\n",
       "       [9.78400350e-01],\n",
       "       [3.69709074e-01],\n",
       "       [2.88142323e-01],\n",
       "       [1.04446802e-03],\n",
       "       [2.03157485e-01],\n",
       "       [8.57875466e-01],\n",
       "       [9.99707043e-01],\n",
       "       [6.10672057e-01],\n",
       "       [4.27482389e-02],\n",
       "       [9.88763332e-01],\n",
       "       [3.73185605e-01],\n",
       "       [8.95071387e-01],\n",
       "       [3.73185605e-01],\n",
       "       [9.92266953e-01],\n",
       "       [1.12949302e-02],\n",
       "       [4.59832817e-01],\n",
       "       [9.13289636e-02],\n",
       "       [9.75166321e-01],\n",
       "       [2.32805192e-01],\n",
       "       [4.16847527e-01],\n",
       "       [5.05987704e-02],\n",
       "       [3.62077296e-01],\n",
       "       [9.21530500e-02],\n",
       "       [2.31601428e-02],\n",
       "       [2.05609664e-01],\n",
       "       [7.77825713e-02],\n",
       "       [6.32631928e-02],\n",
       "       [8.21210444e-01],\n",
       "       [2.04877406e-02],\n",
       "       [8.24101791e-02],\n",
       "       [3.17102112e-02],\n",
       "       [1.56227797e-02],\n",
       "       [1.10827632e-01],\n",
       "       [6.24795198e-01],\n",
       "       [7.45626464e-02],\n",
       "       [5.73070168e-01],\n",
       "       [1.24811932e-01],\n",
       "       [2.24833116e-01],\n",
       "       [8.62549782e-01],\n",
       "       [1.63962156e-01],\n",
       "       [4.96976376e-02],\n",
       "       [5.22366688e-02],\n",
       "       [5.89856040e-03],\n",
       "       [9.85845864e-01],\n",
       "       [1.56227797e-02],\n",
       "       [3.82849663e-01],\n",
       "       [9.92335737e-01],\n",
       "       [9.92641628e-01],\n",
       "       [9.97521222e-01],\n",
       "       [9.99910474e-01],\n",
       "       [9.99525666e-01],\n",
       "       [2.11748093e-01],\n",
       "       [1.01490952e-01],\n",
       "       [2.03795508e-01],\n",
       "       [4.51584280e-01],\n",
       "       [9.96617496e-01],\n",
       "       [4.84166801e-01],\n",
       "       [2.72637904e-01],\n",
       "       [4.70400870e-01],\n",
       "       [7.12860584e-01],\n",
       "       [3.53906229e-02],\n",
       "       [5.23487711e-03],\n",
       "       [8.69818255e-02],\n",
       "       [3.85280013e-01],\n",
       "       [8.31532665e-03],\n",
       "       [5.01621775e-02],\n",
       "       [3.91821921e-01],\n",
       "       [9.88902271e-01],\n",
       "       [1.60089899e-02],\n",
       "       [9.24737573e-01],\n",
       "       [6.57811582e-01],\n",
       "       [7.77570084e-02],\n",
       "       [2.57668585e-01],\n",
       "       [1.25348970e-01],\n",
       "       [7.66265035e-01],\n",
       "       [4.53831524e-01],\n",
       "       [9.03608557e-03]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32680076], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at a single prediction\n",
    "model_1_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32680076],\n",
       "       [0.7534248 ],\n",
       "       [0.9978522 ],\n",
       "       [0.08490026],\n",
       "       [0.10116445],\n",
       "       [0.93091506],\n",
       "       [0.9225775 ],\n",
       "       [0.9933455 ],\n",
       "       [0.9678209 ],\n",
       "       [0.21143188]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 10\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model prediction probabilities to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.87139107611549,\n",
       " 'precision': 0.7953441303708004,\n",
       " 'recall': 0.7887139107611548,\n",
       " 'f1-score': 0.7852145092095362}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model_1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing learned embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04966221 -0.02226266 -0.01261823 ... -0.06546193  0.02754869\n",
      "   0.04124602]\n",
      " [ 0.00408755 -0.00347629 -0.02836252 ...  0.00737716  0.02803759\n",
      "   0.03802251]\n",
      " [-0.04759025  0.00741608 -0.03622359 ... -0.0056222   0.00844918\n",
      "  -0.0373669 ]\n",
      " ...\n",
      " [ 0.01361053 -0.02107885  0.02404416 ... -0.03644736 -0.03101446\n",
      "  -0.04373557]\n",
      " [-0.07225454  0.05843375 -0.0312656  ... -0.05943295  0.07886267\n",
      "   0.01836548]\n",
      " [-0.07404425  0.07273775 -0.06225554 ... -0.02402026  0.06315358\n",
      "   0.05549434]]\n",
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "# (these are the numerical representations of each token in our training data, which have been learned for 5 epochs)\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "print(embed_weights)\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
    "\n",
    "To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
    "\n",
    "And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding files (we got this from TensorFlow's word embeddings documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the files above we can visualize them using http://projector.tensorflow.org/ and clicking the \"load\" button on  the left hand side.\n",
    "\n",
    "> 📖 **Ressource:** If you'd like to know more about embeddings, I'd encourage you to check out:\n",
    "* Jay Alammar's visualized word2vec post: https://jalammar.github.io/illustrated-word2vec/\n",
    "* TensorFlow's Word Embeddings guide: https://www.tensorflow.org/tutorials/text/word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "RNN's are useful for sequence data.\n",
    "\n",
    "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
    "\n",
    "> 📖 **Ressources:** If you want an overview of the internals of a recurrent neural network, see the following:\n",
    " - MIT's sequence modell lecture: https://youtu.be/qjrad0V0uJE\n",
    " - Chris Olag's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    " - Andrej Kaparthy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM\n",
    "LSTM  = long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "Our structure of an RNN typically looks like this:\n",
    "```Input(text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1, ), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "#x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,333,633\n",
      "Trainable params: 1,333,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the nmodel\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220712-070142\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 11ms/step - loss: 0.2278 - accuracy: 0.9202 - val_loss: 0.6266 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1550 - accuracy: 0.9418 - val_loss: 0.6030 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1265 - accuracy: 0.9530 - val_loss: 0.7110 - val_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.1046 - accuracy: 0.9606 - val_loss: 0.7325 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0845 - accuracy: 0.9669 - val_loss: 1.0062 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "histor_model_2 = model_2.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6292415e-02],\n",
       "       [9.2476857e-01],\n",
       "       [9.9998355e-01],\n",
       "       [1.4503796e-01],\n",
       "       [1.2629501e-04],\n",
       "       [9.9873036e-01],\n",
       "       [9.6425557e-01],\n",
       "       [9.9999118e-01],\n",
       "       [9.9997711e-01],\n",
       "       [5.4786944e-01]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with LSTM model\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 2 pred probs to labels\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.69028871391076,\n",
       " 'precision': 0.7781874595396938,\n",
       " 'recall': 0.7769028871391076,\n",
       " 'f1-score': 0.7751243211017478}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU\n",
    "\n",
    "Another popular and effective component is the GRU or gated recurrent unit.\n",
    "\n",
    "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
    "\n",
    "> 📖 **Ressource:** \n",
    " - https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n",
    " - https://en.wikipedia.org/wiki/Gated_recurrent_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an RNN using the GRU cell\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # if you wand to stack recurrent layers --> return_sequences = True\n",
    "# x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.GRU(64)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,321,473\n",
      "Trainable params: 1,321,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220712-070156\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 11ms/step - loss: 0.1510 - accuracy: 0.9422 - val_loss: 0.7732 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.0824 - accuracy: 0.9689 - val_loss: 0.8492 - val_accuracy: 0.7795\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0676 - accuracy: 0.9729 - val_loss: 1.1246 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0568 - accuracy: 0.9737 - val_loss: 1.3070 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0535 - accuracy: 0.9762 - val_loss: 1.1800 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "# Fit \n",
    "model_3_history = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9374516e-02],\n",
       "       [7.1505970e-01],\n",
       "       [9.9988544e-01],\n",
       "       [1.7611142e-01],\n",
       "       [3.9015518e-05],\n",
       "       [9.9943978e-01],\n",
       "       [8.8901144e-01],\n",
       "       [9.9998307e-01],\n",
       "       [9.9996722e-01],\n",
       "       [8.7685621e-01]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred_probs to labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.98425196850394,\n",
       " 'precision': 0.7604578907479682,\n",
       " 'recall': 0.7598425196850394,\n",
       " 'f1-score': 0.758116023760764}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectional RNN\n",
    "\n",
    "Normal RNN's go from left to right (just like you'd read an English sentence), however a bidirectional RNN goes from right to left as well as left to right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📖 **Ressources:** \n",
    " - https://easy-tensorflow.com/tf-tutorials/recurrent-neural-networks/bidirectional-rnn-for-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a bidirectional RNN (BRNN)\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_BRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_BRNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_BRNN/20220712-070207\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 17ms/step - loss: 0.1046 - accuracy: 0.9711 - val_loss: 0.8441 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0543 - accuracy: 0.9777 - val_loss: 1.1930 - val_accuracy: 0.7677\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0483 - accuracy: 0.9772 - val_loss: 1.4213 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0425 - accuracy: 0.9803 - val_loss: 1.2747 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0428 - accuracy: 0.9791 - val_loss: 1.3473 - val_accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19591cfd850>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_4_BRNN\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1677885e-03],\n",
       "       [8.3491397e-01],\n",
       "       [9.9996483e-01],\n",
       "       [1.4854281e-01],\n",
       "       [3.2716867e-05],\n",
       "       [9.9977571e-01],\n",
       "       [9.5332438e-01],\n",
       "       [9.9998736e-01],\n",
       "       [9.9996579e-01],\n",
       "       [9.9033737e-01]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7757380419380466,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1-score': 0.7723566516531356}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_4_preds\n",
    ")\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks for Text (and other types of sequences)\n",
    "\n",
    "We've used CNNs for images but images are typically 2D (height x width)... however our textdata is 1D.\n",
    "\n",
    "Previously we've used Conv2D for our image data but now we're going to use Conv1D.\n",
    "\n",
    "The typical structure of a Conv1D model for sequences (in our case, text):\n",
    "```\n",
    "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (class probabilities)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D\n",
    "\n",
    "For different explanations of parameters see:\n",
    "* https://poloclub.github.io/cnn-explainer/ (this is for 2D but can relate to 1D data)\n",
    "* Difference between same and valid padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out our embedding layer, Conv1D layer and max pooling\n",
    "from tensorflow.keras import layers\n",
    "embedding_test = embedding(text_vectorizer([\"This a test sentence\"])) # turn target sequence into an embedding\n",
    "conv_1d = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=\"relu\",\n",
    "    padding=\"same\"\n",
    ")\n",
    "conv_1d_output = conv_1d(embedding_test) #6 pass test embedding through our Conv1D layer\n",
    "max_pool = layers.GlobalMaxPooling1D()\n",
    "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.00260698,  0.00629941, -0.06542943, ..., -0.04972068,\n",
       "          0.04573457,  0.01191765],\n",
       "        [-0.02259542,  0.00359447, -0.02439448, ..., -0.07503128,\n",
       "          0.00994909,  0.03176597],\n",
       "        [-0.01003832,  0.00419868, -0.01823566, ..., -0.00316939,\n",
       "          0.00969158,  0.02466266],\n",
       "        ...,\n",
       "        [-0.01512512, -0.01838983, -0.00521517, ..., -0.03979459,\n",
       "          0.01658619,  0.03571813],\n",
       "        [-0.01512512, -0.01838983, -0.00521517, ..., -0.03979459,\n",
       "          0.01658619,  0.03571813],\n",
       "        [-0.01512512, -0.01838983, -0.00521517, ..., -0.03979459,\n",
       "          0.01658619,  0.03571813]]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 32), dtype=float32, numpy=\n",
       "array([[[8.63533653e-03, 0.00000000e+00, 7.91355781e-03, 0.00000000e+00,\n",
       "         3.53766605e-02, 0.00000000e+00, 5.26539236e-02, 4.17806022e-02,\n",
       "         0.00000000e+00, 0.00000000e+00, 6.16391972e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.91591997e-02, 0.00000000e+00,\n",
       "         4.34289593e-03, 3.17498818e-02, 6.53036684e-03, 4.19761334e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.84016985e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 7.29408339e-02, 0.00000000e+00, 2.87921187e-02,\n",
       "         6.04796223e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.79488806e-02, 6.00867160e-02, 0.00000000e+00, 4.91102189e-02,\n",
       "         0.00000000e+00, 2.18112785e-02, 7.40704453e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 4.33073714e-02, 2.15624403e-02, 3.74829657e-02,\n",
       "         3.95212248e-02, 4.07445729e-02, 9.76344422e-02, 2.21728850e-02,\n",
       "         0.00000000e+00, 5.55485561e-02, 3.95276286e-02, 0.00000000e+00,\n",
       "         8.92953277e-02, 5.27940271e-03, 0.00000000e+00, 3.30029391e-02,\n",
       "         9.04687345e-02, 0.00000000e+00, 2.63394006e-02, 4.01719697e-02],\n",
       "        [1.16717219e-02, 0.00000000e+00, 4.02646698e-03, 3.68761085e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 2.51133670e-03, 0.00000000e+00,\n",
       "         5.52287325e-02, 0.00000000e+00, 2.79143285e-02, 2.99683288e-05,\n",
       "         4.47527543e-02, 1.73050333e-02, 0.00000000e+00, 1.83177162e-02,\n",
       "         0.00000000e+00, 2.12860201e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.34487187e-03, 1.52372867e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 3.41005437e-02, 0.00000000e+00, 2.13979241e-02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 1.10576125e-02, 1.13936625e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 3.46786045e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.55584542e-02, 7.74464663e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.24140810e-02,\n",
       "         0.00000000e+00, 1.03151165e-02, 9.74154193e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.94197278e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.65162455e-02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 4.38149124e-02, 1.67800742e-03, 0.00000000e+00,\n",
       "         5.08297980e-03, 1.06543917e-02, 5.14071286e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.53794764e-03, 0.00000000e+00,\n",
       "         2.55024899e-02, 1.13067534e-02, 1.03528779e-02, 7.85313919e-03,\n",
       "         0.00000000e+00, 4.83123725e-03, 4.13531773e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.01908010e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 4.52783443e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 6.32897252e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "         9.20514204e-03, 1.63459964e-02, 9.10551008e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 5.99693554e-03, 0.00000000e+00,\n",
       "         4.15793322e-02, 0.00000000e+00, 0.00000000e+00, 2.26391647e-02,\n",
       "         0.00000000e+00, 2.32979320e-02, 2.29589418e-02, 6.84528053e-03,\n",
       "         6.94276858e-03, 0.00000000e+00, 2.42104959e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.06249785e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.01053242e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.33072625e-03, 1.16332220e-02, 6.80069346e-03,\n",
       "         2.61420421e-02, 5.08141879e-04, 0.00000000e+00, 3.75005864e-02,\n",
       "         0.00000000e+00, 1.85125545e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.70842407e-02, 0.00000000e+00, 1.88443288e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.74585234e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.50835042e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.62560183e-03, 2.68475655e-02, 0.00000000e+00,\n",
       "         2.03253403e-02, 2.00476181e-02, 0.00000000e+00, 4.31542769e-02,\n",
       "         0.00000000e+00, 5.64369513e-03, 5.94202010e-03, 0.00000000e+00,\n",
       "         2.08215490e-02, 0.00000000e+00, 2.64206491e-02, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.93475664e-03, 0.00000000e+00, 8.55464861e-03,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.58152592e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.50725478e-02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.89794451e-02, 4.57221922e-03,\n",
       "         8.34132731e-03, 2.84116697e-02, 0.00000000e+00, 2.56862435e-02,\n",
       "         9.00041498e-03, 1.48433018e-02, 7.13185454e-03, 0.00000000e+00,\n",
       "         1.49844196e-02, 0.00000000e+00, 2.50193551e-02, 0.00000000e+00,\n",
       "         7.82808196e-03, 1.23741198e-02, 0.00000000e+00, 3.06128338e-02,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.33415531e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[0.01167172, 0.04381491, 0.01139366, 0.01507255, 0.03537666,\n",
       "        0.06008672, 0.05265392, 0.04911022, 0.05522873, 0.02181128,\n",
       "        0.0616392 , 0.00680069, 0.04475275, 0.04330737, 0.02156244,\n",
       "        0.04315428, 0.03952122, 0.04074457, 0.09763444, 0.02217289,\n",
       "        0.02708424, 0.05554856, 0.0484017 , 0.        , 0.08929533,\n",
       "        0.07294083, 0.        , 0.03651625, 0.09046873, 0.        ,\n",
       "        0.0263394 , 0.04581526]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-d convolutional layer to model sequences\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(\n",
    "    filters=64, \n",
    "    kernel_size=5, # each filter is looking at 5 words at a time\n",
    "    strides=1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\",\n",
    ")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x =layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_Conv1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20220712-070225\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 10ms/step - loss: 0.1157 - accuracy: 0.9607 - val_loss: 0.9073 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0729 - accuracy: 0.9742 - val_loss: 1.0694 - val_accuracy: 0.7677\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0611 - accuracy: 0.9750 - val_loss: 1.1713 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0538 - accuracy: 0.9785 - val_loss: 1.2082 - val_accuracy: 0.7625\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0506 - accuracy: 0.9783 - val_loss: 1.2428 - val_accuracy: 0.7625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19591c76ac0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_5_Conv1D\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.9553714e-01],\n",
       "       [9.0814704e-01],\n",
       "       [9.9992967e-01],\n",
       "       [5.3250343e-02],\n",
       "       [8.8510546e-07],\n",
       "       [9.9697292e-01],\n",
       "       [9.8047560e-01],\n",
       "       [9.9994326e-01],\n",
       "       [9.9999976e-01],\n",
       "       [8.1423944e-01]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.24671916010499,\n",
       " 'precision': 0.7629611993882945,\n",
       " 'recall': 0.7624671916010499,\n",
       " 'f1-score': 0.7608791530897157}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_5_preds\n",
    ")\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
    "\n",
    "Now we've build a few of our own model, let's try and use transfer leraning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a flood in my street\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01154495  0.02487101  0.02879629 -0.01272263  0.0396995   0.08829076\n",
      "  0.02682647  0.05582222 -0.01078761 -0.00596656  0.00640639 -0.01816132\n",
      "  0.0002885   0.09106605  0.05874373 -0.03175148  0.01510154 -0.05164852\n",
      "  0.00994341 -0.06867752 -0.04210395  0.02675389  0.03008907  0.00320448\n",
      " -0.00336864 -0.0479053   0.02267517 -0.00984555 -0.04066692 -0.01285528\n",
      " -0.04665243  0.05630673 -0.03952145  0.00521895  0.02495947 -0.07011834\n",
      "  0.02873132  0.04945794 -0.00634556 -0.08959357  0.02807156 -0.00809173\n",
      " -0.01363955  0.05998397 -0.10361549 -0.05192674  0.0023246  -0.0232653\n",
      " -0.03752431  0.03332979], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Layer using the USW pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=False,\n",
    "    name=\"USE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\"),\n",
    "], name=\"model_6_USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220712-070251\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 8s 28ms/step - loss: 0.5091 - accuracy: 0.7843 - val_loss: 0.4506 - val_accuracy: 0.7979\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.4151 - accuracy: 0.8146 - val_loss: 0.4413 - val_accuracy: 0.8058\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.4013 - accuracy: 0.8227 - val_loss: 0.4333 - val_accuracy: 0.8123\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.3929 - accuracy: 0.8270 - val_loss: 0.4293 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3855 - accuracy: 0.8281 - val_loss: 0.4338 - val_accuracy: 0.8084\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of USE pretrained embeddings\n",
    "model_6_history = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"tf_hub_sentence_encoder\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.18385035],\n",
       "        [0.75989646],\n",
       "        [0.98909307],\n",
       "        [0.21878527],\n",
       "        [0.6466983 ],\n",
       "        [0.7190955 ],\n",
       "        [0.9797483 ],\n",
       "        [0.9765886 ],\n",
       "        [0.9344469 ],\n",
       "        [0.0953437 ],\n",
       "        [0.62424266],\n",
       "        [0.4567644 ],\n",
       "        [0.14979894],\n",
       "        [0.37908158],\n",
       "        [0.2350505 ],\n",
       "        [0.03125679],\n",
       "        [0.30075324],\n",
       "        [0.5409296 ],\n",
       "        [0.31774536],\n",
       "        [0.3193682 ],\n",
       "        [0.89695776],\n",
       "        [0.09601576],\n",
       "        [0.38674593],\n",
       "        [0.03227001],\n",
       "        [0.85100687],\n",
       "        [0.97054213],\n",
       "        [0.05864502],\n",
       "        [0.10273932],\n",
       "        [0.08993565],\n",
       "        [0.28429896],\n",
       "        [0.45611674],\n",
       "        [0.9191448 ],\n",
       "        [0.32067624],\n",
       "        [0.26712587],\n",
       "        [0.51254976],\n",
       "        [0.08044849],\n",
       "        [0.9771135 ],\n",
       "        [0.05604436],\n",
       "        [0.03863328],\n",
       "        [0.9815988 ],\n",
       "        [0.06719355],\n",
       "        [0.21076828],\n",
       "        [0.35401338],\n",
       "        [0.56320053],\n",
       "        [0.2399761 ],\n",
       "        [0.9652573 ],\n",
       "        [0.340755  ],\n",
       "        [0.9637256 ],\n",
       "        [0.59623855],\n",
       "        [0.80955774],\n",
       "        [0.05016427],\n",
       "        [0.60501385],\n",
       "        [0.14922854],\n",
       "        [0.05485251],\n",
       "        [0.09720447],\n",
       "        [0.03651754],\n",
       "        [0.10645334],\n",
       "        [0.88526696],\n",
       "        [0.10913015],\n",
       "        [0.04837541],\n",
       "        [0.07708277],\n",
       "        [0.97477084],\n",
       "        [0.9657548 ],\n",
       "        [0.06784375],\n",
       "        [0.89424145],\n",
       "        [0.9620444 ],\n",
       "        [0.66717803],\n",
       "        [0.15077895],\n",
       "        [0.06789674],\n",
       "        [0.49237138],\n",
       "        [0.08948886],\n",
       "        [0.06932723],\n",
       "        [0.72764295],\n",
       "        [0.0512951 ],\n",
       "        [0.03059282],\n",
       "        [0.4706786 ],\n",
       "        [0.17653832],\n",
       "        [0.2321043 ],\n",
       "        [0.07019089],\n",
       "        [0.7204737 ],\n",
       "        [0.7227769 ],\n",
       "        [0.41134378],\n",
       "        [0.90854335],\n",
       "        [0.0905373 ],\n",
       "        [0.64553314],\n",
       "        [0.52423644],\n",
       "        [0.07555807],\n",
       "        [0.11439526],\n",
       "        [0.98774046],\n",
       "        [0.8737086 ],\n",
       "        [0.99640405],\n",
       "        [0.03528741],\n",
       "        [0.0886512 ],\n",
       "        [0.02345761],\n",
       "        [0.96953917],\n",
       "        [0.7328102 ],\n",
       "        [0.9531292 ],\n",
       "        [0.8321853 ],\n",
       "        [0.9789018 ],\n",
       "        [0.91333824],\n",
       "        [0.9315729 ],\n",
       "        [0.1490201 ],\n",
       "        [0.18003201],\n",
       "        [0.9890531 ],\n",
       "        [0.9733343 ],\n",
       "        [0.03747208],\n",
       "        [0.86048424],\n",
       "        [0.75997454],\n",
       "        [0.12869166],\n",
       "        [0.8246761 ],\n",
       "        [0.11374411],\n",
       "        [0.05075363],\n",
       "        [0.15800664],\n",
       "        [0.24080041],\n",
       "        [0.13360575],\n",
       "        [0.18478356],\n",
       "        [0.4316746 ],\n",
       "        [0.5965027 ],\n",
       "        [0.7414187 ],\n",
       "        [0.70465535],\n",
       "        [0.8919455 ],\n",
       "        [0.1295012 ],\n",
       "        [0.4769954 ],\n",
       "        [0.7196309 ],\n",
       "        [0.56171596],\n",
       "        [0.37305033],\n",
       "        [0.13986753],\n",
       "        [0.07959691],\n",
       "        [0.10525952],\n",
       "        [0.32855973],\n",
       "        [0.09867351],\n",
       "        [0.9199421 ],\n",
       "        [0.9602198 ],\n",
       "        [0.9683741 ],\n",
       "        [0.72966486],\n",
       "        [0.15467057],\n",
       "        [0.94980174],\n",
       "        [0.379896  ],\n",
       "        [0.41270512],\n",
       "        [0.11019726],\n",
       "        [0.97522086],\n",
       "        [0.10803144],\n",
       "        [0.36061284],\n",
       "        [0.39236653],\n",
       "        [0.75735945],\n",
       "        [0.29239765],\n",
       "        [0.03010674],\n",
       "        [0.0723578 ],\n",
       "        [0.13234776],\n",
       "        [0.8754444 ],\n",
       "        [0.31212032],\n",
       "        [0.04665517],\n",
       "        [0.4860988 ],\n",
       "        [0.06185883],\n",
       "        [0.38146487],\n",
       "        [0.79490554],\n",
       "        [0.6125105 ],\n",
       "        [0.06951713],\n",
       "        [0.9371307 ],\n",
       "        [0.13414499],\n",
       "        [0.90605766],\n",
       "        [0.06912704],\n",
       "        [0.12917219],\n",
       "        [0.93744403],\n",
       "        [0.06266418],\n",
       "        [0.0406504 ],\n",
       "        [0.9941341 ],\n",
       "        [0.18412806],\n",
       "        [0.9059009 ],\n",
       "        [0.11937259],\n",
       "        [0.98275787],\n",
       "        [0.38040677],\n",
       "        [0.95228714],\n",
       "        [0.05836444],\n",
       "        [0.9373401 ],\n",
       "        [0.03071586],\n",
       "        [0.8062714 ],\n",
       "        [0.42728254],\n",
       "        [0.5381182 ],\n",
       "        [0.9945781 ],\n",
       "        [0.05150343],\n",
       "        [0.6412302 ],\n",
       "        [0.36441788],\n",
       "        [0.87642527],\n",
       "        [0.9158677 ],\n",
       "        [0.24702449],\n",
       "        [0.15573059],\n",
       "        [0.9707762 ],\n",
       "        [0.24714047],\n",
       "        [0.06660539],\n",
       "        [0.3113717 ],\n",
       "        [0.9538018 ],\n",
       "        [0.08093127],\n",
       "        [0.17336297],\n",
       "        [0.090276  ],\n",
       "        [0.09341478],\n",
       "        [0.10895225],\n",
       "        [0.18952659],\n",
       "        [0.10110685],\n",
       "        [0.04946443],\n",
       "        [0.12424318],\n",
       "        [0.94517803],\n",
       "        [0.84131694],\n",
       "        [0.18206371],\n",
       "        [0.13335393],\n",
       "        [0.98384327],\n",
       "        [0.25687355],\n",
       "        [0.7649648 ],\n",
       "        [0.87739265],\n",
       "        [0.81653446],\n",
       "        [0.03082386],\n",
       "        [0.9783766 ],\n",
       "        [0.05235794],\n",
       "        [0.07435137],\n",
       "        [0.0267301 ],\n",
       "        [0.03824867],\n",
       "        [0.89549315],\n",
       "        [0.8960932 ],\n",
       "        [0.5797017 ],\n",
       "        [0.04205747],\n",
       "        [0.48206395],\n",
       "        [0.05597677],\n",
       "        [0.07087414],\n",
       "        [0.19708548],\n",
       "        [0.9856367 ],\n",
       "        [0.1332653 ],\n",
       "        [0.17516099],\n",
       "        [0.96588135],\n",
       "        [0.666611  ],\n",
       "        [0.27689242],\n",
       "        [0.77151877],\n",
       "        [0.15870668],\n",
       "        [0.9355507 ],\n",
       "        [0.04134741],\n",
       "        [0.31496954],\n",
       "        [0.40421864],\n",
       "        [0.33925736],\n",
       "        [0.42446518],\n",
       "        [0.9790636 ],\n",
       "        [0.03452746],\n",
       "        [0.5526375 ],\n",
       "        [0.22258838],\n",
       "        [0.97691035],\n",
       "        [0.91009265],\n",
       "        [0.03424009],\n",
       "        [0.19071858],\n",
       "        [0.89775306],\n",
       "        [0.17102921],\n",
       "        [0.08726453],\n",
       "        [0.6747352 ],\n",
       "        [0.09622521],\n",
       "        [0.816062  ],\n",
       "        [0.03469316],\n",
       "        [0.40389627],\n",
       "        [0.8751667 ],\n",
       "        [0.16991003],\n",
       "        [0.7712511 ],\n",
       "        [0.9933657 ],\n",
       "        [0.2710231 ],\n",
       "        [0.09927478],\n",
       "        [0.93793714],\n",
       "        [0.08735336],\n",
       "        [0.15806814],\n",
       "        [0.94581074],\n",
       "        [0.8182317 ],\n",
       "        [0.664364  ],\n",
       "        [0.9083641 ],\n",
       "        [0.06617641],\n",
       "        [0.10868887],\n",
       "        [0.0640536 ],\n",
       "        [0.121341  ],\n",
       "        [0.34314135],\n",
       "        [0.9119139 ],\n",
       "        [0.10631601],\n",
       "        [0.3278639 ],\n",
       "        [0.9351651 ],\n",
       "        [0.1316336 ],\n",
       "        [0.07835253],\n",
       "        [0.97873086],\n",
       "        [0.39078537],\n",
       "        [0.08740558],\n",
       "        [0.11506025],\n",
       "        [0.96545833],\n",
       "        [0.3573504 ],\n",
       "        [0.1695573 ],\n",
       "        [0.50740516],\n",
       "        [0.7748224 ],\n",
       "        [0.15312827],\n",
       "        [0.76038784],\n",
       "        [0.05033816],\n",
       "        [0.7660709 ],\n",
       "        [0.5540598 ],\n",
       "        [0.24485587],\n",
       "        [0.65280694],\n",
       "        [0.055609  ],\n",
       "        [0.8603226 ],\n",
       "        [0.18250218],\n",
       "        [0.9783326 ],\n",
       "        [0.07559402],\n",
       "        [0.53334737],\n",
       "        [0.30696395],\n",
       "        [0.09877895],\n",
       "        [0.06191466],\n",
       "        [0.6794418 ],\n",
       "        [0.1973285 ],\n",
       "        [0.1391887 ],\n",
       "        [0.08148061],\n",
       "        [0.6881616 ],\n",
       "        [0.05472101],\n",
       "        [0.02747609],\n",
       "        [0.1019142 ],\n",
       "        [0.96257263],\n",
       "        [0.6333267 ],\n",
       "        [0.19880931],\n",
       "        [0.96829534],\n",
       "        [0.06765135],\n",
       "        [0.9061619 ],\n",
       "        [0.62509555],\n",
       "        [0.02441671],\n",
       "        [0.22875606],\n",
       "        [0.08185364],\n",
       "        [0.13108316],\n",
       "        [0.97381026],\n",
       "        [0.06683715],\n",
       "        [0.7119082 ],\n",
       "        [0.06023086],\n",
       "        [0.1705246 ],\n",
       "        [0.83689016],\n",
       "        [0.04676634],\n",
       "        [0.8517154 ],\n",
       "        [0.831959  ],\n",
       "        [0.07973228],\n",
       "        [0.9352025 ],\n",
       "        [0.23944667],\n",
       "        [0.19348584],\n",
       "        [0.46654826],\n",
       "        [0.04356372],\n",
       "        [0.3558089 ],\n",
       "        [0.42996973],\n",
       "        [0.5439141 ],\n",
       "        [0.10003845],\n",
       "        [0.17559345],\n",
       "        [0.9084978 ],\n",
       "        [0.9570992 ],\n",
       "        [0.70460594],\n",
       "        [0.16816874],\n",
       "        [0.26616478],\n",
       "        [0.07252256],\n",
       "        [0.05121466],\n",
       "        [0.15452072],\n",
       "        [0.20746875],\n",
       "        [0.31921083],\n",
       "        [0.07100776],\n",
       "        [0.0814733 ],\n",
       "        [0.49123845],\n",
       "        [0.03869269],\n",
       "        [0.9558519 ],\n",
       "        [0.9587751 ],\n",
       "        [0.8194661 ],\n",
       "        [0.5798547 ],\n",
       "        [0.31778187],\n",
       "        [0.06563156],\n",
       "        [0.95263773],\n",
       "        [0.47545582],\n",
       "        [0.38091537],\n",
       "        [0.04373681],\n",
       "        [0.12393512],\n",
       "        [0.07542741],\n",
       "        [0.16495767],\n",
       "        [0.02963133],\n",
       "        [0.70894396],\n",
       "        [0.04057078],\n",
       "        [0.1231709 ],\n",
       "        [0.1753055 ],\n",
       "        [0.06180583],\n",
       "        [0.07358982],\n",
       "        [0.12372891],\n",
       "        [0.11244814],\n",
       "        [0.12778464],\n",
       "        [0.35282335],\n",
       "        [0.9318742 ],\n",
       "        [0.7476881 ],\n",
       "        [0.08148853],\n",
       "        [0.19794178],\n",
       "        [0.48461175],\n",
       "        [0.9535701 ],\n",
       "        [0.37082815],\n",
       "        [0.24388562],\n",
       "        [0.99009866],\n",
       "        [0.26739267],\n",
       "        [0.10275794],\n",
       "        [0.3575172 ],\n",
       "        [0.03327608],\n",
       "        [0.84982866],\n",
       "        [0.57689923],\n",
       "        [0.9895644 ],\n",
       "        [0.09283435],\n",
       "        [0.69761294],\n",
       "        [0.24107113],\n",
       "        [0.36277512],\n",
       "        [0.96264535],\n",
       "        [0.13825546],\n",
       "        [0.56612027],\n",
       "        [0.9026058 ],\n",
       "        [0.08502423],\n",
       "        [0.92908084],\n",
       "        [0.24542153],\n",
       "        [0.71158093],\n",
       "        [0.05025493],\n",
       "        [0.24103035],\n",
       "        [0.84410214],\n",
       "        [0.03511487],\n",
       "        [0.06060529],\n",
       "        [0.41584507],\n",
       "        [0.9164314 ],\n",
       "        [0.7267427 ],\n",
       "        [0.18397956],\n",
       "        [0.95485026],\n",
       "        [0.18464887],\n",
       "        [0.07282992],\n",
       "        [0.966171  ],\n",
       "        [0.86144954],\n",
       "        [0.6596302 ],\n",
       "        [0.7736421 ],\n",
       "        [0.03670942],\n",
       "        [0.5227633 ],\n",
       "        [0.11837412],\n",
       "        [0.79735565],\n",
       "        [0.37616944],\n",
       "        [0.9170398 ],\n",
       "        [0.06428194],\n",
       "        [0.05791736],\n",
       "        [0.08609889],\n",
       "        [0.5981219 ],\n",
       "        [0.21629897],\n",
       "        [0.2538035 ],\n",
       "        [0.40387988],\n",
       "        [0.28540626],\n",
       "        [0.9840336 ],\n",
       "        [0.6581218 ],\n",
       "        [0.63090295],\n",
       "        [0.7285523 ],\n",
       "        [0.34416428],\n",
       "        [0.1037686 ],\n",
       "        [0.16296689],\n",
       "        [0.70698637],\n",
       "        [0.0520154 ],\n",
       "        [0.05593403],\n",
       "        [0.18331787],\n",
       "        [0.1577024 ],\n",
       "        [0.04293576],\n",
       "        [0.88842845],\n",
       "        [0.9292513 ],\n",
       "        [0.8362998 ],\n",
       "        [0.9594226 ],\n",
       "        [0.9816202 ],\n",
       "        [0.06284492],\n",
       "        [0.16343614],\n",
       "        [0.33287716],\n",
       "        [0.8119723 ],\n",
       "        [0.98352873],\n",
       "        [0.06430791],\n",
       "        [0.10515936],\n",
       "        [0.37401688],\n",
       "        [0.9893253 ],\n",
       "        [0.94350314],\n",
       "        [0.1591005 ],\n",
       "        [0.21026137],\n",
       "        [0.9016809 ],\n",
       "        [0.03519462],\n",
       "        [0.15119806],\n",
       "        [0.89399225],\n",
       "        [0.50252277],\n",
       "        [0.2551927 ],\n",
       "        [0.6908708 ],\n",
       "        [0.46373698],\n",
       "        [0.8336616 ],\n",
       "        [0.9791738 ],\n",
       "        [0.07739729],\n",
       "        [0.05085145],\n",
       "        [0.14834172],\n",
       "        [0.06094268],\n",
       "        [0.25201595],\n",
       "        [0.85068506],\n",
       "        [0.03217123],\n",
       "        [0.51920223],\n",
       "        [0.07840724],\n",
       "        [0.07142829],\n",
       "        [0.23927641],\n",
       "        [0.40027317],\n",
       "        [0.2896072 ],\n",
       "        [0.9566292 ],\n",
       "        [0.18469949],\n",
       "        [0.07065207],\n",
       "        [0.1085233 ],\n",
       "        [0.12873799],\n",
       "        [0.5042639 ],\n",
       "        [0.8168002 ],\n",
       "        [0.10082261],\n",
       "        [0.87009007],\n",
       "        [0.958951  ],\n",
       "        [0.04217339],\n",
       "        [0.34663916],\n",
       "        [0.78716296],\n",
       "        [0.18827473],\n",
       "        [0.61719805],\n",
       "        [0.0768763 ],\n",
       "        [0.95376104],\n",
       "        [0.1599875 ],\n",
       "        [0.17382303],\n",
       "        [0.10323734],\n",
       "        [0.05823705],\n",
       "        [0.16140772],\n",
       "        [0.54957366],\n",
       "        [0.955227  ],\n",
       "        [0.14548522],\n",
       "        [0.9747959 ],\n",
       "        [0.6326984 ],\n",
       "        [0.623385  ],\n",
       "        [0.9828705 ],\n",
       "        [0.4493016 ],\n",
       "        [0.34209737],\n",
       "        [0.8366796 ],\n",
       "        [0.94426674],\n",
       "        [0.05567113],\n",
       "        [0.17964947],\n",
       "        [0.07474521],\n",
       "        [0.20833758],\n",
       "        [0.30259064],\n",
       "        [0.92121625],\n",
       "        [0.70373243],\n",
       "        [0.9598569 ],\n",
       "        [0.06888968],\n",
       "        [0.0395855 ],\n",
       "        [0.7979489 ],\n",
       "        [0.09898613],\n",
       "        [0.06130401],\n",
       "        [0.05233916],\n",
       "        [0.11998412],\n",
       "        [0.43939346],\n",
       "        [0.19431193],\n",
       "        [0.4315168 ],\n",
       "        [0.1890745 ],\n",
       "        [0.13542065],\n",
       "        [0.10479592],\n",
       "        [0.17797261],\n",
       "        [0.37845376],\n",
       "        [0.94096816],\n",
       "        [0.7451086 ],\n",
       "        [0.6839573 ],\n",
       "        [0.91316515],\n",
       "        [0.93599385],\n",
       "        [0.0646566 ],\n",
       "        [0.8100796 ],\n",
       "        [0.06386746],\n",
       "        [0.97978354],\n",
       "        [0.05851199],\n",
       "        [0.17822519],\n",
       "        [0.20395827],\n",
       "        [0.05581575],\n",
       "        [0.13775559],\n",
       "        [0.2252387 ],\n",
       "        [0.9362685 ],\n",
       "        [0.834389  ],\n",
       "        [0.80834895],\n",
       "        [0.06883396],\n",
       "        [0.6800467 ],\n",
       "        [0.73391104],\n",
       "        [0.07169045],\n",
       "        [0.20903096],\n",
       "        [0.82933956],\n",
       "        [0.61816883],\n",
       "        [0.98341906],\n",
       "        [0.21720785],\n",
       "        [0.10528582],\n",
       "        [0.5337366 ],\n",
       "        [0.08443383],\n",
       "        [0.7164799 ],\n",
       "        [0.8934791 ],\n",
       "        [0.17696197],\n",
       "        [0.04866766],\n",
       "        [0.1098277 ],\n",
       "        [0.94031936],\n",
       "        [0.13625002],\n",
       "        [0.0577312 ],\n",
       "        [0.9691171 ],\n",
       "        [0.15631592],\n",
       "        [0.07056283],\n",
       "        [0.6589552 ],\n",
       "        [0.02323326],\n",
       "        [0.21165058],\n",
       "        [0.33326393],\n",
       "        [0.5532564 ],\n",
       "        [0.0146662 ],\n",
       "        [0.22769703],\n",
       "        [0.9517902 ],\n",
       "        [0.09975342],\n",
       "        [0.9152844 ],\n",
       "        [0.9822869 ],\n",
       "        [0.04717739],\n",
       "        [0.04894409],\n",
       "        [0.05394245],\n",
       "        [0.9258357 ],\n",
       "        [0.46452293],\n",
       "        [0.97839385],\n",
       "        [0.09531081],\n",
       "        [0.27363256],\n",
       "        [0.08243947],\n",
       "        [0.04549437],\n",
       "        [0.7800512 ],\n",
       "        [0.09059429],\n",
       "        [0.9141445 ],\n",
       "        [0.06856132],\n",
       "        [0.13845922],\n",
       "        [0.97895676],\n",
       "        [0.21310169],\n",
       "        [0.05166786],\n",
       "        [0.4088505 ],\n",
       "        [0.0362873 ],\n",
       "        [0.5290298 ],\n",
       "        [0.98365664],\n",
       "        [0.0610876 ],\n",
       "        [0.9876605 ],\n",
       "        [0.19348761],\n",
       "        [0.77966774],\n",
       "        [0.11760175],\n",
       "        [0.37381932],\n",
       "        [0.24902777],\n",
       "        [0.8758902 ],\n",
       "        [0.03313237],\n",
       "        [0.490358  ],\n",
       "        [0.9337535 ],\n",
       "        [0.68326366],\n",
       "        [0.6393709 ],\n",
       "        [0.89836365],\n",
       "        [0.04722768],\n",
       "        [0.7130966 ],\n",
       "        [0.09141373],\n",
       "        [0.69342256],\n",
       "        [0.13285826],\n",
       "        [0.9201524 ],\n",
       "        [0.36480457],\n",
       "        [0.5721219 ],\n",
       "        [0.21634759],\n",
       "        [0.05456647],\n",
       "        [0.6414791 ],\n",
       "        [0.12445589],\n",
       "        [0.16357616],\n",
       "        [0.5589245 ],\n",
       "        [0.9643127 ],\n",
       "        [0.9858343 ],\n",
       "        [0.06185389],\n",
       "        [0.05309321],\n",
       "        [0.06484334],\n",
       "        [0.10740472],\n",
       "        [0.23555066],\n",
       "        [0.06288833],\n",
       "        [0.97394526],\n",
       "        [0.09538271],\n",
       "        [0.41174275],\n",
       "        [0.08953319],\n",
       "        [0.08694277],\n",
       "        [0.83449656],\n",
       "        [0.10986809],\n",
       "        [0.09288442],\n",
       "        [0.2142164 ],\n",
       "        [0.09620188],\n",
       "        [0.29704   ],\n",
       "        [0.9796274 ],\n",
       "        [0.47049418],\n",
       "        [0.05083119],\n",
       "        [0.15735711],\n",
       "        [0.10210703],\n",
       "        [0.03017643],\n",
       "        [0.9275514 ],\n",
       "        [0.18437344],\n",
       "        [0.62186414],\n",
       "        [0.41432166],\n",
       "        [0.10013747],\n",
       "        [0.2864634 ],\n",
       "        [0.29784802],\n",
       "        [0.04966374],\n",
       "        [0.1182404 ],\n",
       "        [0.8484263 ],\n",
       "        [0.14296903],\n",
       "        [0.92062914],\n",
       "        [0.04899317],\n",
       "        [0.15204516],\n",
       "        [0.20833758],\n",
       "        [0.03613995],\n",
       "        [0.7904286 ],\n",
       "        [0.9379763 ],\n",
       "        [0.19710925],\n",
       "        [0.07399332],\n",
       "        [0.97222286],\n",
       "        [0.75214946],\n",
       "        [0.8159859 ],\n",
       "        [0.60612005],\n",
       "        [0.7478182 ],\n",
       "        [0.07557914],\n",
       "        [0.14653502],\n",
       "        [0.24811578],\n",
       "        [0.747764  ],\n",
       "        [0.07790937],\n",
       "        [0.37510195],\n",
       "        [0.1829607 ],\n",
       "        [0.26834393],\n",
       "        [0.06065192],\n",
       "        [0.08024585],\n",
       "        [0.11602137],\n",
       "        [0.171111  ],\n",
       "        [0.18960823],\n",
       "        [0.52637583],\n",
       "        [0.02242731],\n",
       "        [0.0850466 ],\n",
       "        [0.15385526],\n",
       "        [0.23767091],\n",
       "        [0.02680268],\n",
       "        [0.6417635 ],\n",
       "        [0.02921821],\n",
       "        [0.57541996],\n",
       "        [0.11699428],\n",
       "        [0.20964076],\n",
       "        [0.8809624 ],\n",
       "        [0.05844035],\n",
       "        [0.31630698],\n",
       "        [0.09722599],\n",
       "        [0.06125575],\n",
       "        [0.9314908 ],\n",
       "        [0.226225  ],\n",
       "        [0.15120055],\n",
       "        [0.8520682 ],\n",
       "        [0.94073105],\n",
       "        [0.89325666],\n",
       "        [0.99021405],\n",
       "        [0.95599943],\n",
       "        [0.15406501],\n",
       "        [0.13545476],\n",
       "        [0.05034981],\n",
       "        [0.70755345],\n",
       "        [0.8642562 ],\n",
       "        [0.54977536],\n",
       "        [0.3470874 ],\n",
       "        [0.05576373],\n",
       "        [0.376921  ],\n",
       "        [0.3332826 ],\n",
       "        [0.12188767],\n",
       "        [0.15719163],\n",
       "        [0.1065387 ],\n",
       "        [0.06195244],\n",
       "        [0.09877796],\n",
       "        [0.2713292 ],\n",
       "        [0.9250397 ],\n",
       "        [0.08567586],\n",
       "        [0.9259634 ],\n",
       "        [0.6562883 ],\n",
       "        [0.05693561],\n",
       "        [0.11426686],\n",
       "        [0.09972715],\n",
       "        [0.8851316 ],\n",
       "        [0.5761937 ],\n",
       "        [0.09611735]], dtype=float32),)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences),\n",
    "model_6_pred_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 USE:\n",
      "{'accuracy': 80.83989501312337, 'precision': 0.8124533883813974, 'recall': 0.8083989501312336, 'f1-score': 0.8062063003139296}\n",
      "Baseline:\n",
      "{'accuracy': 79.26509186351706, 'precision': 0.8111390004213173, 'recall': 0.7926509186351706, 'f1-score': 0.7862189758049549}\n"
     ]
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_6_preds\n",
    ")\n",
    "print(f\"Model 6 USE:\\n{model_6_results}\\nBaseline:\\n{baseline_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 7613, 7613)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_df), len(train_df_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: TF Hub Pretrained USE but with 10% training data\n",
    "\n",
    "Transfer learning really helps when you don't have a large dataset.\n",
    "\n",
    "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **Note:** Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained 100% data). DO NOT make data splits which leak data from validation/test set into training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS BAD!\n",
    "# Create subsets of 10% of the training data\n",
    "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "# train_10_percent.head(), len(train_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 🔑 **Note:** Be *very* careful when creating training/val/test splits that you don't leak data accross the dataset. Otherwise your model evaluation metrics will be wrong. If something looks to good to be true (a model trained on 10% of data outperforming the same model trained 100% of data) trust your gut and go back through to find where the error may lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 685)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a better dataset split (no data leakage)\n",
    "train_10_percent_split = int(0.1 * len(train_sentences)) # already in random order\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
    "len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "# len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of target in our subset of data\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate a model the same as a previous model we've created, we can use the `tf.keras.models.clone_model()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a model the same as model 6\n",
    "model_7 = tf.keras.models.clone_model(model_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_7.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_USE_10_percent_correct_split/20220712-070600\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 146ms/step - loss: 0.6646 - accuracy: 0.6949 - val_loss: 0.6484 - val_accuracy: 0.7205\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 0.5984 - accuracy: 0.7956 - val_loss: 0.5961 - val_accuracy: 0.7428\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.5245 - accuracy: 0.8219 - val_loss: 0.5445 - val_accuracy: 0.7769\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4640 - accuracy: 0.8307 - val_loss: 0.5115 - val_accuracy: 0.7795\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4237 - accuracy: 0.8409 - val_loss: 0.4946 - val_accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19631da0d60>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(\n",
    "    train_sentences_10_percent,\n",
    "    train_labels_10_percent,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"model_7_USE_10_percent_correct_split\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20715252],\n",
       "       [0.5745126 ],\n",
       "       [0.8828461 ],\n",
       "       [0.36611807],\n",
       "       [0.56679916],\n",
       "       [0.70585066],\n",
       "       [0.86654824],\n",
       "       [0.78478783],\n",
       "       [0.83028847],\n",
       "       [0.15467183]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7747317935775544,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1-score': 0.7729333240681188}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_7_preds\n",
    ")\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.83989501312337,\n",
       " 'precision': 0.8124533883813974,\n",
       " 'recall': 0.8083989501312336,\n",
       " 'f1-score': 0.8062063003139296}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1-score': 0.7862189758049549}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63418e73e250c304d26eaf03185e2f59ff2277f62dd1cc8bba54019c2c46cc60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
