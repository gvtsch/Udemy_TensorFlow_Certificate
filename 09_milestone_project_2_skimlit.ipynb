{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 2: SkimLit ðŸ“°ðŸ”¥\n",
    "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
    "\n",
    "The paper we're replicating (the source of the dataset that we'll be using) is available here: https://arxiv.org/abs/1710.06071\n",
    "\n",
    "And reading through the paper above, we see that the model architecture that they use to achieve ther best results is available here: https://arxiv.org/abs/1612.05251\n",
    "\n",
    "If you want to finde the ground truth of this notebook (with lots of diagrams and text annotations) see github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm access to a GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 18 18:59:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.59       Driver Version: 516.59       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P3    23W /  N/A |   1193MiB /  6144MiB |     27%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1528    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      3596    C+G   ...s Auto Creations 2021.exe    N/A      |\n",
      "|    0   N/A  N/A      4992    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      7836    C+G   ...obeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A      9860    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     10008    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12896    C+G   ...lication\\WebCompanion.exe    N/A      |\n",
      "|    0   N/A  N/A     13208    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     14756    C+G   ...ropbox\\Client\\Dropbox.exe    N/A      |\n",
      "|    0   N/A  N/A     15604    C+G   ...264.62\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     15912    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16412    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     16600    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     18580    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     19108    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     20116    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     21860    C+G   ... iCUE 4 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A     25556    C+G   ...signal-desktop\\Signal.exe    N/A      |\n",
      "|    0   N/A  N/A     25864    C+G   ...batNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     26484    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     28408    C+G   ...4__htrsf667h5kn2\\AWCC.exe    N/A      |\n",
      "|    0   N/A  N/A     30308    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-2349283b-d8c3-574d-bb05-0097332584c3)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Since we'll be replicating the paper above (PudMed 200k RCT), let's download the dataset they used.\n",
    "\n",
    "We can do so from the authors github: https://github.com/Franck-Dernoncourt/pubmed-rct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt\n",
      "test.txt\n",
      "train.txt\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset\n",
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start our experiments using the 20k dataset with numbers replaced by \"@\" sign\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "Now we've got some text data, it's time to become one with it.\n",
    "\n",
    "And one of the best waysto become one with the data is to ...\n",
    "\n",
    "> Visualize, visualize, visualize\n",
    "\n",
    "So with that in mind, let's write a function to read in all of the lines of a target textfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename (a text filename) and return the lines of the text as a list.\n",
    "\n",
    "    Args:\n",
    "        filename: a string containing the target filepath.\n",
    "\n",
    "    Returns:\n",
    "        A list of strings with one string per line from the target filename.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
       " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
       " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
       " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
       " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
       " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines\n",
    "train_lines = get_lines(data_dir+\"train.txt\")\n",
    "train_lines[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about, how we want our data to look...\n",
    "\n",
    "How I think our data would be best represented...\n",
    "\n",
    "```\n",
    "[{'line_number': '0',\n",
    "    'target': 'Background'\n",
    "    'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\"',\n",
    "    'total_lines': '11'}]\n",
    "```\n",
    "\n",
    "Let's write a function which turns each of our datasets into the above format so we can conitnue prepare our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "    Takes in filename, reads it contents and sorts through each line,\n",
    "    extracting things like the target label, the text of the sentence, \n",
    "    how many sentences are in the current abstract and what sentence\n",
    "    number the target line is.\n",
    "    \"\"\"\n",
    "    input_lines = get_lines(filename) # get all lines from filename\n",
    "    abstract_lines = \"\" # create an empty abstract\n",
    "    abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "    # Loop through each line in the target file\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"): # Check to see if the line is an 1D line\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\" # reset the abstract string if the line is an 1D line\n",
    "            \n",
    "        elif line.isspace(): # check to see if line is a new line\n",
    "            abstract_line_split = abstract_lines.splitlines() # split abstract into seperate lines\n",
    "            \n",
    "            # Iterate through each line in a single abstract and count them at the same time\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {} # create an empty dictionary for each line\n",
    "                target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "                line_data[\"target\"] = target_text_split[0] # get target label\n",
    "                line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "                line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in abstract?\n",
    "                line_data[\"total_lines\"] = len(abstract_line_split) - 1# How many total lines are ther in the targat abstract? (start from 0)\n",
    "                abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "\n",
    "        else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "            abstract_lines += line\n",
    "        \n",
    "    return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+\"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir+\"dev.txt\") # dev is another word for val\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10},\n",
       " {'target': 'OBJECTIVE',\n",
       "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is in the format of a list of dictionaries, how about we turn it into a DataFrame to further visualize it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Distribution of labels in training data\n",
    " train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"401.690625pt\" height=\"249.610631pt\" viewBox=\"0 0 401.690625 249.610631\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-07-18T18:59:43.763575</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 249.610631 \nL 401.690625 249.610631 \nL 401.690625 0 \nL 0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 59.690625 225.732506 \nL 394.490625 225.732506 \nL 394.490625 8.292506 \nL 59.690625 8.292506 \nz\n\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 74.908807 225.732506 \nL 105.34517 225.732506 \nL 105.34517 221.459313 \nL 74.908807 221.459313 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 105.34517 225.732506 \nL 135.781534 225.732506 \nL 135.781534 154.864386 \nL 105.34517 154.864386 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 135.781534 225.732506 \nL 166.217898 225.732506 \nL 166.217898 18.646791 \nL 135.781534 18.646791 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 166.217898 225.732506 \nL 196.654261 225.732506 \nL 196.654261 101.337513 \nL 166.217898 101.337513 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 196.654261 225.732506 \nL 227.090625 225.732506 \nL 227.090625 125.093149 \nL 196.654261 125.093149 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 227.090625 225.732506 \nL 257.526989 225.732506 \nL 257.526989 191.908945 \nL 227.090625 191.908945 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 257.526989 225.732506 \nL 287.963352 225.732506 \nL 287.963352 219.44082 \nL 257.526989 219.44082 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 287.963352 225.732506 \nL 318.399716 225.732506 \nL 318.399716 221.980808 \nL 287.963352 221.980808 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 318.399716 225.732506 \nL 348.83608 225.732506 \nL 348.83608 224.839829 \nL 318.399716 224.839829 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 348.83608 225.732506 \nL 379.272443 225.732506 \nL 379.272443 225.459488 \nL 348.83608 225.459488 \nz\n\" clip-path=\"url(#p22c89fff22)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m08cf036dd7\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"97.454261\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(94.273011 240.330943)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"153.817898\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(147.455398 240.330943)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"210.181534\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 15 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(203.819034 240.330943)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"266.54517\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(260.18267 240.330943)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"322.908807\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 25 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(316.546307 240.330943)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m08cf036dd7\" x=\"379.272443\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 30 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(372.909943 240.330943)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m10134b8b97\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"225.732506\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(46.328125 229.531724)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"195.056322\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 198.855541)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"164.380138\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 168.179357)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"133.703954\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 30000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 137.503173)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"103.02777\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 40000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 106.826989)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"72.351586\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 50000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 76.150805)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"41.675403\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 60000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 45.474621)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m10134b8b97\" x=\"59.690625\" y=\"10.999219\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 70000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(20.878125 14.798437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- Frequency -->\n     <g style=\"fill: #ffffff\" transform=\"translate(14.798438 142.842193)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-46\" d=\"M 628 4666 \nL 3309 4666 \nL 3309 4134 \nL 1259 4134 \nL 1259 2759 \nL 3109 2759 \nL 3109 2228 \nL 1259 2228 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-71\" d=\"M 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\nM 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 -1331 \nL 2906 -1331 \nL 2906 525 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-46\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"50.269531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"89.132812\"/>\n      <use xlink:href=\"#DejaVuSans-71\" x=\"150.65625\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"214.132812\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"277.511719\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"339.035156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"402.414062\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"457.394531\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 59.690625 225.732506 \nL 59.690625 8.292506 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 394.490625 225.732506 \nL 394.490625 8.292506 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 59.690625 225.732506 \nL 394.490625 225.732506 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 59.690625 8.292506 \nL 394.490625 8.292506 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p22c89fff22\">\n   <rect x=\"59.690625\" y=\"8.292506\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check the length of different lines\n",
    "train_df.total_lines.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists\n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the 10 lines of training sentences\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make numeric labels (ML Models require numeric labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False) \n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels (\"target\" columns) and encode them into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder instance\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a series of modelling experiments...\n",
    "As usual, we're going to be trying out a bunch of different models and seeing which one works best.\n",
    "\n",
    "And as always, we're going to start with a baseline (TF-IDF Multinomial Naive Bayes classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tf-idf\", TfidfVectorizer()),\n",
    "    (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(\n",
    "    X=train_sentences,\n",
    "    y=train_labels_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline model on validation dataset\n",
    "model_0.score(\n",
    "    X=val_sentences,\n",
    "    y=val_labels_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using our baseline model\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, ..., 4, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download helper_functions.py\n",
    "Import a function to compare predictions from previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"helper_functions.py\"):\n",
    "    !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels_encoded,\n",
    "    y_pred=baseline_preds\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare our data (the text) for deep sequence model\n",
    "\n",
    "Before we start building deeper models, we've got to create vectorization and embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sentence_length = [len(sentence.split()) for sentence in train_sentences]\n",
    "    # going through all of the lines in train_sentences\n",
    "avg_sentence_length = np.mean(sentence_length)\n",
    "avg_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"394.375pt\" height=\"248.518125pt\" viewBox=\"0 0 394.375 248.518125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-07-18T18:59:55.272598</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 394.375 248.518125 \nL 394.375 0 \nL 0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.375 224.64 \nL 387.175 224.64 \nL 387.175 7.2 \nL 52.375 7.2 \nz\n\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 67.593182 224.64 \nL 98.029545 224.64 \nL 98.029545 17.554286 \nL 67.593182 17.554286 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 98.029545 224.64 \nL 128.465909 224.64 \nL 128.465909 145.946573 \nL 98.029545 145.946573 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 128.465909 224.64 \nL 158.902273 224.64 \nL 158.902273 215.793531 \nL 128.465909 215.793531 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 158.902273 224.64 \nL 189.338636 224.64 \nL 189.338636 223.346599 \nL 158.902273 223.346599 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 189.338636 224.64 \nL 219.775 224.64 \nL 219.775 224.39975 \nL 189.338636 224.39975 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 219.775 224.64 \nL 250.211364 224.64 \nL 250.211364 224.587342 \nL 219.775 224.587342 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 250.211364 224.64 \nL 280.647727 224.64 \nL 280.647727 224.608735 \nL 250.211364 224.608735 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 280.647727 224.64 \nL 311.084091 224.64 \nL 311.084091 224.626836 \nL 280.647727 224.626836 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 311.084091 224.64 \nL 341.520455 224.64 \nL 341.520455 224.635063 \nL 311.084091 224.635063 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 341.520455 224.64 \nL 371.956818 224.64 \nL 371.956818 224.636709 \nL 341.520455 224.636709 \nz\n\" clip-path=\"url(#p1cb1223063)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m0e25ed49cf\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"66.561441\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(63.380191 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"118.148498\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(111.785998 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"169.735555\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(160.191805 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"221.322612\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(211.778862 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"272.909669\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(263.365919 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"324.496726\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(314.952976 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m0e25ed49cf\" x=\"376.083783\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(366.540033 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m8690182cf8\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(39.0125 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"191.729027\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 20000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(13.5625 195.528246)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"158.818054\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 40000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(13.5625 162.617273)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"125.907082\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 60000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(13.5625 129.7063)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"92.996109\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 80000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(13.5625 96.795327)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"60.085136\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 100000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 63.884355)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"318.115234\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m8690182cf8\" x=\"52.375\" y=\"27.174163\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 120000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 30.973382)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"318.115234\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 52.375 224.64 \nL 52.375 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 387.175 224.64 \nL 387.175 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 52.375 224.64 \nL 387.175 224.64 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 52.375 7.2 \nL 387.175 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1cb1223063\">\n   <rect x=\"52.375\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution look like?\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sentence_length, bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of examples?\n",
    "output_seq_len = int(np.percentile(sentence_length, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length in the training set\n",
    "max(sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text vectorizer layer\n",
    "\n",
    "WE want to make a layer which maps our texts from words to numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words are in our vocab? (taken from table 2 in: https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens=68_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text vectorizer\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer=TextVectorization(\n",
    "    max_tokens=max_tokens, # num of words in vocabv\n",
    "    output_sequence_length=output_seq_len # desired output length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "using rmn , only minor complications have been observed .\n",
      "\n",
      "Length of text: 10\n",
      "\n",
      "Vectorized test: \n",
      "[[   59 24777   192  1857   296    99   167   148     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer of random sentences\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized test: \\n{text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower number mean, that the word is ranken higher in the vocab.\n",
    "\n",
    "e.g. **the** is ranken two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 64841\n",
      "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocabulary\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
    "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of our text vectorizer\n",
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token embedding layer\n",
    "token_embed = layers.Embedding(\n",
    "    input_dim=len(rct_20k_text_vocab),\n",
    "    output_dim=128, # Note: different embedding sizes result in drastically different numbers or parameters to train\n",
    "    mask_zero=True, # use masking to handel variable sequence length (even though our sequences have same length)\n",
    "    name=\"Token_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      "using rmn , only minor complications have been observed .\n",
      "\n",
      "Sentence after vectorization (before the embedding)\n",
      "[[   59 24777   192  1857   296    99   167   148     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "After embedding:\n",
      "[[[-0.00827924 -0.00923313 -0.02299832 ... -0.03150679 -0.04437449\n",
      "   -0.041615  ]\n",
      "  [ 0.0267673   0.04869017 -0.04702846 ... -0.00346637  0.03263528\n",
      "   -0.0202652 ]\n",
      "  [ 0.005765   -0.0431351   0.01921346 ... -0.04245947  0.00256307\n",
      "    0.01675477]\n",
      "  ...\n",
      "  [ 0.00633104  0.04751818  0.00355885 ... -0.01487952 -0.0412328\n",
      "    0.01929498]\n",
      "  [ 0.00633104  0.04751818  0.00355885 ... -0.01487952 -0.0412328\n",
      "    0.01929498]\n",
      "  [ 0.00633104  0.04751818  0.00355885 ... -0.01487952 -0.0412328\n",
      "    0.01929498]]]\n",
      "\n",
      "Embedded sentence shape: (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectorization (before the embedding)\\n{vectorized_sentence}\\n\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"After embedding:\\n{embedded_sentence}\\n\")\n",
    "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets (making sure our data loads as fast as possible)\n",
    "\n",
    "We're going to setup our data to run as fast as possible with the TensorFlow tf.data API, many of the steps here are discussed at length at these two ressources:\n",
    "- https://www.tensorflow.org/guide/data_performance\n",
    "- https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180040, 5)\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels_one_hot.shape)\n",
    "print(train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDatasets and turn them into prefetched datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Conv1D with token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D conv modcel to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs)\n",
    "token_embeddings = token_embed(text_vectors) \n",
    "x = layers.Conv1D(\n",
    "    64, # multiple of 8 calculates good\n",
    "    kernel_size=5, # looking at 5 words at once\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\"\n",
    ")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector from conv layer\n",
    "outputs = layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"softmax\",\n",
    ")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization (TextVect (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "Token_embedding (Embedding)  (None, 55, 128)           8299648   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 14s 9ms/step - loss: 0.9016 - accuracy: 0.6444 - val_loss: 0.6836 - val_accuracy: 0.7380\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 5s 9ms/step - loss: 0.6599 - accuracy: 0.7536 - val_loss: 0.6383 - val_accuracy: 0.7686\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 5s 9ms/step - loss: 0.6215 - accuracy: 0.7721 - val_loss: 0.5995 - val_accuracy: 0.7816\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "history_model_1 = model_1.fit(\n",
    "    train_dataset, # it's a touple, which loads pretty fast and can be passed to fit (no need to pass labels, since they are included)\n",
    "    steps_per_epoch=int(0.1*len(train_dataset)), # speed training up, since we want to find out what is not working and wand the models to fit fast\n",
    "    epochs=3,\n",
    "    validation_data=valid_dataset, # touple, too\n",
    "    validation_steps=int(0.1*len(valid_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.6015 - accuracy: 0.7847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6015000939369202, 0.7846550941467285]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.28313196e-01, 1.71670437e-01, 8.73082578e-02, 2.83935279e-01,\n",
       "         2.87728552e-02],\n",
       "        [4.24609870e-01, 3.08595181e-01, 1.28650386e-02, 2.44977087e-01,\n",
       "         8.95276759e-03],\n",
       "        [1.51463091e-01, 8.31937045e-03, 1.90679985e-03, 8.38277757e-01,\n",
       "         3.29952491e-05],\n",
       "        ...,\n",
       "        [4.11800465e-06, 6.25269371e-04, 8.20066605e-04, 2.99598082e-06,\n",
       "         9.98547494e-01],\n",
       "        [6.22810908e-02, 4.19206113e-01, 1.04004875e-01, 7.63412416e-02,\n",
       "         3.38166744e-01],\n",
       "        [1.65748000e-01, 6.76337719e-01, 4.57935967e-02, 4.71365750e-02,\n",
       "         6.49841428e-02]], dtype=float32),\n",
       " (30212, 5))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_1_pred_probs = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs, model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 4, 2, 4, 2, 4, 1], dtype=int64)>,\n",
       " TensorShape([30212]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds[:10], model_1_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BACKGROUND', 'BACKGROUND', 'OBJECTIVE', ..., 'RESULTS',\n",
       "       'CONCLUSIONS', 'CONCLUSIONS'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[model_1_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.46551039322124,\n",
       " 'precision': 0.7812610547462817,\n",
       " 'recall': 0.7846551039322124,\n",
       " 'f1': 0.7822841806288997}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels_encoded,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Feature extraction\n",
    "Now let's use pretrained word embeddings from TensorFlow Hub, more specifically universal sentence encoder (USE): https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "\n",
    "The paper originally used GloVe embeddings, however, we're going to stick with the later created USE pretrained embeddings.\n",
    "\n",
    "> ðŸ“– **Ressources:** For more information see:\n",
    "* GloVe: https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010\n",
    "* https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained TensorFlow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    trainable=False,\n",
    "    name=\"universal_sentence_encoder\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence:\n",
      "discrimination and risk reclassification metrics were used to assess the added value of galectin-@ and st@ in predicting mode of death risk beyond a clinical model that included nt-probnp .\n",
      "\n",
      "Sentence after embedding:\n",
      "[ 0.01098233 -0.02724998 -0.06629622 -0.05019914 -0.01089875 -0.08966617\n",
      " -0.0555408  -0.00703677  0.02692528  0.00270071  0.09094903 -0.03958034\n",
      "  0.01975885 -0.0539487  -0.05409431  0.02263735 -0.04695369  0.04972596\n",
      "  0.07060817 -0.03654463  0.05771256  0.06006123 -0.0465292  -0.00712325\n",
      "  0.04410044  0.00359965  0.03076302  0.02811777 -0.06198126  0.02095037]\n",
      "\n",
      "Length of sentence embedding: 512\n"
     ]
    }
   ],
   "source": [
    "# Test out pretrained embedding on a random sentence\n",
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f\"Random sentence:\\n{random_train_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
    "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]}\\n\")\n",
    "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and fitting a NLP feature extraction model using pretrained embeddings Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extration model using TF Hub layer\n",
    "inputs = layers.Input(shape=[], dtype=tf.string) # tf_hub_embedding layer expects an empty list as input\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding of each sequence (512 long vector)\n",
    "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_2.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "universal_sentence_encoder ( (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 9s 13ms/step - loss: 0.9168 - accuracy: 0.6486 - val_loss: 0.7972 - val_accuracy: 0.6912\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7683 - accuracy: 0.7011 - val_loss: 0.7538 - val_accuracy: 0.7038\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7500 - accuracy: 0.7120 - val_loss: 0.7358 - val_accuracy: 0.7178\n"
     ]
    }
   ],
   "source": [
    "history_model_2 = model_2.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "    epochs=3,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=int(0.1*len(valid_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 8s 9ms/step - loss: 0.7392 - accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.739204466342926, 0.7150139212608337]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_pred_probs = model_2.predict(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 71.50139017608898,\n",
       " 'precision': 0.7156629746548162,\n",
       " 'recall': 0.7150139017608897,\n",
       " 'f1': 0.7123270755925124}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels_encoded,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Conv1D with character embeddings\n",
    "\n",
    "The paper we're replicatin states they used a combination of token and character-level embeddings.\n",
    "\n",
    "Previously we've maken token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a character-level tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d i s c r i m i n a t i o n   a n d   r i s k   r e c l a s s i f i c a t i o n   m e t r i c s   w e r e   u s e d   t o   a s s e s s   t h e   a d d e d   v a l u e   o f   g a l e c t i n - @   a n d   s t @   i n   p r e d i c t i n g   m o d e   o f   d e a t h   r i s k   b e y o n d   a   c l i n i c a l   m o d e l   t h a t   i n c l u d e d   n t - p r o b n p   .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "# Text splitting non-character-level sequence into characters\n",
    "split_chars(random_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'o',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'v',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 'i',\n",
       " 'g',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'f',\n",
       " 'f',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'c',\n",
       " 'y',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " '@',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " '-',\n",
       " 'd',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 'd',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'v',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'p',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'b',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 's',\n",
       " 'y',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " '-',\n",
       " 'g',\n",
       " 'r',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 'f',\n",
       " 'l',\n",
       " 'a',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'h',\n",
       " 'o',\n",
       " 'r',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 'm',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'e',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'o',\n",
       " 'u',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'u',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " '@',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'o',\n",
       " 'l',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'd',\n",
       " 'u',\n",
       " 'l',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'k',\n",
       " 'n',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'o',\n",
       " 'a',\n",
       " 'r',\n",
       " 't',\n",
       " 'h',\n",
       " 'r',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " '(',\n",
       " ' ',\n",
       " 'o',\n",
       " 'a',\n",
       " ' ',\n",
       " ')',\n",
       " ' ',\n",
       " '.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(list(train_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
       " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split sequence-level data splits into character-level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the average character length?\n",
    "char_length = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_length)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWtUlEQVR4nO3df2zU9f3A8ac9WkUWuA4yGlpCm6UsxThDt7YYsi0TV1pcLMmI1szQIYFMZY7NRBr+GIv6hxgNNpvWyFCLw5y16CiZ/BJM9o+Ui8UCtrVXqECr5YeW6vQPpb6/fxjvC+NHkbS9Ks9Hcn/03btPX5/38J65+7S3q4CAJOmKlpbqASRJqWcMJEnGQJJkDCRJGANJEjAm1QNcruPHj3P48OFUjyFJ3xrTpk3jBz/4wXm/962NweHDhykqKkr1GJL0rRGPxy/4Pd8mkiQZA0mSMZAkYQwkSRgDSRLGQJKEMZAkYQwkSRgDSRLf4r9AHk0e3//mkB7v/utvHNLjSdJgfGUgSTIGkiRjIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJIlLjMHy5cs5cOAA+/fv58UXX+Tqq68mNzeX3bt3k0gkiMVipKenA5CRkUEsFiORSLB7926mTZuWPE51dTWJRIL29nZKS0uT63PnzqW9vZ1EIsGKFSuG+BQlSYMZNAZTpkzhvvvu46c//SnXX389kUiEyspKVq9ezZo1a8jPz6evr4/FixcDsHjxYvr6+sjPz2fNmjWsXr0agIKCAiorK7nuuusoKyvjqaeeIi0tjbS0NJ588knKy8uZMWMGd9xxBwUFBcN71pKks1zSK4MxY8YwduxYIpEI1157LR988AE33XQTDQ0NANTV1TF//nwAKioqqKurA6ChoYE5c+Yk12OxGJ9//jnvvfcenZ2dFBcXU1xcTGdnJ11dXXzxxRfEYjEqKiqG4VQlSRcyaAzef/99HnvsMY4cOcIHH3xAf38/b731FqdOnWJgYACA7u5usrOzAcjOzubo0aMADAwM0N/fz8SJE89aP/MxF1o/nyVLlhCPx4nH40yaNOnyz1qSdJZBYxCNRqmoqCAvL48pU6Ywbtw4ysrKRmK2c6xdu5aioiKKioo4efJkSmaQpO+iMYPd4eabb6arqyv55PvKK68we/ZsotEokUiEgYEBcnJy6OnpAaCnp4epU6fS09NDJBJhwoQJfPjhh8n1r535mAutS5JGxqCvDI4cOcKsWbMYO3YsAHPmzKG1tZU33niDBQsWAFBVVcWmTZsAaGxspKqqCoAFCxawa9eu5HplZSUZGRnk5uaSn5/Pnj17iMfj5Ofnk5ubS3p6OpWVlTQ2Ng7LyUqSzm/QVwZ79uyhoaGB5uZmTp8+zd69e3nmmWf497//TSwW4+GHH2bv3r2sW7cOgHXr1vHCCy+QSCT46KOPqKysBKC1tZX6+npaW1s5ffo09957L19++SUAy5YtY9u2bUQiEZ599llaW1uH8ZQlSf/rKiCkeojLEY/HKSoqSvUYADy+/80hPd791984pMeTJLj486Z/gSxJMgaSJGMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkLjEGEyZM4OWXX6atrY3W1lZmzZpFZmYm27dvp6Ojg+3btxONRpP3r6mpIZFI0NLSwsyZM5PrCxcupKOjg46ODhYuXJhcLywsZN++fSQSCWpqaobu7CRJl+SSYlBTU8PWrVspKCjghhtuoK2tjerqanbu3Mn06dPZuXMn1dXVAJSXl5Ofn09+fj5Lly6ltrYWgMzMTFatWkVJSQnFxcWsWrUqGZDa2lqWLFmSfFxZWdnwnK0k6bwGjcH48eP5+c9/zrp16wD44osv6O/vp6Kigrq6OgDq6uqYP38+ABUVFaxfvx6ApqYmotEoWVlZzJ07lx07dtDX18epU6fYsWMHZWVlZGVlMX78eJqamgBYv3598liSpJExaAzy8vI4ceIEzz33HM3Nzaxdu5Zrr72WyZMn09vbC0Bvby+TJ08GIDs7m6NHjyYf393dTXZ29kXXu7u7z1k/nyVLlhCPx4nH40yaNOnyzliSdI5BYzBmzBgKCwupra2lsLCQTz/9NPmW0JlCCMMy4JnWrl1LUVERRUVFnDx5cth/niRdKQaNQXd3N93d3ezZsweAhoYGCgsLOXbsGFlZWQBkZWVx/PhxAHp6epg6dWry8Tk5OfT09Fx0PScn55x1SdLIGTQGx44d4+jRo0yfPh2AOXPm0NraSmNjI1VVVQBUVVWxadMmABobG5O/KVRSUkJ/fz+9vb1s27aN0tJSotEo0WiU0tJStm3bRm9vLx9//DElJSXAV79x9PWxJEkjY8yl3OkPf/gDGzZsICMjg0OHDrFo0SLS0tKor69n8eLFHD58mNtuuw2A1157jXnz5tHZ2clnn33GokWLAOjr6+Ohhx4iHo8D8OCDD9LX1wfAPffcw/PPP8/YsWPZsmULW7ZsGY5zlSRdwFXA8L/ZPwzi8ThFRUWpHgOAx/e/OaTHu//6G4f0eJIEF3/e9C+QJUnGQJJkDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkoQxkCRhDCRJGANJEsZAkgSMSfUAqfD4/jdTPYIkjSq+MpAkGQNJkjGQJPENYpCWlkZzczObN28GIDc3l927d5NIJIjFYqSnpwOQkZFBLBYjkUiwe/dupk2bljxGdXU1iUSC9vZ2SktLk+tz586lvb2dRCLBihUrhurcJEmX6JJj8Mc//pG2trbk16tXr2bNmjXk5+fT19fH4sWLAVi8eDF9fX3k5+ezZs0aVq9eDUBBQQGVlZVcd911lJWV8dRTT5GWlkZaWhpPPvkk5eXlzJgxgzvuuIOCgoIhPk1J0sVcUgyys7O55ZZb+Mc//pFcu+mmm2hoaACgrq6O+fPnA1BRUUFdXR0ADQ0NzJkzJ7kei8X4/PPPee+99+js7KS4uJji4mI6Ozvp6uriiy++IBaLUVFRMZTnKEkaxCXF4IknnuCBBx7gyy+/BGDixImcOnWKgYEBALq7u8nOzga+CsfRo0cBGBgYoL+/n4kTJ561fuZjLrR+PkuWLCEejxOPx5k0adJlnK4k6XwGjcEtt9zC8ePHaW5uHol5Lmrt2rUUFRVRVFTEyZMnUz2OJH1nDPpHZ7Nnz+bWW29l3rx5XHPNNYwfP56amhqi0SiRSISBgQFycnLo6ekBoKenh6lTp9LT00MkEmHChAl8+OGHyfWvnfmYC61LkkbGoK8MVq5cydSpU8nLy6OyspJdu3Zx55138sYbb7BgwQIAqqqq2LRpEwCNjY1UVVUBsGDBAnbt2pVcr6ysJCMjg9zcXPLz89mzZw/xeJz8/Hxyc3NJT0+nsrKSxsbG4TpfSdJ5XPbHUaxYsYJYLMbDDz/M3r17WbduHQDr1q3jhRdeIJFI8NFHH1FZWQlAa2sr9fX1tLa2cvr0ae69997kNYhly5axbds2IpEIzz77LK2trUNwapKkS3UVEFI9xOWIx+MUFRVd1mNH+2cT3X/9jakeQdJ30MWeN/0LZEmSMZAkGQNJElfo/5/BaDcc1zS8DiHpYnxlIEkyBpIkYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiSMgSQJYyBJwhhIkjAGkiQuIQY5OTns2rWLd955hwMHDnDfffcBkJmZyfbt2+no6GD79u1Eo9HkY2pqakgkErS0tDBz5szk+sKFC+no6KCjo4OFCxcm1wsLC9m3bx+JRIKampohPD1J0qUYNAanT5/m/vvv57rrrmPWrFnce++9FBQUUF1dzc6dO5k+fTo7d+6kuroagPLycvLz88nPz2fp0qXU1tYCX8Vj1apVlJSUUFxczKpVq5IBqa2tZcmSJcnHlZWVDd8ZS5LOMWgMent72bt3LwD//e9/aWtrIzs7m4qKCurq6gCoq6tj/vz5AFRUVLB+/XoAmpqaiEajZGVlMXfuXHbs2EFfXx+nTp1ix44dlJWVkZWVxfjx42lqagJg/fr1yWNJkkbGN7pmMG3aNGbOnElTUxOTJ0+mt7cX+CoYkydPBiA7O5ujR48mH9Pd3U12dvZF17u7u89ZlySNnDGXesdx48axceNGli9fzieffHLO90MIQzrY+SxZsoSlS5cCMGnSpGH/eZJ0pbikVwZjxoxh48aNbNiwgVdffRWAY8eOkZWVBUBWVhbHjx8HoKenh6lTpyYfm5OTQ09Pz0XXc3Jyzlk/n7Vr11JUVERRUREnT578hqcqSbqQS4rBunXraGtrY82aNcm1xsZGqqqqAKiqqmLTpk3J9a9/U6ikpIT+/n56e3vZtm0bpaWlRKNRotEopaWlbNu2jd7eXj7++GNKSkqAr37j6OtjSZJGxqBvE82ePZuFCxeyb9++5IXklStX8sgjj1BfX8/ixYs5fPgwt912GwCvvfYa8+bNo7Ozk88++4xFixYB0NfXx0MPPUQ8HgfgwQcfpK+vD4B77rmH559/nrFjx7Jlyxa2bNkyLCcrSTq/q4Dhf7N/GMTjcYqKii7rsY/vf3OIpxn97r/+xlSPICnFLva86V8gS5KMgSTJGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAljIEnCGEiSMAaSJIyBJAkYk+oBNDIe3//mkB7v/utvHNLjSUotXxlIkoyBJMkYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScIYSJIwBpIkjIEkCWMgScKPsNZl8iOxpe8WXxlIkkZPDObOnUt7ezuJRIIVK1akehxJuqKMihikpaXx5JNPUl5ezowZM7jjjjsoKChI9ViSdMUYFdcMiouL6ezspKurC4BYLEZFRQVtbW0pnkwjZaivQQwHr2vou2xUxCA7O5ujR48mv+7u7qakpOSc+y1ZsoSlS5cC8KMf/Yh4PH5ZP2/S9yZx8uTJyxs2BSZN+vbM+22aFb7ZvJf7720ofZf3dzT4rs87bdq0i34/pPr2m9/8Jqxduzb59Z133hn+9re/DdvPi8fjKT/n7+q836ZZndd5nff/b6PimkFPTw9Tp05Nfp2Tk0NPT08KJ5KkK8uoiEE8Hic/P5/c3FzS09OprKyksbEx1WNJ0hVjVFwzGBgYYNmyZWzbto1IJMKzzz5La2vrsP28Z555ZtiOPRy+TfN+m2YF5x1uzju8hnLeq/jq/SJJ0hVsVLxNJElKLWMgSbqyYjAaP/IiJyeHXbt28c4773DgwAHuu+8+ADIzM9m+fTsdHR1s376daDSafExNTQ2JRIKWlhZmzpyZkrnT0tJobm5m8+bNAOTm5rJ7924SiQSxWIz09HQAMjIyiMViJBIJdu/ePejvOQ+HCRMm8PLLL9PW1kZrayuzZs0a1fu7fPlyDhw4wP79+3nxxRe5+uqrR9X+rlu3jmPHjrF///7k2uXs58KFC+no6KCjo4OFCxeO6LyPPvoobW1ttLS08MorrzBhwoTk96qrq0kkErS3t1NaWppcH6nnj/PN+7U///nPhBCYOHFicm0o9zflvys7Ere0tLTQ2dkZ8vLyQnp6enj77bdDQUFByufKysoKM2fODED43ve+F959991QUFAQVq9eHVasWBGAsGLFivDII48EIJSXl4fXXnstAKGkpCTs3r07JXP/6U9/Chs2bAibN28OQHjppZfC7bffHoBQW1sbfv/73wcg3H333aG2tjYA4fbbbw+xWGzEZ33++efD4sWLAxDS09PDhAkTRu3+TpkyJRw6dChcc801yX2tqqoaVfv7s5/9LMycOTPs378/ufZN9zMzMzMcPHgwZGZmhmg0Gg4ePBii0eiIzfurX/0qRCKRAIRHHnkkOW9BQUF4++23Q0ZGRsjNzQ2dnZ0hLS1tRJ8/zjcvEHJycsLWrVvDe++9FyZOnDgc+zty/9BTeZs1a1bYunVr8uvq6upQXV2d8rn+9/avf/0r3HzzzaG9vT1kZWUF+CoY7e3tAQhPP/10qKysTN7/zPuN1C07Ozu8/vrr4Ze//GUyBidOnEj+x3XmXm/dujXMmjUrACESiYQTJ06M6Kzjx48Phw4dOmd9tO7vlClTwpEjR0JmZmaIRCJh8+bNobS0dNTt77Rp0856svqm+1lZWRmefvrp5Pr/3m+45z3zNn/+/PDPf/4zwLnPC1/v70g/f5xv3pdffjn8+Mc/Dl1dXckYDOX+XjFvE53vIy+ys7NTONG5pk2bxsyZM2lqamLy5Mn09vYC0Nvby+TJk4HRcR5PPPEEDzzwAF9++SUAEydO5NSpUwwMDJwz05nzDgwM0N/ff9ZL3OGWl5fHiRMneO6552hubmbt2rVce+21o3Z/33//fR577DGOHDnCBx98QH9/P2+99dao3d+vfdP9TPU+n+muu+5iy5YtwOid99Zbb6Wnp4d9+/adtT6U814xMRjtxo0bx8aNG1m+fDmffPLJOd8PIaRgqnPdcsstHD9+nObm5lSPcknGjBlDYWEhtbW1FBYW8umnn1JdXX3O/UbL/kajUSoqKsjLy2PKlCmMGzeOsrKyVI/1jY2W/RzMypUrOX36NBs2bEj1KBc0duxYVq5cyV/+8pdh/TlXTAxG80dejBkzho0bN7JhwwZeffVVAI4dO0ZWVhYAWVlZHD9+HEj9ecyePZtbb72Vrq4uYrEYN910EzU1NUSjUSKRyDkznTlvJBJhwoQJfPjhhyM2b3d3N93d3ezZsweAhoYGCgsLR+3+3nzzzXR1dXHy5ElOnz7NK6+8wuzZs0ft/n7tm+5nqvcZoKqqil//+tf89re/Ta6Nxnl/+MMfkpeXR0tLC11dXeTk5NDc3MzkyZOHfN4ReY8x1bdIJBIOHjwYcnNzkxeAZsyYkfK5gFBXVxfWrFlz1tqjjz561gW51atXByDMmzfvrAtGTU1NKZv7F7/4RfKaQX19/VkXOO++++4AhHvuueesC5wvvfTSiM/5n//8J0yfPj0AYdWqVeHRRx8dtftbXFwcDhw4EMaOHRvgq4vfy5YtG3X7+7/vaX/T/czMzAyHDh0K0Wg0RKPRcOjQoZCZmTli886dOze88847YdKkSWfdb8aMGWddQD548GBIS0sb8eePi13jOPOawRDv78j9Q0/1rby8PLz77ruhs7MzrFy5MuXzAGH27NkhhBBaWlrC3r17w969e0N5eXn4/ve/H15//fXQ0dERduzYcdb/kH//+99DZ2dn2LdvX/jJT36SstnPjEFeXl5oamoKiUQi1NfXh4yMjACEq6++OtTX14dEIhGamppCXl7eiM95ww03hHg8HlpaWsKrr74aotHoqN7fv/71r6GtrS3s378/rF+/PmRkZIyq/X3xxRfD+++/Hz7//PNw9OjRcNddd13Wfi5atCgkEomQSCTC7373uxGdN5FIhCNHjiT/m/s6qEBYuXJl6OzsDO3t7aGsrCy5PlLPH+eb98zvnxmDodxfP45CknTlXDOQJF2YMZAkGQNJkjGQJGEMJEkYA0kSxkCSBPwf18jPEotfB9EAAAAASUVORK5CYII=",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"388.595918pt\" height=\"248.518125pt\" viewBox=\"0 0 388.595918 248.518125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-07-18T19:25:03.733365</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 388.595918 248.518125 \nL 388.595918 0 \nL 0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 46.0125 224.64 \nL 380.8125 224.64 \nL 380.8125 7.2 \nL 46.0125 7.2 \nz\n\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 61.230682 224.64 \nL 81.521591 224.64 \nL 81.521591 125.26018 \nL 61.230682 125.26018 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 81.521591 224.64 \nL 101.8125 224.64 \nL 101.8125 17.554286 \nL 81.521591 17.554286 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 101.8125 224.64 \nL 122.103409 224.64 \nL 122.103409 141.030799 \nL 101.8125 141.030799 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 122.103409 224.64 \nL 142.394318 224.64 \nL 142.394318 205.163263 \nL 122.103409 205.163263 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 142.394318 224.64 \nL 162.685227 224.64 \nL 162.685227 220.322349 \nL 142.394318 220.322349 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 162.685227 224.64 \nL 182.976136 224.64 \nL 182.976136 223.562318 \nL 162.685227 223.562318 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 182.976136 224.64 \nL 203.267045 224.64 \nL 203.267045 224.319234 \nL 182.976136 224.319234 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 203.267045 224.64 \nL 223.557955 224.64 \nL 223.557955 224.536155 \nL 203.267045 224.536155 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 223.557955 224.64 \nL 243.848864 224.64 \nL 243.848864 224.582308 \nL 223.557955 224.582308 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 243.848864 224.64 \nL 264.139773 224.64 \nL 264.139773 224.614616 \nL 243.848864 224.614616 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 264.139773 224.64 \nL 284.430682 224.64 \nL 284.430682 224.633077 \nL 264.139773 224.633077 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 284.430682 224.64 \nL 304.721591 224.64 \nL 304.721591 224.635385 \nL 284.430682 224.635385 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 304.721591 224.64 \nL 325.0125 224.64 \nL 325.0125 224.635385 \nL 304.721591 224.635385 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 325.0125 224.64 \nL 345.303409 224.64 \nL 345.303409 224.64 \nL 325.0125 224.64 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 345.303409 224.64 \nL 365.594318 224.64 \nL 365.594318 224.637692 \nL 345.303409 224.637692 \nz\n\" clip-path=\"url(#pfe861cfc11)\" style=\"fill: #8dd3c7\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m1ba779be00\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"61.010925\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(57.829675 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"104.962352\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(95.418602 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"148.91378\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(139.37003 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"192.865208\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(183.321458 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"236.816635\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(227.272885 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"280.768063\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(268.043063 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"324.71949\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 1200 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(311.99449 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m1ba779be00\" x=\"368.670918\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1400 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(355.945918 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path id=\"mdfa8bb61f0\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mdfa8bb61f0\" x=\"46.0125\" y=\"224.64\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(32.65 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mdfa8bb61f0\" x=\"46.0125\" y=\"178.486595\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 182.285813)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mdfa8bb61f0\" x=\"46.0125\" y=\"132.333189\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 40000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 136.132408)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mdfa8bb61f0\" x=\"46.0125\" y=\"86.179784\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 60000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 89.979003)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#mdfa8bb61f0\" x=\"46.0125\" y=\"40.026379\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 80000 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 43.825598)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 46.0125 224.64 \nL 46.0125 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 380.8125 224.64 \nL 380.8125 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 46.0125 224.64 \nL 380.8125 224.64 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 46.0125 7.2 \nL 380.8125 7.2 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfe861cfc11\">\n   <rect x=\"46.0125\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of our sequences at a character-level\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(char_length, bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find what character-length covers 95% of sequences\n",
    "output_seq_char_len = int(np.percentile(char_length, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~', 68)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all keyboard characters\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet, len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char-level token vectorizer instance\n",
    "NUM_CHAR_TOKEN = len(alphabet) + 2 # add 2 for space and OOV (Out Of Vocab, '[UNK]') token\n",
    "char_vectorizer = TextVectorization(\n",
    "    max_tokens=NUM_CHAR_TOKEN,\n",
    "    output_sequence_length=output_seq_char_len,\n",
    "    # standardize=\"lower_and_strip_punctuation\", # None, if you want to leave punctuation in\n",
    "    name=\"char_vectorizer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptr character vectorizer to training character\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different character in character vocab: 28\n",
      "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
      "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocab stats\n",
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f\"Number of different character in character vocab: {len(char_vocab)}\")\n",
    "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
    "print(f\"5 least common characters: {char_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "t h e   d i f f e r e n c e   i n   t h e   m e a n   b g   o f   t h e   g r o u p s   w a s   @   m g / d l   w i t h   a   @ - s i d e d   u p p e r   @   %   c o n f i d e n c e   l i m i t   o f   @   m g / d l   (   l e s s   t h a n   t h e   m a x i m a l   a c c e p t a b l e   d i f f e r e n c e   o f   @   m g / d l   ;   p   =   @   )   .\n",
      "\n",
      "Length of random_train_chars: 139\n",
      "\n",
      "Vectorized chars:\n",
      "[[ 3 13  2 10  4 17 17  2  8  2  6 11  2  4  6  3 13  2 15  2  5  6 22 18\n",
      "   7 17  3 13  2 18  8  7 16 14  9 20  5  9 15 18 10 12 20  4  3 13  5  9\n",
      "   4 10  2 10 16 14 14  2  8 11  7  6 17  4 10  2  6 11  2 12  4 15  4  3\n",
      "   7 17 15 18 10 12 12  2  9  9  3 13  5  6  3 13  2 15  5 24  4 15  5 12\n",
      "   5 11 11  2 14  3  5 22 12  2 10  4 17 17  2  8  2  6 11  2  7 17 15 18\n",
      "  10 12 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Length of vectorized chars: 290\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f\"Charified text:\\n{random_train_chars}\\n\")\n",
    "print(f\"Length of random_train_chars: {len(random_train_chars.split())}\")\n",
    "vectorized_chars = char_vectorizer([random_train_chars])\n",
    "print(f\"\\nVectorized chars:\\n{vectorized_chars}\\n\")\n",
    "print(f\"Length of vectorized chars: {len(vectorized_chars[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a character-level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create char embedding layer\n",
    "char_embed = layers.Embedding(\n",
    "    input_dim=len(char_vocab), # number of different characters\n",
    "    output_dim=25, # this is the size of the char embedding in the paper: https://arxiv.org/pdf/1612.0521.pdf (Figure 1)\n",
    "    mask_zero=True,\n",
    "    name=\"char_embed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "t h e   d i f f e r e n c e   i n   t h e   m e a n   b g   o f   t h e   g r o u p s   w a s   @   m g / d l   w i t h   a   @ - s i d e d   u p p e r   @   %   c o n f i d e n c e   l i m i t   o f   @   m g / d l   (   l e s s   t h a n   t h e   m a x i m a l   a c c e p t a b l e   d i f f e r e n c e   o f   @   m g / d l   ;   p   =   @   )   .\n",
      "\n",
      "Embedded chars: (after vectorization and embedding)\n",
      "[[[-0.03407185  0.03363922  0.017402   ...  0.02730198 -0.03647494\n",
      "    0.03924633]\n",
      "  [ 0.00169531 -0.02311249  0.04158517 ... -0.02193321  0.04871334\n",
      "   -0.04876667]\n",
      "  [ 0.02889205  0.02798403  0.01500044 ... -0.02886503 -0.03980403\n",
      "   -0.03646337]\n",
      "  ...\n",
      "  [ 0.03410124 -0.00817337 -0.03914834 ... -0.00961565 -0.00405387\n",
      "   -0.01287712]\n",
      "  [ 0.03410124 -0.00817337 -0.03914834 ... -0.00961565 -0.00405387\n",
      "   -0.01287712]\n",
      "  [ 0.03410124 -0.00817337 -0.03914834 ... -0.00961565 -0.00405387\n",
      "   -0.01287712]]]\n",
      "Char embedding shape: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test out character embedding layer\n",
    "print(f\"Charified text:\\n{random_train_chars}\\n\")\n",
    "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
    "print(f\"Embedded chars: (after vectorization and embedding)\\n{char_embed_example}\")\n",
    "print(f\"Char embedding shape: {char_embed_example.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_train_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Conv1D model to fit on character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Conv1D on chars only\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_Conv1D_char_embeddings\")\n",
    "\n",
    "model_3.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_Conv1D_char_embeddings\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "char_vectorizer (TextVectori (None, 290)               0         \n",
      "_________________________________________________________________\n",
      "char_embed (Embedding)       (None, 290, 25)           700       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 290, 64)           8064      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create char level datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 180040, 30135, 30135)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_chars), len(train_labels_one_hot), len(test_chars), len(test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 3s 6ms/step - loss: 0.8034 - accuracy: 0.6874 - val_loss: 0.8566 - val_accuracy: 0.6609\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 3s 5ms/step - loss: 0.8651 - accuracy: 0.6594 - val_loss: 0.8226 - val_accuracy: 0.6842\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 3s 5ms/step - loss: 0.8459 - accuracy: 0.6700 - val_loss: 0.8100 - val_accuracy: 0.6792\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_3.fit(\n",
    "    train_char_dataset,\n",
    "    steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
    "    epochs=3,\n",
    "    validation_data=val_char_dataset,\n",
    "    validation_steps=int(0.1*len(val_char_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step - loss: 0.8201 - accuracy: 0.6808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8200764656066895, 0.6807891130447388]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 68.07890904276447,\n",
       " 'precision': 0.6840794940056418,\n",
       " 'recall': 0.6807890904276447,\n",
       " 'f1': 0.6750687414884535}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels_encoded,\n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Combining pretrained token embeddings + characters embeddings (hybrid embedding layer)\n",
    "1. Create a token-level embedding (similar `model_1`)\n",
    "2. Create a character-level model (similar `model_3`)\n",
    "3. Combine (1) & (2) with a concatenate layer (`layers.concatenat`)\n",
    "4. Build a series of output layers on top of (3) similar to Figure 1 and section 4.2 of the paper: https://arxiv.org/pdf/1612.05251.pdf\n",
    "5. Construct a model which takes token and character-level sequence as input an produces sequence label probabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63418e73e250c304d26eaf03185e2f59ff2277f62dd1cc8bba54019c2c46cc60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
