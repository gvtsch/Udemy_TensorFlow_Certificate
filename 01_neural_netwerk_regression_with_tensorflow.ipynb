{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter ... predicting a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ðŸ”‘ **Note:** Hyperparameter\n",
    "* Input layer shape: Same shape as number of features(e.g. # bedrooms, # bathrooms, ...)\n",
    "* Hidden layer(s): Problem specific, minimum = 1, maximum = unlimited\n",
    "* Neurons per hidden layer: Problem specific, generally 10 to 100\n",
    "* Output layer shape: Same shape as desired prediction shape\n",
    "* Hidden activation: Usually ReLU\n",
    "* Output activation: None, ReLU, tanh\n",
    "* Loss function: MSE, MAE\n",
    "* Optimizer: SGD, Adam, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating some data to view and to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1966651d220>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7., -4., -1., 2., 5., 8., 11., 14.])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3., 6., 9., 12., 15., 18., 21., 24])\n",
    "\n",
    "# Visualize\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the relationship our neural network should learn\n",
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939_700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our NumPy arrays into tensors\n",
    "X = tf.constant(X, dtype=tf.float32)\n",
    "y = tf.constant(y, dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how ring it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation matrix (what we can use to interpret the performance of our model)\n",
    "3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19666a58490>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)]) # This way we're adding Layers like in a list. We can also use `model.add`\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # mean absolute error of predicted values\n",
    "    optimizer=tf.keras.optimizers.SGD(), # stochastic gradient descent\n",
    "    metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we tool to create a model\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might chagen the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9262 - mae: 6.9262\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19667c71c70>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "# 1. Create a model (specified to your problem)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # mean absolute error of predicted values\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model (train for longer this time)\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>,\n",
       " array([[29.739855]], dtype=float32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.])\n",
    "X, y, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 11.7683 - mae: 11.7683\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0964 - mae: 11.0964\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4150 - mae: 10.4150\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7211 - mae: 9.7211\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0105 - mae: 9.0105\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2779 - mae: 8.2779\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5200 - mae: 7.5200\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9648 - mae: 6.9648\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0674 - mae: 7.0674\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3316 - mae: 7.3316\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4673 - mae: 7.4673\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5290 - mae: 7.5290\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4016 - mae: 7.4016\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1921 - mae: 7.1921\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9573 - mae: 6.9573\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6951 - mae: 6.6951\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4128 - mae: 6.4128\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3048 - mae: 6.3048\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2575 - mae: 6.2575\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3980 - mae: 6.3980\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4549 - mae: 6.4549\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4001 - mae: 6.4001\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2484 - mae: 6.2484\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0103 - mae: 6.0103\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7876 - mae: 5.7876\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6809 - mae: 5.6809\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5715 - mae: 5.5715\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6125 - mae: 5.6125\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5541 - mae: 5.5541\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4569 - mae: 5.4569\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3200 - mae: 5.3200\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1472 - mae: 5.1472\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9440 - mae: 4.9440\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8239 - mae: 4.8239\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7389 - mae: 4.7389\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6661 - mae: 4.6661\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5844 - mae: 4.5844\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4027 - mae: 4.4027\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2653 - mae: 4.2653\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1212 - mae: 4.1212\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9702 - mae: 3.9702\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8272 - mae: 3.8272\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7044 - mae: 3.7044\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5317 - mae: 3.5317\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3664 - mae: 3.3664\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2116 - mae: 3.2116\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0463 - mae: 3.0463\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8705 - mae: 2.8705\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6840 - mae: 2.6840\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4868 - mae: 2.4868\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2787 - mae: 2.2787\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0596 - mae: 2.0596\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8293 - mae: 1.8293\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5876 - mae: 1.5876\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3531 - mae: 1.3531\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0850 - mae: 1.0850\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8224 - mae: 0.8224\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5467 - mae: 0.5467\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2755 - mae: 0.2755\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1350 - mae: 0.1350\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4493 - mae: 0.4493\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6499 - mae: 0.6499\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6216 - mae: 0.6216\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8027 - mae: 0.8027\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7992 - mae: 0.7992\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7408 - mae: 0.7408\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7812 - mae: 0.7812\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6305 - mae: 0.6305\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5554 - mae: 0.5554\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4307 - mae: 0.4307\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2788 - mae: 0.2788\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1380 - mae: 0.1380\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1191 - mae: 0.1191\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2780 - mae: 0.2780\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3237 - mae: 0.3237\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4154 - mae: 0.4154\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4314 - mae: 0.4314\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3389 - mae: 0.3389\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2969 - mae: 0.2969\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2363 - mae: 0.2363\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1628 - mae: 0.1628\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1351 - mae: 0.1351\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1253 - mae: 0.1253\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1708 - mae: 0.1708\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2119 - mae: 0.2119\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2282 - mae: 0.2282\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1901 - mae: 0.1901\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1352 - mae: 0.1352\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1214 - mae: 0.1214\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0379 - mae: 0.0379\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2195 - mae: 0.2195\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2185 - mae: 0.2185\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1429 - mae: 0.1429\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1179 - mae: 0.1179\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2066 - mae: 0.2066\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1516 - mae: 0.1516\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2140 - mae: 0.2140\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2333 - mae: 0.2333\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0779 - mae: 0.0779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19668134460>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "# 1. Create a model (specified to your problem)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae, # mean absolute error of predicted values\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01), # stochastic gradient descent\n",
    "    metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model (train for longer this time)\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>,\n",
       " array([[26.587622]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.])\n",
    "X, y, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "In practive, a typical workflow you'll go through when build neural networks is:\n",
    "`Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> ...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to evalution... ther are 3 words you should memorize:\n",
    ">`Visualize, visualize, visualize:`\n",
    "\n",
    "It's a good idea to visualize:\n",
    "* The data - what data are we working with? What does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x19667bc9040>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 3 sets ...\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available\n",
    "* **Test set** - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 are the training samples (80% of the data)\n",
    "y_train = y[:40]\n",
    "X_test = X[40:] # 20% of the data\n",
    "y_test = y[40:]\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "Now we've got our data in training and test sets... let's visualize it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1967e132370>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"blue\", label=\"Training data\")\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"green\", label=\"Testing data\")\n",
    "# show legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5273 - mae: 10.5273\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3906 - mae: 9.3906\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6292 - mae: 7.6292\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6859 - mae: 9.6859\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0740 - mae: 11.0740\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2264 - mae: 10.2264\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2347 - mae: 9.2347\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.1547 - mae: 9.1547\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7875 - mae: 11.7875\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7172 - mae: 13.7172\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8015 - mae: 11.8015\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3555 - mae: 16.3555\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9043 - mae: 11.9043\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8239 - mae: 13.8239\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2084 - mae: 11.2084\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5877 - mae: 8.5877\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7567 - mae: 13.7567\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6177 - mae: 11.6177\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7100 - mae: 17.7100\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.8462 - mae: 14.8462\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7513 - mae: 10.7513\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4917 - mae: 8.4917\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.7766 - mae: 9.7766\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.8531 - mae: 10.8531\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1113 - mae: 9.1113\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0840 - mae: 13.0840\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4066 - mae: 10.4066\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4238 - mae: 13.4238\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.6076 - mae: 9.6076\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2601 - mae: 17.2601\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.8003 - mae: 22.8003\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9049 - mae: 7.9049\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.1734 - mae: 14.1734\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4283 - mae: 12.4283\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2339 - mae: 8.2339\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4408 - mae: 10.4408\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0926 - mae: 10.0926\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2658 - mae: 11.2658\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7947 - mae: 14.7947\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9246 - mae: 12.9246\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3199 - mae: 9.3199\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9560 - mae: 10.9560\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3161 - mae: 8.3161\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9795 - mae: 12.9795\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7222 - mae: 13.7222\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4129 - mae: 8.4129\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.1536 - mae: 9.1536\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6543 - mae: 10.6543\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7674 - mae: 7.7674\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5726 - mae: 9.5726\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1575 - mae: 9.1575\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4515 - mae: 16.4515\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0818 - mae: 14.0818\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.0172 - mae: 21.0172\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4738 - mae: 16.4738\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8662 - mae: 9.8662\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6413 - mae: 9.6413\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9628 - mae: 8.9628\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1686 - mae: 10.1686\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4129 - mae: 8.4129\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2533 - mae: 9.2533\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0626 - mae: 7.0626\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6398 - mae: 8.6398\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2166 - mae: 9.2166\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.4767 - mae: 10.4767\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6303 - mae: 15.6303\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.0248 - mae: 10.0248\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0030 - mae: 9.0030\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4993 - mae: 12.4993\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9709 - mae: 8.9709\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9493 - mae: 9.9493\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9817 - mae: 9.9817\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4756 - mae: 12.4756\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5140 - mae: 10.5140\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.6442 - mae: 9.6442\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.1190 - mae: 11.1190\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2914 - mae: 8.2914\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9997 - mae: 8.9997\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.7057 - mae: 19.7057\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.8733 - mae: 17.8733\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0400 - mae: 7.0400\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4264 - mae: 10.4264\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8572 - mae: 9.8572\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.9069 - mae: 7.9069\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4048 - mae: 9.4048\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2307 - mae: 9.2307\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.0129 - mae: 12.0129\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6296 - mae: 10.6296\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.2506 - mae: 7.2506\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7702 - mae: 12.7702\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4544 - mae: 7.4544\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7385 - mae: 6.7385\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.9206 - mae: 11.9206\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6966 - mae: 7.6966\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7327 - mae: 6.7327\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6033 - mae: 8.6033\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3858 - mae: 9.3858\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1203 - mae: 9.1203\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4808 - mae: 10.4808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1967e1944c0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at how to build a neural network four our data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "# 2. Compile the mdoel\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1])\n",
    "    ])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.mae,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[\"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total params - total number of parameters in the model.\n",
    "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
    "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learned parameters from other models during **transfer learning**)\n",
    "\n",
    "> ðŸ“– **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8429 - mae: 12.8429\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.7871 - mae: 7.7871\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9179 - mae: 9.9179\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5446 - mae: 8.5446\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5981 - mae: 7.5981\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.9227 - mae: 6.9227\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.0363 - mae: 4.0363\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6187 - mae: 5.6187\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.0543 - mae: 18.0543\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.5911 - mae: 6.5911\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.3830 - mae: 5.3830\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9490 - mae: 9.9490\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.9080 - mae: 10.9080\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.9784 - mae: 18.9784\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4820 - mae: 7.4820\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0777 - mae: 7.0777\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5107 - mae: 7.5107\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.2199 - mae: 11.2199\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.1667 - mae: 13.1667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9937 - mae: 9.9937\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0252 - mae: 9.0252\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7196 - mae: 10.7196\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 5.1342 - mae: 5.1342\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.7938 - mae: 6.7938\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0219 - mae: 11.0219\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7294 - mae: 12.7294\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7187 - mae: 9.7187\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.4194 - mae: 13.4194\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.9582 - mae: 6.9582\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.8525 - mae: 17.8525\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.5837 - mae: 20.5837\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.8548 - mae: 5.8548\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.1548 - mae: 7.1548\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2749 - mae: 12.2749\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4441 - mae: 5.4441\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8082 - mae: 6.8082\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.9796 - mae: 5.9796\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2574 - mae: 9.2574\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2617 - mae: 7.2617\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0524 - mae: 10.0524\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8680 - mae: 10.8680\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4886 - mae: 9.4886\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.4071 - mae: 5.4071\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6613 - mae: 14.6613\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3421 - mae: 12.3421\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6023 - mae: 5.6023\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9992 - mae: 7.9992\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7781 - mae: 7.7781\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7473 - mae: 5.7473\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.8147 - mae: 8.8147\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2319 - mae: 6.2319\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4047 - mae: 18.4047\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6566 - mae: 11.6566\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3838 - mae: 17.3838\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.3495 - mae: 17.3495\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2031 - mae: 8.2031\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4406 - mae: 8.4406\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.6031 - mae: 5.6031\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.4873 - mae: 6.4873\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0098 - mae: 7.0098\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7263 - mae: 6.7263\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9229 - mae: 8.9229\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7760 - mae: 7.7760\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.8219 - mae: 7.8219\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4810 - mae: 9.4810\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.9724 - mae: 8.9724\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9305 - mae: 10.9305\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5398 - mae: 9.5398\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5254 - mae: 8.5254\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.3670 - mae: 4.3670\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4411 - mae: 8.4411\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.8203 - mae: 9.8203\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6109 - mae: 7.6109\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.4596 - mae: 14.4596\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.8768 - mae: 3.8768\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.0887 - mae: 5.0887\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3377 - mae: 11.3377\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7626 - mae: 11.7626\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0558 - mae: 14.0558\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1281 - mae: 10.1281\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5219 - mae: 9.5219\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4114 - mae: 7.4114\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.8352 - mae: 5.8352\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.2018 - mae: 6.2018\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2787 - mae: 14.2787\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5813 - mae: 11.5813\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4014 - mae: 10.4014\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.8273 - mae: 7.8273\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3577 - mae: 7.3577\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0397 - mae: 10.0397\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3293 - mae: 7.3293\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6371 - mae: 11.6371\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.7586 - mae: 4.7586\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7613 - mae: 9.7613\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5638 - mae: 11.5638\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7345 - mae: 7.7345\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5471 - mae: 10.5471\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.7929 - mae: 7.7929\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1990 - mae: 8.1990\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3843 - mae: 11.3843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19666510850>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "# Every time i fit the model without reinstantiating it, it updates the actual training model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63418e73e250c304d26eaf03185e2f59ff2277f62dd1cc8bba54019c2c46cc60"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
