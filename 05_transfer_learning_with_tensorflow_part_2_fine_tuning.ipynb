{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
    "In the previous notebook, we covered transfer learning feature extraction now it's time to learn about a new kind of transfer learning: fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 23 13:44:10 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.40       Driver Version: 516.40       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   60C    P3    27W /  N/A |      0MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check if we're using a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating helper funtions\n",
    "In previous, we've created a bunch of helper functions, now we could rewrite them all, however this is tedious.\n",
    "\n",
    "So it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere).\n",
    "\n",
    "We've done this for some of the functions we've used previously here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under helper_functions (1).py\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions we're going to use in this notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ”‘ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete `helper functions.py`, so you'll have to redownload it if you want access to your helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some data\n",
    "\n",
    "This time we're going to see how we can use the pretrained models within tf.keras.applications and apply them to our own problem (recognizing images of food).\n",
    "\n",
    "link: https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under 10_food_classes_10_percent (1).zip\n"
     ]
    }
   ],
   "source": [
    "# Get 10% of training data of 10 classes of Food101.\n",
    "!python -m wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip_data(\"10_food_classes_10_percent\")\n",
    "# Already existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\test'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_curry'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_wings'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\fried_rice'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\grilled_salmon'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\hamburger'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ice_cream'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\pizza'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ramen'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\steak'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\sushi'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\train'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_curry'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_wings'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\fried_rice'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\grilled_salmon'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\hamburger'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ice_cream'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\pizza'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ramen'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\steak'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\sushi'.\n"
     ]
    }
   ],
   "source": [
    "# Check out how many images and subdirectories are in our dataset\n",
    "walk_through_dir(\"10_food_classes_10_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test directory paths\n",
    "train_dir = \"10_food_classes_10_percent/train\"\n",
    "test_dir = \"10_food_classes_10_percent/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 files belonging to 10 classes.\n",
      "Found 2500 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chicken_curry',\n",
       " 'chicken_wings',\n",
       " 'fried_rice',\n",
       " 'grilled_salmon',\n",
       " 'hamburger',\n",
       " 'ice_cream',\n",
       " 'pizza',\n",
       " 'ramen',\n",
       " 'steak',\n",
       " 'sushi']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the class names of our dataset\n",
    "train_data_10_percent.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[2.01928574e+02 1.69928574e+02 1.18928574e+02]\n",
      "   [2.14454071e+02 1.82454071e+02 1.33454071e+02]\n",
      "   [1.97903061e+02 1.66903061e+02 1.20117348e+02]\n",
      "   ...\n",
      "   [3.36717868e+00 5.36717892e+00 1.37741089e+00]\n",
      "   [1.14797192e+01 1.64797192e+01 1.04797192e+01]\n",
      "   [2.50867577e+01 3.00867577e+01 2.40867577e+01]]\n",
      "\n",
      "  [[2.05785721e+02 1.74857147e+02 1.27642860e+02]\n",
      "   [2.19790817e+02 1.88790817e+02 1.42653061e+02]\n",
      "   [2.16255096e+02 1.85255096e+02 1.39255096e+02]\n",
      "   ...\n",
      "   [2.44872928e-01 1.45913684e+00 0.00000000e+00]\n",
      "   [3.06151628e-01 4.44391870e+00 1.68384671e-01]\n",
      "   [4.85717583e+00 9.85717583e+00 3.85717583e+00]]\n",
      "\n",
      "  [[2.15158157e+02 1.88801010e+02 1.44015305e+02]\n",
      "   [2.29928574e+02 2.01357147e+02 1.57571426e+02]\n",
      "   [2.19668365e+02 1.90193878e+02 1.46668365e+02]\n",
      "   ...\n",
      "   [2.45408726e+00 4.68881512e+00 5.96943855e-01]\n",
      "   [1.69897783e+00 4.69897795e+00 8.41834486e-01]\n",
      "   [9.94891107e-01 4.42346287e+00 5.66319406e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.23173470e+02 1.27744934e+02 9.59592056e+01]\n",
      "   [1.23923409e+02 1.28494888e+02 9.67091446e+01]\n",
      "   [1.28168365e+02 1.33168365e+02 1.01168373e+02]\n",
      "   ...\n",
      "   [1.58933594e+02 1.89362122e+02 1.87576385e+02]\n",
      "   [1.56770432e+02 1.88770432e+02 1.86198959e+02]\n",
      "   [1.52510086e+02 1.84510086e+02 1.81938614e+02]]\n",
      "\n",
      "  [[1.25290802e+02 1.30290802e+02 9.82908020e+01]\n",
      "   [1.28775497e+02 1.33775497e+02 1.01775497e+02]\n",
      "   [1.20999962e+02 1.26999962e+02 9.29999619e+01]\n",
      "   ...\n",
      "   [1.67719330e+02 1.98290802e+02 1.93505066e+02]\n",
      "   [1.56010208e+02 1.88010208e+02 1.83010208e+02]\n",
      "   [1.57989960e+02 1.92989960e+02 1.86989960e+02]]\n",
      "\n",
      "  [[1.23790855e+02 1.28790863e+02 9.67908554e+01]\n",
      "   [1.23984604e+02 1.29984604e+02 9.59846039e+01]\n",
      "   [1.24066528e+02 1.30066528e+02 9.60665283e+01]\n",
      "   ...\n",
      "   [1.63331650e+02 1.93903122e+02 1.88117386e+02]\n",
      "   [1.62403107e+02 1.95403107e+02 1.88403107e+02]\n",
      "   [1.59867477e+02 1.94867477e+02 1.87867477e+02]]]\n",
      "\n",
      "\n",
      " [[[2.35153065e+01 1.35153065e+01 1.25153065e+01]\n",
      "   [2.98571434e+01 1.98571434e+01 1.88571434e+01]\n",
      "   [3.63418350e+01 2.63418369e+01 2.53418369e+01]\n",
      "   ...\n",
      "   [8.48212433e+01 5.13927155e+01 3.17499237e+01]\n",
      "   [7.73060379e+01 4.55203590e+01 3.04489174e+01]\n",
      "   [6.68418121e+01 3.88418121e+01 2.48418140e+01]]\n",
      "\n",
      "  [[2.17091827e+01 1.17091837e+01 1.07091837e+01]\n",
      "   [2.11377544e+01 1.11377544e+01 1.01377544e+01]\n",
      "   [3.42397957e+01 2.42397976e+01 2.32397976e+01]\n",
      "   ...\n",
      "   [7.42040329e+01 4.07755051e+01 2.15306320e+01]\n",
      "   [7.66326904e+01 4.57092514e+01 2.80511093e+01]\n",
      "   [8.68573227e+01 5.88573227e+01 4.48573227e+01]]\n",
      "\n",
      "  [[2.54285717e+01 1.54285717e+01 1.44285717e+01]\n",
      "   [2.14132652e+01 1.14132652e+01 1.04132652e+01]\n",
      "   [2.53367348e+01 1.53367357e+01 1.43367348e+01]\n",
      "   ...\n",
      "   [9.58163223e+01 6.08163223e+01 4.16020584e+01]\n",
      "   [8.70611572e+01 5.62040405e+01 3.82040405e+01]\n",
      "   [7.44335098e+01 4.74335060e+01 3.00049343e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.11918320e+02 1.49132584e+02 7.25611115e+01]\n",
      "   [2.03658112e+02 1.40872375e+02 6.43009109e+01]\n",
      "   [2.06214325e+02 1.44214325e+02 6.76428604e+01]\n",
      "   ...\n",
      "   [2.04535934e+02 1.40750198e+02 7.61074066e+01]\n",
      "   [2.21648132e+02 1.57816528e+02 9.59746628e+01]\n",
      "   [2.26229553e+02 1.63586761e+02 1.03229561e+02]]\n",
      "\n",
      "  [[2.07117371e+02 1.44117371e+02 6.51173706e+01]\n",
      "   [2.10209274e+02 1.47209274e+02 6.82092590e+01]\n",
      "   [2.18199020e+02 1.55413300e+02 7.84132996e+01]\n",
      "   ...\n",
      "   [2.20816345e+02 1.59530701e+02 9.40460434e+01]\n",
      "   [2.20520325e+02 1.62943863e+02 9.88009872e+01]\n",
      "   [2.17663223e+02 1.62811218e+02 9.87857056e+01]]\n",
      "\n",
      "  [[2.15484818e+02 1.49484818e+02 7.14848099e+01]\n",
      "   [2.16979599e+02 1.53979599e+02 7.49795990e+01]\n",
      "   [2.17724365e+02 1.54724365e+02 7.61529388e+01]\n",
      "   ...\n",
      "   [2.18918289e+02 1.59642822e+02 9.33520279e+01]\n",
      "   [2.13714264e+02 1.60857147e+02 9.48571472e+01]\n",
      "   [2.13372177e+02 1.63545746e+02 9.79589615e+01]]]\n",
      "\n",
      "\n",
      " [[[5.10000000e+01 6.10000000e+01 6.30000000e+01]\n",
      "   [5.10255089e+01 6.10255089e+01 6.30255089e+01]\n",
      "   [4.75663261e+01 5.75663261e+01 5.93520393e+01]\n",
      "   ...\n",
      "   [7.29948196e+01 3.87805557e+01 1.31377621e+01]\n",
      "   [7.13061371e+01 3.72346954e+01 1.08265114e+01]\n",
      "   [7.50153656e+01 3.73010063e+01 7.58665228e+00]]\n",
      "\n",
      "  [[4.58571396e+01 5.58571396e+01 5.78571396e+01]\n",
      "   [4.81428566e+01 5.81428566e+01 6.01428566e+01]\n",
      "   [4.61428566e+01 5.61428566e+01 5.79285698e+01]\n",
      "   ...\n",
      "   [7.27194672e+01 3.89031219e+01 1.10919819e+01]\n",
      "   [8.04438934e+01 4.63724556e+01 1.82958965e+01]\n",
      "   [7.99336777e+01 4.28621483e+01 1.05049706e+01]]\n",
      "\n",
      "  [[4.17857132e+01 5.13571434e+01 5.33571434e+01]\n",
      "   [4.18571396e+01 5.14285698e+01 5.34285698e+01]\n",
      "   [3.79540825e+01 4.75255089e+01 4.87397957e+01]\n",
      "   ...\n",
      "   [6.70713425e+01 3.56428146e+01 6.21428585e+00]\n",
      "   [6.96020737e+01 3.64591904e+01 5.38774776e+00]\n",
      "   [7.32908936e+01 3.65765381e+01 1.79078960e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.42756348e+01 3.51328201e+01 1.15716248e+01]\n",
      "   [1.49010513e+02 9.11687469e+01 6.44544373e+01]\n",
      "   [1.58347092e+02 9.83011932e+01 6.99185333e+01]\n",
      "   ...\n",
      "   [1.64336411e+02 1.72650852e+01 2.70508213e+01]\n",
      "   [1.64290863e+02 2.36481304e+01 3.25766907e+01]\n",
      "   [1.54157654e+02 1.74434891e+01 2.49485779e+01]]\n",
      "\n",
      "  [[8.81276779e+01 2.75817280e+01 2.02042508e+00]\n",
      "   [1.17601906e+02 5.63926849e+01 2.75151405e+01]\n",
      "   [1.05841675e+02 4.45559120e+01 1.56885872e+01]\n",
      "   ...\n",
      "   [1.63627609e+02 2.20868702e+01 3.10715637e+01]\n",
      "   [1.57504822e+02 2.06426086e+01 3.06426086e+01]\n",
      "   [1.36887527e+02 1.79069400e+00 1.12906332e+01]]\n",
      "\n",
      "  [[1.08479599e+02 4.31224213e+01 1.07907543e+01]\n",
      "   [1.10153038e+02 4.47958603e+01 1.39896746e+01]\n",
      "   [9.79337158e+01 3.07041016e+01 4.20921040e+00]\n",
      "   ...\n",
      "   [1.61025253e+02 2.09640560e+01 2.96732635e+01]\n",
      "   [1.37055939e+02 1.86213565e+00 1.11273727e+01]\n",
      "   [1.30418167e+02 0.00000000e+00 5.41816330e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.57285721e+02 1.22285713e+02 5.55714302e+01]\n",
      "   [1.58260208e+02 1.24454086e+02 5.78571434e+01]\n",
      "   [1.60780609e+02 1.27081635e+02 6.07755089e+01]\n",
      "   ...\n",
      "   [5.05714073e+01 2.55714073e+01 5.14287901e+00]\n",
      "   [5.17857399e+01 2.67857399e+01 6.78574038e+00]\n",
      "   [5.72296486e+01 3.02296486e+01 1.12296495e+01]]\n",
      "\n",
      "  [[1.61000000e+02 1.29785721e+02 6.57857132e+01]\n",
      "   [1.60933670e+02 1.30780609e+02 6.67142868e+01]\n",
      "   [1.63142853e+02 1.33071426e+02 7.08724518e+01]\n",
      "   ...\n",
      "   [4.90714264e+01 2.42703876e+01 3.44394112e+00]\n",
      "   [5.21479874e+01 2.71479855e+01 7.14798641e+00]\n",
      "   [5.67652740e+01 3.27602730e+01 1.24286060e+01]]\n",
      "\n",
      "  [[1.60637756e+02 1.33933670e+02 7.56428604e+01]\n",
      "   [1.60000000e+02 1.34214279e+02 7.58571472e+01]\n",
      "   [1.61214279e+02 1.35428558e+02 7.86428604e+01]\n",
      "   ...\n",
      "   [4.96428146e+01 2.72142868e+01 5.57149410e+00]\n",
      "   [4.91836662e+01 2.75000134e+01 6.48470449e+00]\n",
      "   [4.97857132e+01 2.94285717e+01 9.78571415e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[2.48030762e+02 2.04331848e+02 1.20183937e+02]\n",
      "   [2.37423752e+02 1.95694229e+02 1.07638130e+02]\n",
      "   [2.14500015e+02 1.72785828e+02 7.55001755e+01]\n",
      "   ...\n",
      "   [8.34744339e+01 4.65968819e+01 9.54090953e-01]\n",
      "   [7.96988678e+01 4.51019936e+01 1.98956549e-01]\n",
      "   [7.57907028e+01 4.15662613e+01 0.00000000e+00]]\n",
      "\n",
      "  [[2.37127609e+02 2.01413376e+02 1.24341972e+02]\n",
      "   [2.54601974e+02 2.24658066e+02 1.42882584e+02]\n",
      "   [2.25627563e+02 1.89857162e+02 9.89031067e+01]\n",
      "   ...\n",
      "   [7.84692917e+01 4.30713806e+01 7.85736084e-01]\n",
      "   [7.46478958e+01 3.98520126e+01 0.00000000e+00]\n",
      "   [7.19030380e+01 3.82347031e+01 0.00000000e+00]]\n",
      "\n",
      "  [[2.30427979e+02 2.01014771e+02 1.29040283e+02]\n",
      "   [2.35464096e+02 2.07107025e+02 1.29795822e+02]\n",
      "   [2.12836456e+02 1.80831421e+02 9.45558853e+01]\n",
      "   ...\n",
      "   [7.32192612e+01 3.84999084e+01 0.00000000e+00]\n",
      "   [6.92142029e+01 3.52142029e+01 0.00000000e+00]\n",
      "   [6.72856445e+01 3.52856445e+01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.46025818e+02 7.74221954e+01 7.04712982e+01]\n",
      "   [1.51669968e+02 9.34068909e+01 8.63086777e+01]\n",
      "   [1.54709183e+02 1.08565369e+02 1.04132973e+02]\n",
      "   ...\n",
      "   [1.40536743e+02 1.20269447e+02 9.90013428e+01]\n",
      "   [1.29961945e+02 1.05208420e+02 8.81962738e+01]\n",
      "   [1.20489418e+02 9.42030334e+01 7.10898132e+01]]\n",
      "\n",
      "  [[1.57517853e+02 1.43787628e+02 1.29133926e+02]\n",
      "   [1.56303894e+02 1.46519135e+02 1.33407516e+02]\n",
      "   [1.51370529e+02 1.46835464e+02 1.36702484e+02]\n",
      "   ...\n",
      "   [1.42908157e+02 1.22305122e+02 1.02717804e+02]\n",
      "   [1.29376450e+02 9.51865997e+01 7.34620285e+01]\n",
      "   [1.25383781e+02 7.03207550e+01 3.41684837e+01]]\n",
      "\n",
      "  [[1.59473846e+02 1.43294647e+02 1.32901779e+02]\n",
      "   [1.59554535e+02 1.41483093e+02 1.34894775e+02]\n",
      "   [1.59561234e+02 1.39178574e+02 1.36203751e+02]\n",
      "   ...\n",
      "   [1.43105545e+02 1.17196182e+02 9.61216507e+01]\n",
      "   [1.06141640e+02 7.34185638e+01 5.21700935e+01]\n",
      "   [1.19513474e+02 5.99322357e+01 2.17531719e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.50729156e+02 2.37782860e+01 3.06308861e+01]\n",
      "   [1.57156891e+02 2.80586281e+01 3.31077614e+01]\n",
      "   [1.54748138e+02 2.90608978e+01 3.18852177e+01]\n",
      "   ...\n",
      "   [1.21723328e+02 1.06741943e+01 3.56152153e+00]\n",
      "   [1.25276001e+02 1.41098042e+01 7.76281834e+00]\n",
      "   [1.24326385e+02 1.22772503e+01 8.67031670e+00]]\n",
      "\n",
      "  [[1.50538101e+02 2.31411228e+01 3.05381031e+01]\n",
      "   [1.57007965e+02 3.12805882e+01 3.54948730e+01]\n",
      "   [1.53465286e+02 2.94652901e+01 3.13064976e+01]\n",
      "   ...\n",
      "   [1.25651611e+02 1.35400696e+01 8.86391449e+00]\n",
      "   [1.25125168e+02 1.30136299e+01 8.23671341e+00]\n",
      "   [1.22447922e+02 1.03363800e+01 5.55946350e+00]]\n",
      "\n",
      "  [[1.52787354e+02 2.47159328e+01 3.38032837e+01]\n",
      "   [1.50934448e+02 2.73719139e+01 3.07960377e+01]\n",
      "   [1.50152466e+02 2.73941460e+01 2.71030521e+01]\n",
      "   ...\n",
      "   [1.32250565e+02 1.74604053e+01 2.17498169e+01]\n",
      "   [1.34331787e+02 1.95416336e+01 2.31696987e+01]\n",
      "   [1.31023193e+02 1.62330341e+01 1.83936787e+01]]]\n",
      "\n",
      "\n",
      " [[[3.50000000e+01 3.10000000e+01 2.80000000e+01]\n",
      "   [3.59540825e+01 3.19540825e+01 2.89540825e+01]\n",
      "   [3.70000000e+01 3.30000000e+01 3.00000000e+01]\n",
      "   ...\n",
      "   [4.22142639e+01 4.02142639e+01 4.12142639e+01]\n",
      "   [4.03316269e+01 3.83316269e+01 3.93316269e+01]\n",
      "   [3.92295799e+01 3.72295799e+01 3.82295799e+01]]\n",
      "\n",
      "  [[3.60000000e+01 3.20000000e+01 2.90000000e+01]\n",
      "   [3.60663261e+01 3.20663261e+01 2.90663261e+01]\n",
      "   [3.72704086e+01 3.32704086e+01 3.02704086e+01]\n",
      "   ...\n",
      "   [4.22703896e+01 4.02703896e+01 4.12703896e+01]\n",
      "   [4.10663261e+01 3.90663261e+01 4.00663261e+01]\n",
      "   [4.00714302e+01 3.80714302e+01 3.90714302e+01]]\n",
      "\n",
      "  [[3.67857132e+01 3.27857132e+01 2.97857132e+01]\n",
      "   [3.69846954e+01 3.29846954e+01 2.99846935e+01]\n",
      "   [3.81683693e+01 3.41683693e+01 3.11683674e+01]\n",
      "   ...\n",
      "   [4.30000000e+01 4.10000000e+01 4.20000000e+01]\n",
      "   [4.19846916e+01 3.99846916e+01 4.09846916e+01]\n",
      "   [4.17857132e+01 3.97857132e+01 4.07857132e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.00000000e+01 1.00000000e+01 1.00000000e+01]\n",
      "   [1.09846935e+01 1.09846935e+01 1.09846935e+01]\n",
      "   [9.95407963e+00 9.95407963e+00 9.95407963e+00]\n",
      "   ...\n",
      "   [2.51683788e+01 2.67397900e+01 2.59540844e+01]\n",
      "   [2.49285583e+01 2.64999695e+01 2.57142639e+01]\n",
      "   [2.31377525e+01 2.47091637e+01 2.39234581e+01]]\n",
      "\n",
      "  [[9.07141113e+00 9.07141113e+00 9.07141113e+00]\n",
      "   [1.00663099e+01 1.00663099e+01 1.00663099e+01]\n",
      "   [9.98469734e+00 9.98469734e+00 9.98469734e+00]\n",
      "   ...\n",
      "   [2.50561104e+01 2.50561104e+01 2.50561104e+01]\n",
      "   [2.49285583e+01 2.49285583e+01 2.49285583e+01]\n",
      "   [2.30459042e+01 2.30459042e+01 2.30459042e+01]]\n",
      "\n",
      "  [[7.77040958e+00 7.77040958e+00 7.77040958e+00]\n",
      "   [9.92857170e+00 9.92857170e+00 9.92857170e+00]\n",
      "   [1.00000000e+01 1.00000000e+01 1.00000000e+01]\n",
      "   ...\n",
      "   [2.43571472e+01 2.43571472e+01 2.43571472e+01]\n",
      "   [2.39285583e+01 2.39285583e+01 2.39285583e+01]\n",
      "   [2.26428223e+01 2.26428223e+01 2.26428223e+01]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# See an example of a batch of data\n",
    "for images, labels in train_data_10_percent.take(1):\n",
    "    print(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0: Building a transfer learning model using the Keras Functional API\n",
    "\n",
    "The Sequential API is straight-forward, it runs our layers in sequential order.\n",
    "\n",
    "But the functional API gives us more flexibility with our models - https://www.tensorflow.org/guide/keras/functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`load_weights` requires h5py when loading weights from HDF5.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11388/2715014888.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1. Create base model with tf.keras.applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m base_model = tf.keras.applications.EfficientNetB0(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gutsc\\anaconda3\\envs\\udemy_tensorflow\\lib\\site-packages\\keras\\applications\\efficientnet.py\u001b[0m in \u001b[0;36mEfficientNetB0\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m                    \u001b[0mclassifier_activation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m                    **kwargs):\n\u001b[1;32m--> 536\u001b[1;33m   return EfficientNet(\n\u001b[0m\u001b[0;32m    537\u001b[0m       \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m       \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gutsc\\anaconda3\\envs\\udemy_tensorflow\\lib\\site-packages\\keras\\applications\\efficientnet.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         file_hash=file_hash)\n\u001b[1;32m--> 412\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\gutsc\\anaconda3\\envs\\udemy_tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2344\u001b[0m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2345\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2346\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m   2347\u001b[0m             '`load_weights` requires h5py when loading weights from HDF5.')\n\u001b[0;32m   2348\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: `load_weights` requires h5py when loading weights from HDF5."
     ]
    }
   ],
   "source": [
    "# 1. Create base model with tf.keras.applications\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create inputs into our model\n",
    "inputs = tf.keras.layers.Input(shape=IMG_SIZE + (3,), name=\"input_layer\")\n",
    "\n",
    "# 4. If using a model like ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet)\n",
    "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./225.)(inputs)\n",
    "\n",
    "# 5. Pass the inputs to the base_model\n",
    "x = base_model(inputs)\n",
    "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
    "\n",
    "# 7. Create the output activation layer\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# 8. Combine the inputs with the outputs into a model\n",
    "model_0 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile the model\n",
    "model_0.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 10. Fit the model and save it's history\n",
    "history_0 = model_0.fit(\n",
    "    train_data_10_percent,\n",
    "    epochs=5,\n",
    "    steps=len(train_data_10_percent),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(\n",
    "            dir_name=\"transfer_learning\",\n",
    "            experiment_name=\"10_percent_feature_extraction\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('udemy_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63418e73e250c304d26eaf03185e2f59ff2277f62dd1cc8bba54019c2c46cc60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
